{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b347f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os,sys, re, time\n",
    "import PIL\n",
    "from PIL import Image as PILImage\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import torchvision\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcd2611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.68</td>\n",
       "      <td>10.32</td>\n",
       "      <td>10.68</td>\n",
       "      <td>201853036</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>10.73</td>\n",
       "      <td>10.85</td>\n",
       "      <td>10.64</td>\n",
       "      <td>10.71</td>\n",
       "      <td>155225609</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>10.69</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.54</td>\n",
       "      <td>10.63</td>\n",
       "      <td>112396081</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>10.75</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.65</td>\n",
       "      <td>10.90</td>\n",
       "      <td>176139334</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>10.96</td>\n",
       "      <td>11.03</td>\n",
       "      <td>10.82</td>\n",
       "      <td>10.86</td>\n",
       "      <td>168861224</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date   Open   High    Low  Close     Volume  Name\n",
       "0           0  2006-01-03  10.34  10.68  10.32  10.68  201853036  AAPL\n",
       "1           1  2006-01-04  10.73  10.85  10.64  10.71  155225609  AAPL\n",
       "2           2  2006-01-05  10.69  10.70  10.54  10.63  112396081  AAPL\n",
       "3           3  2006-01-06  10.75  10.96  10.65  10.90  176139334  AAPL\n",
       "4           4  2006-01-09  10.96  11.03  10.82  10.86  168861224  AAPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('time_series_data/train_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68033959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "683fe045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StocksDataLoader(data.Dataset):\n",
    "    def __init__(self,stocks = False,data_dir=None, stage=None, length=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.stage = stage\n",
    "        self.length = length\n",
    "        self.stocks = stocks\n",
    "        if not self.stocks:\n",
    "            if self.stage == 'train': \n",
    "                self.data = self.load_data(os.path.join(self.data_dir,'train_data.csv'))\n",
    "            elif self.stage == 'test':\n",
    "                self.data = self.load_data(os.path.join(self.data_dir, 'test_data.csv'))\n",
    "            elif self.stage == 'val':\n",
    "                self.data = self.load_data(os.path.join(self.data_dir, 'val_data.csv'))\n",
    "        else:\n",
    "            tr_ratio, val_ratio, test_ratio = 0.7,0.15,0.15\n",
    "            self.root = os.path.join(self.data_dir,self.stocks)\n",
    "            self.data = self.split_data(self.root,tr_ratio, val_ratio, test_ratio)\n",
    "        \n",
    "            \n",
    "            \n",
    "    def load_data(self,path):\n",
    "        data = pd.read_csv(path)\n",
    "        data = torch.tensor(data['Close'])\n",
    "        return data\n",
    "    \n",
    "    def split_data(self,path,tr_ratio,val_ratio,test_ratio):\n",
    "        \n",
    "        data = pd.read_csv(path)\n",
    "        total_rows = len(data)\n",
    "        train_end_idx = int(tr_ratio*total_rows)\n",
    "        val_end_idx = int(train_end_idx + val_ratio*total_rows)\n",
    "        test_end_idx = int(val_end_idx + test_ratio*total_rows)\n",
    "        \n",
    "        train_data = data.iloc[:train_end_idx]\n",
    "        val_data = data.iloc[train_end_idx:val_end_idx]\n",
    "        test_data = data.iloc[val_end_idx:]\n",
    "        if self.stage == 'train':\n",
    "            data = torch.tensor(train_data['Close'].values)\n",
    "        elif self.stage == 'val':\n",
    "            data = torch.tensor(val_data['Close'].values)\n",
    "        elif self.stage == 'test':\n",
    "            data = torch.tensor(test_data['Close'].values)\n",
    "        return data\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        input_data = self.data[idx:idx+self.length].float()\n",
    "        output_data = self.data[idx+self.length].float()\n",
    "        return idx, input_data, output_data\n",
    "    \n",
    "    def __len__(self,):\n",
    "        return len(self.data) - self.length\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65fe4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,num_layers=None, num_target = 1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_layers = num_layers \n",
    "        self.num_target = num_target\n",
    "        self.linear1 = nn.Linear(num_layers,512)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batchNorm = nn.BatchNorm1d(512)\n",
    "        self.drop = nn.Dropout()\n",
    "        self.linear2 = nn.Linear(512,1)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.batchNorm(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    def init_weights(self,):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight.data)\n",
    "                layer.bias.data.fill_(0.1)\n",
    "                \n",
    "                \n",
    "            elif isinstance(layer, nn.BatchNorm1d):\n",
    "                layer.weight.data.fill_(1)\n",
    "                layer.bias.data.fill_(0.01)\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b862bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20\n",
    "train_batch_size = 512\n",
    "val_batch_size = 512\n",
    "test_batch_size = 512\n",
    "\n",
    "train_data = StocksDataLoader('MSFT_2006-01-01_to_2018-01-01.csv','time_series_data','train',seq_length)\n",
    "train_dataloader = data.DataLoader(train_data, batch_size = train_batch_size, shuffle=True)\n",
    "\n",
    "val_data = StocksDataLoader('MSFT_2006-01-01_to_2018-01-01.csv','time_series_data','val',seq_length)\n",
    "val_dataloader = data.DataLoader(val_data, batch_size = val_batch_size, shuffle=False)\n",
    "\n",
    "test_data = StocksDataLoader('MSFT_2006-01-01_to_2018-01-01.csv','time_series_data','test',seq_length)\n",
    "test_dataloader = data.DataLoader(test_data, batch_size = test_batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97881133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "print('Using {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33d2b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (linear1): Linear(in_features=20, out_features=512, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (batchNorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (linear2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "Total number of trainable parameters : 13314\n"
     ]
    }
   ],
   "source": [
    "model = Model(seq_length)\n",
    "model.to(device)\n",
    "model.train()\n",
    "total_params = 0\n",
    "print(model)\n",
    "for n,params in model.state_dict().items():\n",
    "    total_params += params.numel()\n",
    "    \n",
    "print('Total number of trainable parameters : {}'.format(total_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d6f9e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Train loss: 1.570, Validation loss: 4.288\n",
      "Epoch:1, Train loss: 1.544, Validation loss: 4.289\n",
      "Epoch:2, Train loss: 1.525, Validation loss: 4.267\n",
      "Epoch:3, Train loss: 1.528, Validation loss: 4.245\n",
      "Epoch:4, Train loss: 1.478, Validation loss: 4.217\n",
      "Epoch:5, Train loss: 1.500, Validation loss: 4.201\n",
      "Epoch:6, Train loss: 1.484, Validation loss: 4.187\n",
      "Epoch:7, Train loss: 1.487, Validation loss: 4.187\n",
      "Epoch:8, Train loss: 1.460, Validation loss: 4.158\n",
      "Epoch:9, Train loss: 1.472, Validation loss: 4.133\n",
      "Epoch:10, Train loss: 1.467, Validation loss: 4.140\n",
      "Epoch:11, Train loss: 1.441, Validation loss: 4.113\n",
      "Epoch:12, Train loss: 1.459, Validation loss: 4.090\n",
      "Epoch:13, Train loss: 1.442, Validation loss: 4.077\n",
      "Epoch:14, Train loss: 1.433, Validation loss: 4.056\n",
      "Epoch:15, Train loss: 1.415, Validation loss: 4.045\n",
      "Epoch:16, Train loss: 1.384, Validation loss: 4.015\n",
      "Epoch:17, Train loss: 1.384, Validation loss: 4.004\n",
      "Epoch:18, Train loss: 1.369, Validation loss: 3.976\n",
      "Epoch:19, Train loss: 1.355, Validation loss: 3.968\n",
      "Epoch:20, Train loss: 1.326, Validation loss: 3.943\n",
      "Epoch:21, Train loss: 1.349, Validation loss: 3.927\n",
      "Epoch:22, Train loss: 1.298, Validation loss: 3.903\n",
      "Epoch:23, Train loss: 1.300, Validation loss: 3.881\n",
      "Epoch:24, Train loss: 1.292, Validation loss: 3.861\n",
      "Epoch:25, Train loss: 1.298, Validation loss: 3.835\n",
      "Epoch:26, Train loss: 1.269, Validation loss: 3.809\n",
      "Epoch:27, Train loss: 1.255, Validation loss: 3.786\n",
      "Epoch:28, Train loss: 1.260, Validation loss: 3.760\n",
      "Epoch:29, Train loss: 1.228, Validation loss: 3.736\n",
      "Epoch:30, Train loss: 1.197, Validation loss: 3.713\n",
      "Epoch:31, Train loss: 1.195, Validation loss: 3.688\n",
      "Epoch:32, Train loss: 1.187, Validation loss: 3.652\n",
      "Epoch:33, Train loss: 1.165, Validation loss: 3.621\n",
      "Epoch:34, Train loss: 1.170, Validation loss: 3.599\n",
      "Epoch:35, Train loss: 1.127, Validation loss: 3.570\n",
      "Epoch:36, Train loss: 1.126, Validation loss: 3.529\n",
      "Epoch:37, Train loss: 1.097, Validation loss: 3.496\n",
      "Epoch:38, Train loss: 1.101, Validation loss: 3.468\n",
      "Epoch:39, Train loss: 1.091, Validation loss: 3.430\n",
      "Epoch:40, Train loss: 1.043, Validation loss: 3.395\n",
      "Epoch:41, Train loss: 0.998, Validation loss: 3.379\n",
      "Epoch:42, Train loss: 1.022, Validation loss: 3.311\n",
      "Epoch:43, Train loss: 0.985, Validation loss: 3.295\n",
      "Epoch:44, Train loss: 0.957, Validation loss: 3.254\n",
      "Epoch:45, Train loss: 0.952, Validation loss: 3.205\n",
      "Epoch:46, Train loss: 0.940, Validation loss: 3.175\n",
      "Epoch:47, Train loss: 0.920, Validation loss: 3.123\n",
      "Epoch:48, Train loss: 0.884, Validation loss: 3.084\n",
      "Epoch:49, Train loss: 0.846, Validation loss: 3.044\n",
      "Epoch:50, Train loss: 0.825, Validation loss: 3.010\n",
      "Epoch:51, Train loss: 0.827, Validation loss: 2.973\n",
      "Epoch:52, Train loss: 0.802, Validation loss: 2.932\n",
      "Epoch:53, Train loss: 0.765, Validation loss: 2.879\n",
      "Epoch:54, Train loss: 0.778, Validation loss: 2.825\n",
      "Epoch:55, Train loss: 0.724, Validation loss: 2.775\n",
      "Epoch:56, Train loss: 0.693, Validation loss: 2.745\n",
      "Epoch:57, Train loss: 0.671, Validation loss: 2.706\n",
      "Epoch:58, Train loss: 0.656, Validation loss: 2.630\n",
      "Epoch:59, Train loss: 0.644, Validation loss: 2.604\n",
      "Epoch:60, Train loss: 0.619, Validation loss: 2.548\n",
      "Epoch:61, Train loss: 0.589, Validation loss: 2.496\n",
      "Epoch:62, Train loss: 0.559, Validation loss: 2.442\n",
      "Epoch:63, Train loss: 0.529, Validation loss: 2.407\n",
      "Epoch:64, Train loss: 0.538, Validation loss: 2.367\n",
      "Epoch:65, Train loss: 0.511, Validation loss: 2.304\n",
      "Epoch:66, Train loss: 0.487, Validation loss: 2.239\n",
      "Epoch:67, Train loss: 0.463, Validation loss: 2.213\n",
      "Epoch:68, Train loss: 0.431, Validation loss: 2.189\n",
      "Epoch:69, Train loss: 0.412, Validation loss: 2.112\n",
      "Epoch:70, Train loss: 0.412, Validation loss: 2.087\n",
      "Epoch:71, Train loss: 0.396, Validation loss: 2.017\n",
      "Epoch:72, Train loss: 0.374, Validation loss: 1.986\n",
      "Epoch:73, Train loss: 0.334, Validation loss: 1.952\n",
      "Epoch:74, Train loss: 0.315, Validation loss: 1.902\n",
      "Epoch:75, Train loss: 0.309, Validation loss: 1.858\n",
      "Epoch:76, Train loss: 0.293, Validation loss: 1.826\n",
      "Epoch:77, Train loss: 0.279, Validation loss: 1.764\n",
      "Epoch:78, Train loss: 0.254, Validation loss: 1.747\n",
      "Epoch:79, Train loss: 0.238, Validation loss: 1.680\n",
      "Epoch:80, Train loss: 0.228, Validation loss: 1.639\n",
      "Epoch:81, Train loss: 0.215, Validation loss: 1.626\n",
      "Epoch:82, Train loss: 0.196, Validation loss: 1.582\n",
      "Epoch:83, Train loss: 0.194, Validation loss: 1.569\n",
      "Epoch:84, Train loss: 0.181, Validation loss: 1.521\n",
      "Epoch:85, Train loss: 0.175, Validation loss: 1.476\n",
      "Epoch:86, Train loss: 0.160, Validation loss: 1.428\n",
      "Epoch:87, Train loss: 0.145, Validation loss: 1.435\n",
      "Epoch:88, Train loss: 0.142, Validation loss: 1.393\n",
      "Epoch:89, Train loss: 0.127, Validation loss: 1.363\n",
      "Epoch:90, Train loss: 0.128, Validation loss: 1.342\n",
      "Epoch:91, Train loss: 0.114, Validation loss: 1.309\n",
      "Epoch:92, Train loss: 0.111, Validation loss: 1.285\n",
      "Epoch:93, Train loss: 0.100, Validation loss: 1.247\n",
      "Epoch:94, Train loss: 0.098, Validation loss: 1.219\n",
      "Epoch:95, Train loss: 0.090, Validation loss: 1.214\n",
      "Epoch:96, Train loss: 0.087, Validation loss: 1.168\n",
      "Epoch:97, Train loss: 0.081, Validation loss: 1.161\n",
      "Epoch:98, Train loss: 0.079, Validation loss: 1.123\n",
      "Epoch:99, Train loss: 0.067, Validation loss: 1.109\n",
      "Epoch:100, Train loss: 0.065, Validation loss: 1.101\n",
      "Epoch:101, Train loss: 0.060, Validation loss: 1.084\n",
      "Epoch:102, Train loss: 0.058, Validation loss: 1.059\n",
      "Epoch:103, Train loss: 0.051, Validation loss: 1.028\n",
      "Epoch:104, Train loss: 0.051, Validation loss: 1.036\n",
      "Epoch:105, Train loss: 0.055, Validation loss: 0.999\n",
      "Epoch:106, Train loss: 0.044, Validation loss: 1.020\n",
      "Epoch:107, Train loss: 0.045, Validation loss: 0.988\n",
      "Epoch:108, Train loss: 0.041, Validation loss: 0.966\n",
      "Epoch:109, Train loss: 0.038, Validation loss: 0.976\n",
      "Epoch:110, Train loss: 0.043, Validation loss: 0.968\n",
      "Epoch:111, Train loss: 0.035, Validation loss: 0.937\n",
      "Epoch:112, Train loss: 0.030, Validation loss: 0.906\n",
      "Epoch:113, Train loss: 0.033, Validation loss: 0.906\n",
      "Epoch:114, Train loss: 0.030, Validation loss: 0.905\n",
      "Epoch:115, Train loss: 0.030, Validation loss: 0.893\n",
      "Epoch:116, Train loss: 0.027, Validation loss: 0.891\n",
      "Epoch:117, Train loss: 0.027, Validation loss: 0.875\n",
      "Epoch:118, Train loss: 0.027, Validation loss: 0.858\n",
      "Epoch:119, Train loss: 0.025, Validation loss: 0.865\n",
      "Epoch:120, Train loss: 0.027, Validation loss: 0.855\n",
      "Epoch:121, Train loss: 0.027, Validation loss: 0.850\n",
      "Epoch:122, Train loss: 0.025, Validation loss: 0.834\n",
      "Epoch:123, Train loss: 0.022, Validation loss: 0.841\n",
      "Epoch:124, Train loss: 0.021, Validation loss: 0.813\n",
      "Epoch:125, Train loss: 0.019, Validation loss: 0.838\n",
      "Epoch:126, Train loss: 0.021, Validation loss: 0.815\n",
      "Epoch:127, Train loss: 0.019, Validation loss: 0.814\n",
      "Epoch:128, Train loss: 0.018, Validation loss: 0.805\n",
      "Epoch:129, Train loss: 0.021, Validation loss: 0.798\n",
      "Epoch:130, Train loss: 0.018, Validation loss: 0.794\n",
      "Epoch:131, Train loss: 0.017, Validation loss: 0.795\n",
      "Epoch:132, Train loss: 0.018, Validation loss: 0.797\n",
      "Epoch:133, Train loss: 0.018, Validation loss: 0.784\n",
      "Epoch:134, Train loss: 0.016, Validation loss: 0.770\n",
      "Epoch:135, Train loss: 0.018, Validation loss: 0.790\n",
      "Epoch:136, Train loss: 0.016, Validation loss: 0.771\n",
      "Epoch:137, Train loss: 0.015, Validation loss: 0.781\n",
      "Epoch:138, Train loss: 0.017, Validation loss: 0.778\n",
      "Epoch:139, Train loss: 0.016, Validation loss: 0.766\n",
      "Epoch:140, Train loss: 0.016, Validation loss: 0.752\n",
      "Epoch:141, Train loss: 0.015, Validation loss: 0.761\n",
      "Epoch:142, Train loss: 0.015, Validation loss: 0.761\n",
      "Epoch:143, Train loss: 0.017, Validation loss: 0.751\n",
      "Epoch:144, Train loss: 0.014, Validation loss: 0.752\n",
      "Epoch:145, Train loss: 0.014, Validation loss: 0.748\n",
      "Epoch:146, Train loss: 0.015, Validation loss: 0.758\n",
      "Epoch:147, Train loss: 0.015, Validation loss: 0.737\n",
      "Epoch:148, Train loss: 0.016, Validation loss: 0.749\n",
      "Epoch:149, Train loss: 0.014, Validation loss: 0.738\n",
      "Epoch:150, Train loss: 0.017, Validation loss: 0.738\n",
      "Epoch:151, Train loss: 0.013, Validation loss: 0.738\n",
      "Epoch:152, Train loss: 0.012, Validation loss: 0.746\n",
      "Epoch:153, Train loss: 0.014, Validation loss: 0.745\n",
      "Epoch:154, Train loss: 0.013, Validation loss: 0.737\n",
      "Epoch:155, Train loss: 0.015, Validation loss: 0.739\n",
      "Epoch:156, Train loss: 0.013, Validation loss: 0.727\n",
      "Epoch:157, Train loss: 0.014, Validation loss: 0.743\n",
      "Epoch:158, Train loss: 0.014, Validation loss: 0.728\n",
      "Epoch:159, Train loss: 0.013, Validation loss: 0.728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:160, Train loss: 0.013, Validation loss: 0.731\n",
      "Epoch:161, Train loss: 0.013, Validation loss: 0.737\n",
      "Epoch:162, Train loss: 0.012, Validation loss: 0.721\n",
      "Epoch:163, Train loss: 0.014, Validation loss: 0.709\n",
      "Epoch:164, Train loss: 0.012, Validation loss: 0.725\n",
      "Epoch:165, Train loss: 0.015, Validation loss: 0.712\n",
      "Epoch:166, Train loss: 0.014, Validation loss: 0.717\n",
      "Epoch:167, Train loss: 0.013, Validation loss: 0.711\n",
      "Epoch:168, Train loss: 0.013, Validation loss: 0.721\n",
      "Epoch:169, Train loss: 0.014, Validation loss: 0.724\n",
      "Epoch:170, Train loss: 0.014, Validation loss: 0.743\n",
      "Epoch:171, Train loss: 0.013, Validation loss: 0.716\n",
      "Epoch:172, Train loss: 0.011, Validation loss: 0.721\n",
      "Epoch:173, Train loss: 0.013, Validation loss: 0.724\n",
      "Epoch:174, Train loss: 0.013, Validation loss: 0.733\n",
      "Epoch:175, Train loss: 0.013, Validation loss: 0.729\n",
      "Epoch:176, Train loss: 0.011, Validation loss: 0.715\n",
      "Epoch:177, Train loss: 0.013, Validation loss: 0.717\n",
      "Epoch:178, Train loss: 0.013, Validation loss: 0.723\n",
      "Epoch:179, Train loss: 0.012, Validation loss: 0.732\n",
      "Epoch:180, Train loss: 0.012, Validation loss: 0.697\n",
      "Epoch:181, Train loss: 0.012, Validation loss: 0.722\n",
      "Epoch:182, Train loss: 0.012, Validation loss: 0.725\n",
      "Epoch:183, Train loss: 0.012, Validation loss: 0.715\n",
      "Epoch:184, Train loss: 0.012, Validation loss: 0.725\n",
      "Epoch:185, Train loss: 0.012, Validation loss: 0.725\n",
      "Epoch:186, Train loss: 0.012, Validation loss: 0.714\n",
      "Epoch:187, Train loss: 0.013, Validation loss: 0.724\n",
      "Epoch:188, Train loss: 0.012, Validation loss: 0.716\n",
      "Epoch:189, Train loss: 0.011, Validation loss: 0.698\n",
      "Epoch:190, Train loss: 0.011, Validation loss: 0.721\n",
      "Epoch:191, Train loss: 0.011, Validation loss: 0.719\n",
      "Epoch:192, Train loss: 0.013, Validation loss: 0.711\n",
      "Epoch:193, Train loss: 0.010, Validation loss: 0.716\n",
      "Epoch:194, Train loss: 0.011, Validation loss: 0.720\n",
      "Epoch:195, Train loss: 0.013, Validation loss: 0.704\n",
      "Epoch:196, Train loss: 0.012, Validation loss: 0.719\n",
      "Epoch:197, Train loss: 0.012, Validation loss: 0.710\n",
      "Epoch:198, Train loss: 0.013, Validation loss: 0.720\n",
      "Epoch:199, Train loss: 0.012, Validation loss: 0.715\n",
      "Epoch:200, Train loss: 0.010, Validation loss: 0.717\n",
      "Epoch:201, Train loss: 0.012, Validation loss: 0.707\n",
      "Epoch:202, Train loss: 0.011, Validation loss: 0.721\n",
      "Epoch:203, Train loss: 0.012, Validation loss: 0.706\n",
      "Epoch:204, Train loss: 0.012, Validation loss: 0.722\n",
      "Epoch:205, Train loss: 0.013, Validation loss: 0.710\n",
      "Epoch:206, Train loss: 0.011, Validation loss: 0.710\n",
      "Epoch:207, Train loss: 0.011, Validation loss: 0.712\n",
      "Epoch:208, Train loss: 0.011, Validation loss: 0.721\n",
      "Epoch:209, Train loss: 0.011, Validation loss: 0.705\n",
      "Epoch:210, Train loss: 0.011, Validation loss: 0.719\n",
      "Epoch:211, Train loss: 0.011, Validation loss: 0.711\n",
      "Epoch:212, Train loss: 0.012, Validation loss: 0.720\n",
      "Epoch:213, Train loss: 0.011, Validation loss: 0.710\n",
      "Epoch:214, Train loss: 0.010, Validation loss: 0.700\n",
      "Epoch:215, Train loss: 0.012, Validation loss: 0.699\n",
      "Epoch:216, Train loss: 0.011, Validation loss: 0.702\n",
      "Epoch:217, Train loss: 0.013, Validation loss: 0.720\n",
      "Epoch:218, Train loss: 0.011, Validation loss: 0.714\n",
      "Epoch:219, Train loss: 0.010, Validation loss: 0.699\n",
      "Epoch:220, Train loss: 0.011, Validation loss: 0.706\n",
      "Epoch:221, Train loss: 0.011, Validation loss: 0.706\n",
      "Epoch:222, Train loss: 0.011, Validation loss: 0.709\n",
      "Epoch:223, Train loss: 0.010, Validation loss: 0.708\n",
      "Epoch:224, Train loss: 0.010, Validation loss: 0.708\n",
      "Epoch:225, Train loss: 0.010, Validation loss: 0.715\n",
      "Epoch:226, Train loss: 0.011, Validation loss: 0.705\n",
      "Epoch:227, Train loss: 0.012, Validation loss: 0.716\n",
      "Epoch:228, Train loss: 0.011, Validation loss: 0.712\n",
      "Epoch:229, Train loss: 0.010, Validation loss: 0.713\n",
      "Epoch:230, Train loss: 0.011, Validation loss: 0.697\n",
      "Epoch:231, Train loss: 0.011, Validation loss: 0.722\n",
      "Epoch:232, Train loss: 0.010, Validation loss: 0.714\n",
      "Epoch:233, Train loss: 0.010, Validation loss: 0.703\n",
      "Epoch:234, Train loss: 0.010, Validation loss: 0.701\n",
      "Epoch:235, Train loss: 0.010, Validation loss: 0.694\n",
      "Epoch:236, Train loss: 0.011, Validation loss: 0.707\n",
      "Epoch:237, Train loss: 0.011, Validation loss: 0.703\n",
      "Epoch:238, Train loss: 0.009, Validation loss: 0.698\n",
      "Epoch:239, Train loss: 0.011, Validation loss: 0.711\n",
      "Epoch:240, Train loss: 0.012, Validation loss: 0.702\n",
      "Epoch:241, Train loss: 0.011, Validation loss: 0.715\n",
      "Epoch:242, Train loss: 0.010, Validation loss: 0.714\n",
      "Epoch:243, Train loss: 0.010, Validation loss: 0.705\n",
      "Epoch:244, Train loss: 0.011, Validation loss: 0.712\n",
      "Epoch:245, Train loss: 0.011, Validation loss: 0.708\n",
      "Epoch:246, Train loss: 0.010, Validation loss: 0.704\n",
      "Epoch:247, Train loss: 0.009, Validation loss: 0.719\n",
      "Epoch:248, Train loss: 0.010, Validation loss: 0.713\n",
      "Epoch:249, Train loss: 0.010, Validation loss: 0.702\n",
      "Epoch:250, Train loss: 0.009, Validation loss: 0.715\n",
      "Epoch:251, Train loss: 0.010, Validation loss: 0.690\n",
      "Epoch:252, Train loss: 0.011, Validation loss: 0.717\n",
      "Epoch:253, Train loss: 0.011, Validation loss: 0.719\n",
      "Epoch:254, Train loss: 0.011, Validation loss: 0.698\n",
      "Epoch:255, Train loss: 0.011, Validation loss: 0.707\n",
      "Epoch:256, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:257, Train loss: 0.010, Validation loss: 0.700\n",
      "Epoch:258, Train loss: 0.010, Validation loss: 0.713\n",
      "Epoch:259, Train loss: 0.010, Validation loss: 0.707\n",
      "Epoch:260, Train loss: 0.012, Validation loss: 0.706\n",
      "Epoch:261, Train loss: 0.010, Validation loss: 0.706\n",
      "Epoch:262, Train loss: 0.010, Validation loss: 0.706\n",
      "Epoch:263, Train loss: 0.009, Validation loss: 0.708\n",
      "Epoch:264, Train loss: 0.009, Validation loss: 0.700\n",
      "Epoch:265, Train loss: 0.010, Validation loss: 0.709\n",
      "Epoch:266, Train loss: 0.010, Validation loss: 0.709\n",
      "Epoch:267, Train loss: 0.010, Validation loss: 0.712\n",
      "Epoch:268, Train loss: 0.010, Validation loss: 0.704\n",
      "Epoch:269, Train loss: 0.010, Validation loss: 0.705\n",
      "Epoch:270, Train loss: 0.010, Validation loss: 0.703\n",
      "Epoch:271, Train loss: 0.010, Validation loss: 0.715\n",
      "Epoch:272, Train loss: 0.009, Validation loss: 0.713\n",
      "Epoch:273, Train loss: 0.010, Validation loss: 0.705\n",
      "Epoch:274, Train loss: 0.010, Validation loss: 0.708\n",
      "Epoch:275, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:276, Train loss: 0.009, Validation loss: 0.695\n",
      "Epoch:277, Train loss: 0.010, Validation loss: 0.717\n",
      "Epoch:278, Train loss: 0.010, Validation loss: 0.704\n",
      "Epoch:279, Train loss: 0.010, Validation loss: 0.714\n",
      "Epoch:280, Train loss: 0.010, Validation loss: 0.704\n",
      "Epoch:281, Train loss: 0.009, Validation loss: 0.708\n",
      "Epoch:282, Train loss: 0.011, Validation loss: 0.713\n",
      "Epoch:283, Train loss: 0.010, Validation loss: 0.706\n",
      "Epoch:284, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:285, Train loss: 0.010, Validation loss: 0.708\n",
      "Epoch:286, Train loss: 0.010, Validation loss: 0.705\n",
      "Epoch:287, Train loss: 0.012, Validation loss: 0.713\n",
      "Epoch:288, Train loss: 0.010, Validation loss: 0.720\n",
      "Epoch:289, Train loss: 0.011, Validation loss: 0.698\n",
      "Epoch:290, Train loss: 0.009, Validation loss: 0.705\n",
      "Epoch:291, Train loss: 0.011, Validation loss: 0.710\n",
      "Epoch:292, Train loss: 0.010, Validation loss: 0.713\n",
      "Epoch:293, Train loss: 0.010, Validation loss: 0.718\n",
      "Epoch:294, Train loss: 0.009, Validation loss: 0.700\n",
      "Epoch:295, Train loss: 0.009, Validation loss: 0.720\n",
      "Epoch:296, Train loss: 0.009, Validation loss: 0.713\n",
      "Epoch:297, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:298, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:299, Train loss: 0.010, Validation loss: 0.711\n",
      "Epoch:300, Train loss: 0.009, Validation loss: 0.712\n",
      "Epoch:301, Train loss: 0.010, Validation loss: 0.716\n",
      "Epoch:302, Train loss: 0.010, Validation loss: 0.701\n",
      "Epoch:303, Train loss: 0.008, Validation loss: 0.716\n",
      "Epoch:304, Train loss: 0.010, Validation loss: 0.711\n",
      "Epoch:305, Train loss: 0.010, Validation loss: 0.712\n",
      "Epoch:306, Train loss: 0.010, Validation loss: 0.709\n",
      "Epoch:307, Train loss: 0.009, Validation loss: 0.717\n",
      "Epoch:308, Train loss: 0.009, Validation loss: 0.716\n",
      "Epoch:309, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:310, Train loss: 0.009, Validation loss: 0.697\n",
      "Epoch:311, Train loss: 0.009, Validation loss: 0.705\n",
      "Epoch:312, Train loss: 0.009, Validation loss: 0.716\n",
      "Epoch:313, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:314, Train loss: 0.009, Validation loss: 0.712\n",
      "Epoch:315, Train loss: 0.009, Validation loss: 0.712\n",
      "Epoch:316, Train loss: 0.009, Validation loss: 0.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:317, Train loss: 0.010, Validation loss: 0.719\n",
      "Epoch:318, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:319, Train loss: 0.009, Validation loss: 0.718\n",
      "Epoch:320, Train loss: 0.011, Validation loss: 0.723\n",
      "Epoch:321, Train loss: 0.009, Validation loss: 0.715\n",
      "Epoch:322, Train loss: 0.009, Validation loss: 0.708\n",
      "Epoch:323, Train loss: 0.010, Validation loss: 0.698\n",
      "Epoch:324, Train loss: 0.010, Validation loss: 0.713\n",
      "Epoch:325, Train loss: 0.009, Validation loss: 0.710\n",
      "Epoch:326, Train loss: 0.009, Validation loss: 0.713\n",
      "Epoch:327, Train loss: 0.010, Validation loss: 0.717\n",
      "Epoch:328, Train loss: 0.009, Validation loss: 0.710\n",
      "Epoch:329, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:330, Train loss: 0.009, Validation loss: 0.710\n",
      "Epoch:331, Train loss: 0.009, Validation loss: 0.713\n",
      "Epoch:332, Train loss: 0.009, Validation loss: 0.708\n",
      "Epoch:333, Train loss: 0.009, Validation loss: 0.701\n",
      "Epoch:334, Train loss: 0.009, Validation loss: 0.712\n",
      "Epoch:335, Train loss: 0.009, Validation loss: 0.702\n",
      "Epoch:336, Train loss: 0.008, Validation loss: 0.712\n",
      "Epoch:337, Train loss: 0.009, Validation loss: 0.713\n",
      "Epoch:338, Train loss: 0.009, Validation loss: 0.718\n",
      "Epoch:339, Train loss: 0.009, Validation loss: 0.713\n",
      "Epoch:340, Train loss: 0.009, Validation loss: 0.697\n",
      "Epoch:341, Train loss: 0.010, Validation loss: 0.712\n",
      "Epoch:342, Train loss: 0.010, Validation loss: 0.723\n",
      "Epoch:343, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:344, Train loss: 0.009, Validation loss: 0.702\n",
      "Epoch:345, Train loss: 0.008, Validation loss: 0.715\n",
      "Epoch:346, Train loss: 0.009, Validation loss: 0.714\n",
      "Epoch:347, Train loss: 0.009, Validation loss: 0.705\n",
      "Epoch:348, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:349, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:350, Train loss: 0.009, Validation loss: 0.704\n",
      "Epoch:351, Train loss: 0.009, Validation loss: 0.703\n",
      "Epoch:352, Train loss: 0.009, Validation loss: 0.701\n",
      "Epoch:353, Train loss: 0.009, Validation loss: 0.700\n",
      "Epoch:354, Train loss: 0.009, Validation loss: 0.707\n",
      "Epoch:355, Train loss: 0.009, Validation loss: 0.704\n",
      "Epoch:356, Train loss: 0.010, Validation loss: 0.694\n",
      "Epoch:357, Train loss: 0.009, Validation loss: 0.701\n",
      "Epoch:358, Train loss: 0.010, Validation loss: 0.701\n",
      "Epoch:359, Train loss: 0.009, Validation loss: 0.707\n",
      "Epoch:360, Train loss: 0.009, Validation loss: 0.710\n",
      "Epoch:361, Train loss: 0.010, Validation loss: 0.704\n",
      "Epoch:362, Train loss: 0.009, Validation loss: 0.705\n",
      "Epoch:363, Train loss: 0.009, Validation loss: 0.702\n",
      "Epoch:364, Train loss: 0.009, Validation loss: 0.707\n",
      "Epoch:365, Train loss: 0.010, Validation loss: 0.722\n",
      "Epoch:366, Train loss: 0.010, Validation loss: 0.714\n",
      "Epoch:367, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:368, Train loss: 0.010, Validation loss: 0.694\n",
      "Epoch:369, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:370, Train loss: 0.009, Validation loss: 0.722\n",
      "Epoch:371, Train loss: 0.009, Validation loss: 0.718\n",
      "Epoch:372, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:373, Train loss: 0.009, Validation loss: 0.704\n",
      "Epoch:374, Train loss: 0.009, Validation loss: 0.702\n",
      "Epoch:375, Train loss: 0.008, Validation loss: 0.711\n",
      "Epoch:376, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:377, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:378, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:379, Train loss: 0.008, Validation loss: 0.716\n",
      "Epoch:380, Train loss: 0.009, Validation loss: 0.708\n",
      "Epoch:381, Train loss: 0.008, Validation loss: 0.718\n",
      "Epoch:382, Train loss: 0.008, Validation loss: 0.718\n",
      "Epoch:383, Train loss: 0.008, Validation loss: 0.690\n",
      "Epoch:384, Train loss: 0.009, Validation loss: 0.707\n",
      "Epoch:385, Train loss: 0.009, Validation loss: 0.717\n",
      "Epoch:386, Train loss: 0.008, Validation loss: 0.716\n",
      "Epoch:387, Train loss: 0.009, Validation loss: 0.708\n",
      "Epoch:388, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:389, Train loss: 0.009, Validation loss: 0.704\n",
      "Epoch:390, Train loss: 0.009, Validation loss: 0.702\n",
      "Epoch:391, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:392, Train loss: 0.008, Validation loss: 0.712\n",
      "Epoch:393, Train loss: 0.008, Validation loss: 0.721\n",
      "Epoch:394, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:395, Train loss: 0.008, Validation loss: 0.719\n",
      "Epoch:396, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:397, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:398, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:399, Train loss: 0.008, Validation loss: 0.712\n",
      "Epoch:400, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:401, Train loss: 0.009, Validation loss: 0.703\n",
      "Epoch:402, Train loss: 0.010, Validation loss: 0.715\n",
      "Epoch:403, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:404, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:405, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:406, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:407, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:408, Train loss: 0.008, Validation loss: 0.720\n",
      "Epoch:409, Train loss: 0.009, Validation loss: 0.712\n",
      "Epoch:410, Train loss: 0.008, Validation loss: 0.723\n",
      "Epoch:411, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:412, Train loss: 0.008, Validation loss: 0.715\n",
      "Epoch:413, Train loss: 0.009, Validation loss: 0.711\n",
      "Epoch:414, Train loss: 0.009, Validation loss: 0.704\n",
      "Epoch:415, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:416, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:417, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:418, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:419, Train loss: 0.009, Validation loss: 0.698\n",
      "Epoch:420, Train loss: 0.008, Validation loss: 0.716\n",
      "Epoch:421, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:422, Train loss: 0.008, Validation loss: 0.720\n",
      "Epoch:423, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:424, Train loss: 0.008, Validation loss: 0.712\n",
      "Epoch:425, Train loss: 0.009, Validation loss: 0.719\n",
      "Epoch:426, Train loss: 0.008, Validation loss: 0.713\n",
      "Epoch:427, Train loss: 0.008, Validation loss: 0.721\n",
      "Epoch:428, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:429, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:430, Train loss: 0.008, Validation loss: 0.720\n",
      "Epoch:431, Train loss: 0.009, Validation loss: 0.712\n",
      "Epoch:432, Train loss: 0.009, Validation loss: 0.697\n",
      "Epoch:433, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:434, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:435, Train loss: 0.008, Validation loss: 0.717\n",
      "Epoch:436, Train loss: 0.009, Validation loss: 0.702\n",
      "Epoch:437, Train loss: 0.008, Validation loss: 0.698\n",
      "Epoch:438, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:439, Train loss: 0.009, Validation loss: 0.700\n",
      "Epoch:440, Train loss: 0.009, Validation loss: 0.709\n",
      "Epoch:441, Train loss: 0.008, Validation loss: 0.720\n",
      "Epoch:442, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:443, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:444, Train loss: 0.009, Validation loss: 0.710\n",
      "Epoch:445, Train loss: 0.009, Validation loss: 0.715\n",
      "Epoch:446, Train loss: 0.008, Validation loss: 0.713\n",
      "Epoch:447, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:448, Train loss: 0.008, Validation loss: 0.717\n",
      "Epoch:449, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:450, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:451, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:452, Train loss: 0.009, Validation loss: 0.697\n",
      "Epoch:453, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:454, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:455, Train loss: 0.009, Validation loss: 0.696\n",
      "Epoch:456, Train loss: 0.010, Validation loss: 0.702\n",
      "Epoch:457, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:458, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:459, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:460, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:461, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:462, Train loss: 0.008, Validation loss: 0.698\n",
      "Epoch:463, Train loss: 0.008, Validation loss: 0.719\n",
      "Epoch:464, Train loss: 0.008, Validation loss: 0.724\n",
      "Epoch:465, Train loss: 0.007, Validation loss: 0.714\n",
      "Epoch:466, Train loss: 0.009, Validation loss: 0.708\n",
      "Epoch:467, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:468, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:469, Train loss: 0.007, Validation loss: 0.718\n",
      "Epoch:470, Train loss: 0.010, Validation loss: 0.698\n",
      "Epoch:471, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:472, Train loss: 0.008, Validation loss: 0.702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:473, Train loss: 0.008, Validation loss: 0.723\n",
      "Epoch:474, Train loss: 0.008, Validation loss: 0.693\n",
      "Epoch:475, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:476, Train loss: 0.008, Validation loss: 0.695\n",
      "Epoch:477, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:478, Train loss: 0.009, Validation loss: 0.703\n",
      "Epoch:479, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:480, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:481, Train loss: 0.009, Validation loss: 0.704\n",
      "Epoch:482, Train loss: 0.008, Validation loss: 0.698\n",
      "Epoch:483, Train loss: 0.008, Validation loss: 0.713\n",
      "Epoch:484, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:485, Train loss: 0.008, Validation loss: 0.684\n",
      "Epoch:486, Train loss: 0.009, Validation loss: 0.704\n",
      "Epoch:487, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:488, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:489, Train loss: 0.008, Validation loss: 0.711\n",
      "Epoch:490, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:491, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:492, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:493, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:494, Train loss: 0.009, Validation loss: 0.707\n",
      "Epoch:495, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:496, Train loss: 0.009, Validation loss: 0.701\n",
      "Epoch:497, Train loss: 0.009, Validation loss: 0.707\n",
      "Epoch:498, Train loss: 0.009, Validation loss: 0.700\n",
      "Epoch:499, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:500, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:501, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:502, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:503, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:504, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:505, Train loss: 0.008, Validation loss: 0.694\n",
      "Epoch:506, Train loss: 0.008, Validation loss: 0.699\n",
      "Epoch:507, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:508, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:509, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:510, Train loss: 0.008, Validation loss: 0.695\n",
      "Epoch:511, Train loss: 0.008, Validation loss: 0.699\n",
      "Epoch:512, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:513, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:514, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:515, Train loss: 0.007, Validation loss: 0.694\n",
      "Epoch:516, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:517, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:518, Train loss: 0.009, Validation loss: 0.702\n",
      "Epoch:519, Train loss: 0.009, Validation loss: 0.703\n",
      "Epoch:520, Train loss: 0.008, Validation loss: 0.692\n",
      "Epoch:521, Train loss: 0.008, Validation loss: 0.698\n",
      "Epoch:522, Train loss: 0.008, Validation loss: 0.690\n",
      "Epoch:523, Train loss: 0.008, Validation loss: 0.691\n",
      "Epoch:524, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:525, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:526, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:527, Train loss: 0.008, Validation loss: 0.694\n",
      "Epoch:528, Train loss: 0.008, Validation loss: 0.690\n",
      "Epoch:529, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:530, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:531, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:532, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:533, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:534, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:535, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:536, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:537, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:538, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:539, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:540, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:541, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:542, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:543, Train loss: 0.008, Validation loss: 0.692\n",
      "Epoch:544, Train loss: 0.007, Validation loss: 0.718\n",
      "Epoch:545, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:546, Train loss: 0.007, Validation loss: 0.718\n",
      "Epoch:547, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:548, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:549, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:550, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:551, Train loss: 0.010, Validation loss: 0.715\n",
      "Epoch:552, Train loss: 0.008, Validation loss: 0.699\n",
      "Epoch:553, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:554, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:555, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:556, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:557, Train loss: 0.008, Validation loss: 0.711\n",
      "Epoch:558, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:559, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:560, Train loss: 0.010, Validation loss: 0.698\n",
      "Epoch:561, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:562, Train loss: 0.008, Validation loss: 0.688\n",
      "Epoch:563, Train loss: 0.008, Validation loss: 0.687\n",
      "Epoch:564, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:565, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:566, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:567, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:568, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:569, Train loss: 0.007, Validation loss: 0.714\n",
      "Epoch:570, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:571, Train loss: 0.008, Validation loss: 0.695\n",
      "Epoch:572, Train loss: 0.007, Validation loss: 0.692\n",
      "Epoch:573, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:574, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:575, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:576, Train loss: 0.007, Validation loss: 0.723\n",
      "Epoch:577, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:578, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:579, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:580, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:581, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:582, Train loss: 0.008, Validation loss: 0.711\n",
      "Epoch:583, Train loss: 0.008, Validation loss: 0.699\n",
      "Epoch:584, Train loss: 0.007, Validation loss: 0.713\n",
      "Epoch:585, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:586, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:587, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:588, Train loss: 0.010, Validation loss: 0.700\n",
      "Epoch:589, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:590, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:591, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:592, Train loss: 0.009, Validation loss: 0.698\n",
      "Epoch:593, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:594, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:595, Train loss: 0.007, Validation loss: 0.689\n",
      "Epoch:596, Train loss: 0.007, Validation loss: 0.703\n",
      "Epoch:597, Train loss: 0.009, Validation loss: 0.703\n",
      "Epoch:598, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:599, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:600, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:601, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:602, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:603, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:604, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:605, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:606, Train loss: 0.008, Validation loss: 0.696\n",
      "Epoch:607, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:608, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:609, Train loss: 0.008, Validation loss: 0.695\n",
      "Epoch:610, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:611, Train loss: 0.008, Validation loss: 0.711\n",
      "Epoch:612, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:613, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:614, Train loss: 0.008, Validation loss: 0.698\n",
      "Epoch:615, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:616, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:617, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:618, Train loss: 0.007, Validation loss: 0.719\n",
      "Epoch:619, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:620, Train loss: 0.008, Validation loss: 0.699\n",
      "Epoch:621, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:622, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:623, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:624, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:625, Train loss: 0.007, Validation loss: 0.727\n",
      "Epoch:626, Train loss: 0.007, Validation loss: 0.687\n",
      "Epoch:627, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:628, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:629, Train loss: 0.008, Validation loss: 0.699\n",
      "Epoch:630, Train loss: 0.008, Validation loss: 0.710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:631, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:632, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:633, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:634, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:635, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:636, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:637, Train loss: 0.008, Validation loss: 0.692\n",
      "Epoch:638, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:639, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:640, Train loss: 0.008, Validation loss: 0.719\n",
      "Epoch:641, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:642, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:643, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:644, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:645, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:646, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:647, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:648, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:649, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:650, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:651, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:652, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:653, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:654, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:655, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:656, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:657, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:658, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:659, Train loss: 0.009, Validation loss: 0.695\n",
      "Epoch:660, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:661, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:662, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:663, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:664, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:665, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:666, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:667, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:668, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:669, Train loss: 0.008, Validation loss: 0.712\n",
      "Epoch:670, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:671, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:672, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:673, Train loss: 0.008, Validation loss: 0.696\n",
      "Epoch:674, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:675, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:676, Train loss: 0.008, Validation loss: 0.718\n",
      "Epoch:677, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:678, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:679, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:680, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:681, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:682, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:683, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:684, Train loss: 0.007, Validation loss: 0.719\n",
      "Epoch:685, Train loss: 0.007, Validation loss: 0.718\n",
      "Epoch:686, Train loss: 0.009, Validation loss: 0.705\n",
      "Epoch:687, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:688, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:689, Train loss: 0.007, Validation loss: 0.694\n",
      "Epoch:690, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:691, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:692, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:693, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:694, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:695, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:696, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:697, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:698, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:699, Train loss: 0.009, Validation loss: 0.701\n",
      "Epoch:700, Train loss: 0.008, Validation loss: 0.699\n",
      "Epoch:701, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:702, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:703, Train loss: 0.007, Validation loss: 0.721\n",
      "Epoch:704, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:705, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:706, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:707, Train loss: 0.007, Validation loss: 0.716\n",
      "Epoch:708, Train loss: 0.008, Validation loss: 0.696\n",
      "Epoch:709, Train loss: 0.007, Validation loss: 0.717\n",
      "Epoch:710, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:711, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:712, Train loss: 0.007, Validation loss: 0.694\n",
      "Epoch:713, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:714, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:715, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:716, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:717, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:718, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:719, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:720, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:721, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:722, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:723, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:724, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:725, Train loss: 0.007, Validation loss: 0.688\n",
      "Epoch:726, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:727, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:728, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:729, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:730, Train loss: 0.007, Validation loss: 0.716\n",
      "Epoch:731, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:732, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:733, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:734, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:735, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:736, Train loss: 0.008, Validation loss: 0.698\n",
      "Epoch:737, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:738, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:739, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:740, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:741, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:742, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:743, Train loss: 0.008, Validation loss: 0.700\n",
      "Epoch:744, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:745, Train loss: 0.008, Validation loss: 0.717\n",
      "Epoch:746, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:747, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:748, Train loss: 0.006, Validation loss: 0.699\n",
      "Epoch:749, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:750, Train loss: 0.008, Validation loss: 0.704\n",
      "Epoch:751, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:752, Train loss: 0.008, Validation loss: 0.711\n",
      "Epoch:753, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:754, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:755, Train loss: 0.009, Validation loss: 0.703\n",
      "Epoch:756, Train loss: 0.008, Validation loss: 0.696\n",
      "Epoch:757, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:758, Train loss: 0.008, Validation loss: 0.712\n",
      "Epoch:759, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:760, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:761, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:762, Train loss: 0.009, Validation loss: 0.705\n",
      "Epoch:763, Train loss: 0.008, Validation loss: 0.693\n",
      "Epoch:764, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:765, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:766, Train loss: 0.006, Validation loss: 0.701\n",
      "Epoch:767, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:768, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:769, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:770, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:771, Train loss: 0.008, Validation loss: 0.708\n",
      "Epoch:772, Train loss: 0.007, Validation loss: 0.692\n",
      "Epoch:773, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:774, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:775, Train loss: 0.008, Validation loss: 0.707\n",
      "Epoch:776, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:777, Train loss: 0.006, Validation loss: 0.714\n",
      "Epoch:778, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:779, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:780, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:781, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:782, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:783, Train loss: 0.006, Validation loss: 0.705\n",
      "Epoch:784, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:785, Train loss: 0.007, Validation loss: 0.703\n",
      "Epoch:786, Train loss: 0.008, Validation loss: 0.691\n",
      "Epoch:787, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:788, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:789, Train loss: 0.008, Validation loss: 0.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:790, Train loss: 0.008, Validation loss: 0.715\n",
      "Epoch:791, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:792, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:793, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:794, Train loss: 0.008, Validation loss: 0.712\n",
      "Epoch:795, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:796, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:797, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:798, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:799, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:800, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:801, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:802, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:803, Train loss: 0.007, Validation loss: 0.703\n",
      "Epoch:804, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:805, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:806, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:807, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:808, Train loss: 0.008, Validation loss: 0.709\n",
      "Epoch:809, Train loss: 0.008, Validation loss: 0.713\n",
      "Epoch:810, Train loss: 0.008, Validation loss: 0.694\n",
      "Epoch:811, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:812, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:813, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:814, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:815, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:816, Train loss: 0.007, Validation loss: 0.693\n",
      "Epoch:817, Train loss: 0.007, Validation loss: 0.703\n",
      "Epoch:818, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:819, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:820, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:821, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:822, Train loss: 0.009, Validation loss: 0.706\n",
      "Epoch:823, Train loss: 0.007, Validation loss: 0.694\n",
      "Epoch:824, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:825, Train loss: 0.006, Validation loss: 0.696\n",
      "Epoch:826, Train loss: 0.007, Validation loss: 0.703\n",
      "Epoch:827, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:828, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:829, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:830, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:831, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:832, Train loss: 0.008, Validation loss: 0.698\n",
      "Epoch:833, Train loss: 0.008, Validation loss: 0.706\n",
      "Epoch:834, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:835, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:836, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:837, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:838, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:839, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:840, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:841, Train loss: 0.007, Validation loss: 0.693\n",
      "Epoch:842, Train loss: 0.007, Validation loss: 0.688\n",
      "Epoch:843, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:844, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:845, Train loss: 0.007, Validation loss: 0.713\n",
      "Epoch:846, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:847, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:848, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:849, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:850, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:851, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:852, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:853, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:854, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:855, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:856, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:857, Train loss: 0.007, Validation loss: 0.703\n",
      "Epoch:858, Train loss: 0.006, Validation loss: 0.695\n",
      "Epoch:859, Train loss: 0.008, Validation loss: 0.701\n",
      "Epoch:860, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:861, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:862, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:863, Train loss: 0.007, Validation loss: 0.717\n",
      "Epoch:864, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:865, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:866, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:867, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:868, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:869, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:870, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:871, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:872, Train loss: 0.006, Validation loss: 0.717\n",
      "Epoch:873, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:874, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:875, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:876, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:877, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:878, Train loss: 0.006, Validation loss: 0.706\n",
      "Epoch:879, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:880, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:881, Train loss: 0.007, Validation loss: 0.703\n",
      "Epoch:882, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:883, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:884, Train loss: 0.010, Validation loss: 0.712\n",
      "Epoch:885, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:886, Train loss: 0.007, Validation loss: 0.714\n",
      "Epoch:887, Train loss: 0.006, Validation loss: 0.712\n",
      "Epoch:888, Train loss: 0.007, Validation loss: 0.701\n",
      "Epoch:889, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:890, Train loss: 0.008, Validation loss: 0.719\n",
      "Epoch:891, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:892, Train loss: 0.007, Validation loss: 0.713\n",
      "Epoch:893, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:894, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:895, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:896, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:897, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:898, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:899, Train loss: 0.007, Validation loss: 0.714\n",
      "Epoch:900, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:901, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:902, Train loss: 0.008, Validation loss: 0.695\n",
      "Epoch:903, Train loss: 0.006, Validation loss: 0.706\n",
      "Epoch:904, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:905, Train loss: 0.008, Validation loss: 0.705\n",
      "Epoch:906, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:907, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:908, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:909, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:910, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:911, Train loss: 0.008, Validation loss: 0.714\n",
      "Epoch:912, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:913, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:914, Train loss: 0.008, Validation loss: 0.710\n",
      "Epoch:915, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:916, Train loss: 0.006, Validation loss: 0.713\n",
      "Epoch:917, Train loss: 0.007, Validation loss: 0.715\n",
      "Epoch:918, Train loss: 0.007, Validation loss: 0.689\n",
      "Epoch:919, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:920, Train loss: 0.007, Validation loss: 0.713\n",
      "Epoch:921, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:922, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:923, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:924, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:925, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:926, Train loss: 0.007, Validation loss: 0.708\n",
      "Epoch:927, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:928, Train loss: 0.008, Validation loss: 0.696\n",
      "Epoch:929, Train loss: 0.007, Validation loss: 0.714\n",
      "Epoch:930, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:931, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:932, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:933, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:934, Train loss: 0.006, Validation loss: 0.703\n",
      "Epoch:935, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:936, Train loss: 0.008, Validation loss: 0.695\n",
      "Epoch:937, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:938, Train loss: 0.007, Validation loss: 0.691\n",
      "Epoch:939, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:940, Train loss: 0.008, Validation loss: 0.692\n",
      "Epoch:941, Train loss: 0.007, Validation loss: 0.706\n",
      "Epoch:942, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:943, Train loss: 0.008, Validation loss: 0.702\n",
      "Epoch:944, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:945, Train loss: 0.007, Validation loss: 0.692\n",
      "Epoch:946, Train loss: 0.006, Validation loss: 0.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:947, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:948, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:949, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:950, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:951, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:952, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:953, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:954, Train loss: 0.008, Validation loss: 0.703\n",
      "Epoch:955, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:956, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:957, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:958, Train loss: 0.007, Validation loss: 0.697\n",
      "Epoch:959, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:960, Train loss: 0.007, Validation loss: 0.712\n",
      "Epoch:961, Train loss: 0.006, Validation loss: 0.697\n",
      "Epoch:962, Train loss: 0.008, Validation loss: 0.697\n",
      "Epoch:963, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:964, Train loss: 0.007, Validation loss: 0.707\n",
      "Epoch:965, Train loss: 0.008, Validation loss: 0.718\n",
      "Epoch:966, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:967, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:968, Train loss: 0.006, Validation loss: 0.696\n",
      "Epoch:969, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:970, Train loss: 0.006, Validation loss: 0.700\n",
      "Epoch:971, Train loss: 0.006, Validation loss: 0.705\n",
      "Epoch:972, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:973, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:974, Train loss: 0.007, Validation loss: 0.710\n",
      "Epoch:975, Train loss: 0.007, Validation loss: 0.699\n",
      "Epoch:976, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:977, Train loss: 0.007, Validation loss: 0.691\n",
      "Epoch:978, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:979, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:980, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:981, Train loss: 0.007, Validation loss: 0.705\n",
      "Epoch:982, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:983, Train loss: 0.007, Validation loss: 0.718\n",
      "Epoch:984, Train loss: 0.007, Validation loss: 0.711\n",
      "Epoch:985, Train loss: 0.007, Validation loss: 0.716\n",
      "Epoch:986, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:987, Train loss: 0.006, Validation loss: 0.709\n",
      "Epoch:988, Train loss: 0.007, Validation loss: 0.709\n",
      "Epoch:989, Train loss: 0.007, Validation loss: 0.704\n",
      "Epoch:990, Train loss: 0.010, Validation loss: 0.697\n",
      "Epoch:991, Train loss: 0.007, Validation loss: 0.702\n",
      "Epoch:992, Train loss: 0.007, Validation loss: 0.696\n",
      "Epoch:993, Train loss: 0.007, Validation loss: 0.698\n",
      "Epoch:994, Train loss: 0.006, Validation loss: 0.706\n",
      "Epoch:995, Train loss: 0.007, Validation loss: 0.695\n",
      "Epoch:996, Train loss: 0.007, Validation loss: 0.700\n",
      "Epoch:997, Train loss: 0.006, Validation loss: 0.707\n",
      "Epoch:998, Train loss: 0.006, Validation loss: 0.699\n",
      "Epoch:999, Train loss: 0.008, Validation loss: 0.712\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr = 1e-4, weight_decay=1e-3)\n",
    "loss = nn.MSELoss()\n",
    "epochs =1000\n",
    "curr_loss = 0\n",
    "\n",
    "\n",
    "trai_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    curr_val_loss = 0\n",
    "    curr_train_loss = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        idx, X,y = batch\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(X)\n",
    "        \n",
    "        loss_tr = loss(output.view(-1),y)\n",
    "        loss_tr.backward()\n",
    "        optimizer.step()\n",
    "        curr_train_loss += loss_tr.div(train_batch_size)\n",
    "    trai_loss.append(curr_train_loss.div(len(train_dataloader)).item())\n",
    "    optimizer.zero_grad()\n",
    "                       \n",
    "    \n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        idx,X,y=batch\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(X)\n",
    "        loss_validation = loss(output.view(-1),y)\n",
    "        curr_val_loss += loss_validation.div(val_batch_size)\n",
    "    val_loss.append(curr_val_loss.div(len(val_dataloader)).item())\n",
    "\n",
    "    print(\"Epoch:{0:d}, Train loss: {1:0.3f}, Validation loss: {2:0.3f}\".format(e, curr_train_loss.div(len(train_dataloader)).item(), curr_val_loss.div(len(val_dataloader)).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596ba45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 2.7382290363311768\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "total = 0\n",
    "correct = 0\n",
    "for batch in test_dataloader:\n",
    "    idx, X,y = batch\n",
    "    X,y = X.to(device), y.to(device)\n",
    "    \n",
    "    output = model(X)\n",
    "\n",
    "    curr_loss_test = loss(output.view(-1),y)\n",
    "    test_loss += curr_loss_test.div(test_batch_size)\n",
    "    \n",
    "    total += test_batch_size\n",
    "print('Test Loss : {}'.format(test_loss.div(len(test_dataloader))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20000a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
