{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dceb8134-d872-4fa6-bfe8-ec764e6df0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os,sys, re, time\n",
    "import PIL\n",
    "from PIL import Image as PILImage\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import torchvision\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inline\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1868f044-424c-4d27-b452-b9eac86515fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.13-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 3.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pytz>=2022.5\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[K     |████████████████████████████████| 499 kB 9.3 MB/s eta 0:00:01     |███████████▉                    | 184 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: appdirs>=1.4.4 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from yfinance) (3.4.7)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from yfinance) (1.21.2)\n",
      "Collecting lxml>=4.9.1\n",
      "  Downloading lxml-4.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 10.1 MB/s eta 0:00:01     |████████████████████▍           | 4.5 MB 10.1 MB/s eta 0:00:01     |████████████████████████▎       | 5.4 MB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.3.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting beautifulsoup4>=4.11.1\n",
      "  Downloading beautifulsoup4-4.12.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting html5lib>=1.1\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 15.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.3.0 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from yfinance) (1.3.1)\n",
      "Collecting requests>=2.26\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from cryptography>=3.3.2->yfinance) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.20)\n",
      "Requirement already satisfied: webencodings in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from requests>=2.26->yfinance) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages (from requests>=2.26->yfinance) (2.10)\n",
      "Installing collected packages: soupsieve, pytz, charset-normalizer, requests, multitasking, lxml, html5lib, frozendict, beautifulsoup4, yfinance\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/users/adcy366/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script sample is installed in '/users/adcy366/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed beautifulsoup4-4.12.0 charset-normalizer-3.1.0 frozendict-2.3.6 html5lib-1.1 lxml-4.9.2 multitasking-0.0.11 pytz-2022.7.1 requests-2.28.2 soupsieve-2.4 yfinance-0.2.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dffe9efd-555d-4ac4-baa8-9f8c8e4b74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd27e755-0fb0-4236-8257-1aabed8660ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e8771d-d88d-4150-aa78-ae83db48250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(f'Working on {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef91e914-0365-43ed-8901-afe6a056f689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>30.20</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.04</td>\n",
       "      <td>30.38</td>\n",
       "      <td>12903800</td>\n",
       "      <td>VZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>30.57</td>\n",
       "      <td>31.29</td>\n",
       "      <td>30.45</td>\n",
       "      <td>31.27</td>\n",
       "      <td>31004500</td>\n",
       "      <td>VZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>31.28</td>\n",
       "      <td>31.91</td>\n",
       "      <td>31.22</td>\n",
       "      <td>31.63</td>\n",
       "      <td>20664000</td>\n",
       "      <td>VZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.35</td>\n",
       "      <td>57704300</td>\n",
       "      <td>VZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>31.39</td>\n",
       "      <td>31.52</td>\n",
       "      <td>31.21</td>\n",
       "      <td>31.48</td>\n",
       "      <td>17600000</td>\n",
       "      <td>VZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Open   High    Low  Close    Volume Name  Unnamed: 0\n",
       "0  2006-01-03  30.20  30.47  30.04  30.38  12903800   VZ         NaN\n",
       "1  2006-01-04  30.57  31.29  30.45  31.27  31004500   VZ         NaN\n",
       "2  2006-01-05  31.28  31.91  31.22  31.63  20664000   VZ         NaN\n",
       "3  2006-01-06  31.60  31.60  31.16  31.35  57704300   VZ         NaN\n",
       "4  2006-01-09  31.39  31.52  31.21  31.48  17600000   VZ         NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('time_series_data' + '/*.csv')\n",
    "df = pd.concat((pd.read_csv(file) for file in files), ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e19fc7-96e6-44a6-9bc1-69f018a63b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VZ', 'AXP', 'MMM', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO',\n",
       "       'DIS', 'XOM', 'GE', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD',\n",
       "       'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UTX', 'UNH', 'WMT',\n",
       "       'GOOGL', 'AMZN', 'AABA'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6280a996-e781-4914-9d23-0c90564eaa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08a00760-79c7-4e33-b444-cb3d68c54e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Unnamed: 0'] >= 0]['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee649098-0d4e-4e00-86d5-26e18d5f1b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'The Stock Price of Apple')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "sns.set_style(\"ticks\")\n",
    "temp_df = df[df['Name'] == 'AAPL']\n",
    "sns.lineplot(data=temp_df,x=\"Date\",y='Close',color='firebrick')\n",
    "sns.despine()\n",
    "plt.title(\"The Stock Price of Apple\",size='x-large',color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1867091c-5eb3-43e4-aeaa-bf925913e3b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VZ\n",
      "AXP\n",
      "all\n",
      "JPM\n",
      "GE\n",
      "KO\n",
      "all\n",
      "train\n",
      "AAPL\n",
      "UTX\n",
      "WMT\n",
      "CAT\n",
      "AMZN\n",
      "HD\n",
      "PFE\n",
      "XOM\n",
      "MRK\n",
      "CSCO\n",
      "PG\n",
      "test\n",
      "GS\n",
      "TRV\n",
      "MSFT\n",
      "BA\n",
      "MMM\n",
      "MCD\n",
      "DIS\n",
      "IBM\n",
      "NKE\n",
      "CVX\n",
      "INTC\n",
      "val\n",
      "GOOGL\n",
      "AABA\n",
      "JNJ\n",
      "UNH\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    comp = f.split('/')[1].split('_')[0]\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6aa54f-4c98-4312-b211-e4021b960d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset class for loading a datapooint:\n",
    "class StockData:\n",
    "    def __init__(self,company, directory, data_set, seq_len):\n",
    "        self.company = company\n",
    "        self.data_set = data_set\n",
    "        self.directory = directory\n",
    "        self.seq_len = seq_len\n",
    "        self.files = glob.glob(self.directory + '/*.csv')\n",
    "        self.data = self.load_data(self.company)\n",
    "        \n",
    "        total = self.__len__()\n",
    "        train_idx = 0\n",
    "        test_idx = int(0.7*total)\n",
    "        val_idx = int(0.85*total)\n",
    "        \n",
    "        if self.data_set == 'train':\n",
    "            self.data = self.data[:test_idx]\n",
    "        elif self.data_set == 'test':\n",
    "            self.data = self.data[test_idx:val_idx]\n",
    "        elif self.data_set == 'val':\n",
    "            self.data = self.data[val_idx:]\n",
    "        \n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.data) - self.seq_len\n",
    "        \n",
    "    def load_data(self, company_name):\n",
    "        data_ = []\n",
    "        for file in self.files:\n",
    "            comp_file = file.split('/')[1].split('_')[0]\n",
    "            if comp_file == company_name:\n",
    "                data_.append(pd.read_csv(file))\n",
    "        df = pd.concat(data_, ignore_index = True)\n",
    "        tensor_close = torch.tensor(df['Close'])\n",
    "        return tensor_close\n",
    "        \n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        X = self.data[i:i+self.seq_len].float()\n",
    "        y = self.data[i+self.seq_len].float()\n",
    "        \n",
    "        return (X,y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d608ac9-79f2-4f5a-9cc8-692e05024a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the data loaders:\n",
    "train_batch_size = 512\n",
    "company, directory, data_set, seq_len = 'AAPL', 'time_series_data', 'train', 20\n",
    "train_data = StockData(company, directory, data_set, seq_len)\n",
    "train_dataloader = data.DataLoader(train_data, batch_size = train_batch_size, shuffle=True)\n",
    "\n",
    "test_batch_size = 64\n",
    "company, directory, data_set, seq_len = 'AAPL', 'time_series_data', 'test', 20\n",
    "test_data = StockData(company, directory, data_set, seq_len)\n",
    "test_dataloader = data.DataLoader(test_data, batch_size = test_batch_size, shuffle=False)\n",
    "\n",
    "val_batch_size = 512\n",
    "company, directory, data_set, seq_len = 'AAPL', 'time_series_data', 'val', 20\n",
    "val_data = StockData(company, directory, data_set, seq_len)\n",
    "val_dataloader = data.DataLoader(val_data, batch_size = val_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2372047-36f9-45ef-ab43-cef7cac71d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model:\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,num_inputs):\n",
    "        super(MLP,self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.l1 = nn.Linear(num_inputs, 1024)\n",
    "        self.b = nn.BatchNorm1d(1024)\n",
    "        self.drop1 = nn.Dropout()\n",
    "        self.l2 = nn.Linear(1024,1)\n",
    "        self.drop2 = nn.Dropout()\n",
    "        self.l3 = nn.Linear(512,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.l1(X)\n",
    "        X = self.b(X)\n",
    "        X = self.sigmoid(X)\n",
    "        X = self.drop1(X)\n",
    "        X = self.l2(X)\n",
    "        #X = self.sigmoid(X)\n",
    "        #X = self.drop2(X)\n",
    "        #X = self.l3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53867d91-df53-4060-9acc-a8ca0e8cbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MLP(seq_len).to(device)\n",
    "model.train()\n",
    "lr = 0.00001\n",
    "optimizer = optim.SGD(model.parameters(),lr = lr,weight_decay =1e-3)\n",
    "loss_function = nn.MSELoss()\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a807a87c-79c2-4fc3-a62d-4d182e18071e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 || Train Loss : 4.761617183685303 || Val Loss : 34.13591384887695\n",
      "Epoch : 2 || Train Loss : 4.362814903259277 || Val Loss : 33.622196197509766\n",
      "Epoch : 3 || Train Loss : 3.9608635902404785 || Val Loss : 33.09992218017578\n",
      "Epoch : 4 || Train Loss : 3.923535108566284 || Val Loss : 32.61399459838867\n",
      "Epoch : 5 || Train Loss : 3.7222976684570312 || Val Loss : 32.138797760009766\n",
      "Epoch : 6 || Train Loss : 3.6725997924804688 || Val Loss : 31.672771453857422\n",
      "Epoch : 7 || Train Loss : 3.4245216846466064 || Val Loss : 31.246807098388672\n",
      "Epoch : 8 || Train Loss : 3.2853355407714844 || Val Loss : 30.816661834716797\n",
      "Epoch : 9 || Train Loss : 3.3894524574279785 || Val Loss : 30.383222579956055\n",
      "Epoch : 10 || Train Loss : 2.970057725906372 || Val Loss : 29.985387802124023\n",
      "Epoch : 11 || Train Loss : 3.056398630142212 || Val Loss : 29.6014461517334\n",
      "Epoch : 12 || Train Loss : 2.919832944869995 || Val Loss : 29.21601676940918\n",
      "Epoch : 13 || Train Loss : 2.8992269039154053 || Val Loss : 28.841976165771484\n",
      "Epoch : 14 || Train Loss : 2.761996030807495 || Val Loss : 28.47893524169922\n",
      "Epoch : 15 || Train Loss : 2.4486377239227295 || Val Loss : 28.14790153503418\n",
      "Epoch : 16 || Train Loss : 2.481564998626709 || Val Loss : 27.796836853027344\n",
      "Epoch : 17 || Train Loss : 2.58929443359375 || Val Loss : 27.465423583984375\n",
      "Epoch : 18 || Train Loss : 2.215261220932007 || Val Loss : 27.167211532592773\n",
      "Epoch : 19 || Train Loss : 2.364475727081299 || Val Loss : 26.826618194580078\n",
      "Epoch : 20 || Train Loss : 2.3024418354034424 || Val Loss : 26.51900863647461\n",
      "Epoch : 21 || Train Loss : 1.8975422382354736 || Val Loss : 26.249155044555664\n",
      "Epoch : 22 || Train Loss : 1.9327236413955688 || Val Loss : 25.985897064208984\n",
      "Epoch : 23 || Train Loss : 1.8907142877578735 || Val Loss : 25.72381591796875\n",
      "Epoch : 24 || Train Loss : 1.8808571100234985 || Val Loss : 25.48319435119629\n",
      "Epoch : 25 || Train Loss : 2.0557830333709717 || Val Loss : 25.16645050048828\n",
      "Epoch : 26 || Train Loss : 1.6568883657455444 || Val Loss : 24.92966651916504\n",
      "Epoch : 27 || Train Loss : 1.8843406438827515 || Val Loss : 24.68383026123047\n",
      "Epoch : 28 || Train Loss : 1.7272491455078125 || Val Loss : 24.436771392822266\n",
      "Epoch : 29 || Train Loss : 1.8029394149780273 || Val Loss : 24.224647521972656\n",
      "Epoch : 30 || Train Loss : 1.6461095809936523 || Val Loss : 23.984460830688477\n",
      "Epoch : 31 || Train Loss : 1.5268915891647339 || Val Loss : 23.80158042907715\n",
      "Epoch : 32 || Train Loss : 1.4829269647598267 || Val Loss : 23.58847427368164\n",
      "Epoch : 33 || Train Loss : 1.4569733142852783 || Val Loss : 23.394174575805664\n",
      "Epoch : 34 || Train Loss : 1.3935527801513672 || Val Loss : 23.171388626098633\n",
      "Epoch : 35 || Train Loss : 1.3730483055114746 || Val Loss : 22.936176300048828\n",
      "Epoch : 36 || Train Loss : 1.464848279953003 || Val Loss : 22.794857025146484\n",
      "Epoch : 37 || Train Loss : 1.369176983833313 || Val Loss : 22.58104705810547\n",
      "Epoch : 38 || Train Loss : 1.344333291053772 || Val Loss : 22.40471839904785\n",
      "Epoch : 39 || Train Loss : 1.2339967489242554 || Val Loss : 22.272356033325195\n",
      "Epoch : 40 || Train Loss : 1.2069882154464722 || Val Loss : 22.103107452392578\n",
      "Epoch : 41 || Train Loss : 1.1344431638717651 || Val Loss : 21.94225311279297\n",
      "Epoch : 42 || Train Loss : 1.196820855140686 || Val Loss : 21.78881072998047\n",
      "Epoch : 43 || Train Loss : 1.2015056610107422 || Val Loss : 21.599201202392578\n",
      "Epoch : 44 || Train Loss : 1.0421297550201416 || Val Loss : 21.476280212402344\n",
      "Epoch : 45 || Train Loss : 1.0515676736831665 || Val Loss : 21.363819122314453\n",
      "Epoch : 46 || Train Loss : 0.9856618046760559 || Val Loss : 21.18892478942871\n",
      "Epoch : 47 || Train Loss : 0.9787036180496216 || Val Loss : 21.013051986694336\n",
      "Epoch : 48 || Train Loss : 0.9794921278953552 || Val Loss : 20.911380767822266\n",
      "Epoch : 49 || Train Loss : 1.04570734500885 || Val Loss : 20.78497886657715\n",
      "Epoch : 50 || Train Loss : 0.9592710733413696 || Val Loss : 20.6213321685791\n",
      "Epoch : 51 || Train Loss : 1.004793643951416 || Val Loss : 20.523561477661133\n",
      "Epoch : 52 || Train Loss : 0.9377237558364868 || Val Loss : 20.36253547668457\n",
      "Epoch : 53 || Train Loss : 0.9036247134208679 || Val Loss : 20.236547470092773\n",
      "Epoch : 54 || Train Loss : 0.8734995126724243 || Val Loss : 20.174102783203125\n",
      "Epoch : 55 || Train Loss : 0.9279723167419434 || Val Loss : 20.011837005615234\n",
      "Epoch : 56 || Train Loss : 0.7905638217926025 || Val Loss : 19.945873260498047\n",
      "Epoch : 57 || Train Loss : 0.8018345832824707 || Val Loss : 19.7879695892334\n",
      "Epoch : 58 || Train Loss : 0.894773006439209 || Val Loss : 19.74398422241211\n",
      "Epoch : 59 || Train Loss : 0.7793622612953186 || Val Loss : 19.639114379882812\n",
      "Epoch : 60 || Train Loss : 0.86933833360672 || Val Loss : 19.5189151763916\n",
      "Epoch : 61 || Train Loss : 0.7356358766555786 || Val Loss : 19.438861846923828\n",
      "Epoch : 62 || Train Loss : 0.7565985918045044 || Val Loss : 19.302120208740234\n",
      "Epoch : 63 || Train Loss : 0.7799457907676697 || Val Loss : 19.2541446685791\n",
      "Epoch : 64 || Train Loss : 0.6849051117897034 || Val Loss : 19.2435245513916\n",
      "Epoch : 65 || Train Loss : 0.7687814235687256 || Val Loss : 19.087873458862305\n",
      "Epoch : 66 || Train Loss : 0.7195721864700317 || Val Loss : 19.008956909179688\n",
      "Epoch : 67 || Train Loss : 0.7068002820014954 || Val Loss : 18.92822265625\n",
      "Epoch : 68 || Train Loss : 0.7511403560638428 || Val Loss : 18.86817169189453\n",
      "Epoch : 69 || Train Loss : 0.7254443168640137 || Val Loss : 18.755403518676758\n",
      "Epoch : 70 || Train Loss : 0.6398797631263733 || Val Loss : 18.653884887695312\n",
      "Epoch : 71 || Train Loss : 0.7012588977813721 || Val Loss : 18.575286865234375\n",
      "Epoch : 72 || Train Loss : 0.657881498336792 || Val Loss : 18.49906349182129\n",
      "Epoch : 73 || Train Loss : 0.6552206873893738 || Val Loss : 18.45673179626465\n",
      "Epoch : 74 || Train Loss : 0.6865878105163574 || Val Loss : 18.335134506225586\n",
      "Epoch : 75 || Train Loss : 0.5795390009880066 || Val Loss : 18.308212280273438\n",
      "Epoch : 76 || Train Loss : 0.6723014712333679 || Val Loss : 18.254545211791992\n",
      "Epoch : 77 || Train Loss : 0.5639118552207947 || Val Loss : 18.221546173095703\n",
      "Epoch : 78 || Train Loss : 0.5768512487411499 || Val Loss : 18.12588882446289\n",
      "Epoch : 79 || Train Loss : 0.60917729139328 || Val Loss : 18.061677932739258\n",
      "Epoch : 80 || Train Loss : 0.5762229561805725 || Val Loss : 18.030473709106445\n",
      "Epoch : 81 || Train Loss : 0.5429834723472595 || Val Loss : 18.00542640686035\n",
      "Epoch : 82 || Train Loss : 0.5753136277198792 || Val Loss : 17.898670196533203\n",
      "Epoch : 83 || Train Loss : 0.5876164436340332 || Val Loss : 17.79479217529297\n",
      "Epoch : 84 || Train Loss : 0.5402541160583496 || Val Loss : 17.811479568481445\n",
      "Epoch : 85 || Train Loss : 0.501400351524353 || Val Loss : 17.745363235473633\n",
      "Epoch : 86 || Train Loss : 0.4828365743160248 || Val Loss : 17.688451766967773\n",
      "Epoch : 87 || Train Loss : 0.492534875869751 || Val Loss : 17.740253448486328\n",
      "Epoch : 88 || Train Loss : 0.5656314492225647 || Val Loss : 17.661375045776367\n",
      "Epoch : 89 || Train Loss : 0.5108173489570618 || Val Loss : 17.55571937561035\n",
      "Epoch : 90 || Train Loss : 0.4984012544155121 || Val Loss : 17.53835105895996\n",
      "Epoch : 91 || Train Loss : 0.49335336685180664 || Val Loss : 17.518024444580078\n",
      "Epoch : 92 || Train Loss : 0.4581943154335022 || Val Loss : 17.452011108398438\n",
      "Epoch : 93 || Train Loss : 0.5055946707725525 || Val Loss : 17.412704467773438\n",
      "Epoch : 94 || Train Loss : 0.45469751954078674 || Val Loss : 17.42061424255371\n",
      "Epoch : 95 || Train Loss : 0.5130264163017273 || Val Loss : 17.30481719970703\n",
      "Epoch : 96 || Train Loss : 0.5095677971839905 || Val Loss : 17.28830909729004\n",
      "Epoch : 97 || Train Loss : 0.4664522111415863 || Val Loss : 17.29832649230957\n",
      "Epoch : 98 || Train Loss : 0.489427775144577 || Val Loss : 17.21030616760254\n",
      "Epoch : 99 || Train Loss : 0.48396429419517517 || Val Loss : 17.2244815826416\n",
      "Epoch : 100 || Train Loss : 0.453709214925766 || Val Loss : 17.17812156677246\n",
      "Epoch : 101 || Train Loss : 0.4571797847747803 || Val Loss : 17.13347625732422\n",
      "Epoch : 102 || Train Loss : 0.45416179299354553 || Val Loss : 17.092357635498047\n",
      "Epoch : 103 || Train Loss : 0.4263972342014313 || Val Loss : 17.086711883544922\n",
      "Epoch : 104 || Train Loss : 0.46388980746269226 || Val Loss : 16.978443145751953\n",
      "Epoch : 105 || Train Loss : 0.44599056243896484 || Val Loss : 16.94870948791504\n",
      "Epoch : 106 || Train Loss : 0.4151385426521301 || Val Loss : 17.015371322631836\n",
      "Epoch : 107 || Train Loss : 0.4357844293117523 || Val Loss : 16.942092895507812\n",
      "Epoch : 108 || Train Loss : 0.3849405348300934 || Val Loss : 16.951587677001953\n",
      "Epoch : 109 || Train Loss : 0.447132408618927 || Val Loss : 16.936904907226562\n",
      "Epoch : 110 || Train Loss : 0.41766104102134705 || Val Loss : 16.804590225219727\n",
      "Epoch : 111 || Train Loss : 0.419877827167511 || Val Loss : 16.769495010375977\n",
      "Epoch : 112 || Train Loss : 0.35598382353782654 || Val Loss : 16.74483299255371\n",
      "Epoch : 113 || Train Loss : 0.3841381072998047 || Val Loss : 16.75645637512207\n",
      "Epoch : 114 || Train Loss : 0.37284544110298157 || Val Loss : 16.76338768005371\n",
      "Epoch : 115 || Train Loss : 0.4174319803714752 || Val Loss : 16.693992614746094\n",
      "Epoch : 116 || Train Loss : 0.34936755895614624 || Val Loss : 16.706268310546875\n",
      "Epoch : 117 || Train Loss : 0.34100425243377686 || Val Loss : 16.67279815673828\n",
      "Epoch : 118 || Train Loss : 0.34789416193962097 || Val Loss : 16.62690544128418\n",
      "Epoch : 119 || Train Loss : 0.41210809350013733 || Val Loss : 16.652114868164062\n",
      "Epoch : 120 || Train Loss : 0.3619832992553711 || Val Loss : 16.636369705200195\n",
      "Epoch : 121 || Train Loss : 0.3579755425453186 || Val Loss : 16.533222198486328\n",
      "Epoch : 122 || Train Loss : 0.3349462151527405 || Val Loss : 16.560476303100586\n",
      "Epoch : 123 || Train Loss : 0.36180534958839417 || Val Loss : 16.57491111755371\n",
      "Epoch : 124 || Train Loss : 0.34135791659355164 || Val Loss : 16.50789451599121\n",
      "Epoch : 125 || Train Loss : 0.3443174958229065 || Val Loss : 16.559057235717773\n",
      "Epoch : 126 || Train Loss : 0.3286951780319214 || Val Loss : 16.54395294189453\n",
      "Epoch : 127 || Train Loss : 0.33997994661331177 || Val Loss : 16.469314575195312\n",
      "Epoch : 128 || Train Loss : 0.3742677867412567 || Val Loss : 16.47726058959961\n",
      "Epoch : 129 || Train Loss : 0.32162195444107056 || Val Loss : 16.436138153076172\n",
      "Epoch : 130 || Train Loss : 0.344426691532135 || Val Loss : 16.408477783203125\n",
      "Epoch : 131 || Train Loss : 0.3039902448654175 || Val Loss : 16.461627960205078\n",
      "Epoch : 132 || Train Loss : 0.33384671807289124 || Val Loss : 16.406824111938477\n",
      "Epoch : 133 || Train Loss : 0.32983914017677307 || Val Loss : 16.47031021118164\n",
      "Epoch : 134 || Train Loss : 0.31610366702079773 || Val Loss : 16.411922454833984\n",
      "Epoch : 135 || Train Loss : 0.3287163972854614 || Val Loss : 16.340373992919922\n",
      "Epoch : 136 || Train Loss : 0.29953935742378235 || Val Loss : 16.31574058532715\n",
      "Epoch : 137 || Train Loss : 0.3168034553527832 || Val Loss : 16.288930892944336\n",
      "Epoch : 138 || Train Loss : 0.28051137924194336 || Val Loss : 16.288970947265625\n",
      "Epoch : 139 || Train Loss : 0.308901846408844 || Val Loss : 16.30893898010254\n",
      "Epoch : 140 || Train Loss : 0.32182788848876953 || Val Loss : 16.29682159423828\n",
      "Epoch : 141 || Train Loss : 0.3286890983581543 || Val Loss : 16.317180633544922\n",
      "Epoch : 142 || Train Loss : 0.32461491227149963 || Val Loss : 16.26340675354004\n",
      "Epoch : 143 || Train Loss : 0.31335529685020447 || Val Loss : 16.21669578552246\n",
      "Epoch : 144 || Train Loss : 0.2862687110900879 || Val Loss : 16.29865837097168\n",
      "Epoch : 145 || Train Loss : 0.2670498192310333 || Val Loss : 16.203149795532227\n",
      "Epoch : 146 || Train Loss : 0.2760560214519501 || Val Loss : 16.19502830505371\n",
      "Epoch : 147 || Train Loss : 0.26254430413246155 || Val Loss : 16.182384490966797\n",
      "Epoch : 148 || Train Loss : 0.28244850039482117 || Val Loss : 16.141681671142578\n",
      "Epoch : 149 || Train Loss : 0.27174630761146545 || Val Loss : 16.190603256225586\n",
      "Epoch : 150 || Train Loss : 0.29497742652893066 || Val Loss : 16.13260841369629\n",
      "Epoch : 151 || Train Loss : 0.2651887536048889 || Val Loss : 16.147258758544922\n",
      "Epoch : 152 || Train Loss : 0.2836054265499115 || Val Loss : 16.137704849243164\n",
      "Epoch : 153 || Train Loss : 0.25539320707321167 || Val Loss : 16.140094757080078\n",
      "Epoch : 154 || Train Loss : 0.2976062297821045 || Val Loss : 16.1026554107666\n",
      "Epoch : 155 || Train Loss : 0.2675226628780365 || Val Loss : 16.143882751464844\n",
      "Epoch : 156 || Train Loss : 0.28353333473205566 || Val Loss : 16.076705932617188\n",
      "Epoch : 157 || Train Loss : 0.2840951085090637 || Val Loss : 16.094449996948242\n",
      "Epoch : 158 || Train Loss : 0.2894859313964844 || Val Loss : 16.071544647216797\n",
      "Epoch : 159 || Train Loss : 0.2964515686035156 || Val Loss : 16.09467887878418\n",
      "Epoch : 160 || Train Loss : 0.23260807991027832 || Val Loss : 16.076173782348633\n",
      "Epoch : 161 || Train Loss : 0.23653431236743927 || Val Loss : 16.09092140197754\n",
      "Epoch : 162 || Train Loss : 0.250279039144516 || Val Loss : 16.05902099609375\n",
      "Epoch : 163 || Train Loss : 0.23988187313079834 || Val Loss : 16.056489944458008\n",
      "Epoch : 164 || Train Loss : 0.23807556927204132 || Val Loss : 16.069293975830078\n",
      "Epoch : 165 || Train Loss : 0.26656126976013184 || Val Loss : 16.048206329345703\n",
      "Epoch : 166 || Train Loss : 0.22752197086811066 || Val Loss : 15.980546951293945\n",
      "Epoch : 167 || Train Loss : 0.23015718162059784 || Val Loss : 16.07204818725586\n",
      "Epoch : 168 || Train Loss : 0.2582189738750458 || Val Loss : 16.04837417602539\n",
      "Epoch : 169 || Train Loss : 0.2151898592710495 || Val Loss : 16.004932403564453\n",
      "Epoch : 170 || Train Loss : 0.23014020919799805 || Val Loss : 15.983118057250977\n",
      "Epoch : 171 || Train Loss : 0.21746869385242462 || Val Loss : 16.030437469482422\n",
      "Epoch : 172 || Train Loss : 0.22825632989406586 || Val Loss : 15.996312141418457\n",
      "Epoch : 173 || Train Loss : 0.23593969643115997 || Val Loss : 16.0106258392334\n",
      "Epoch : 174 || Train Loss : 0.24183228611946106 || Val Loss : 15.993561744689941\n",
      "Epoch : 175 || Train Loss : 0.23697571456432343 || Val Loss : 15.956676483154297\n",
      "Epoch : 176 || Train Loss : 0.21811354160308838 || Val Loss : 16.012056350708008\n",
      "Epoch : 177 || Train Loss : 0.21290265023708344 || Val Loss : 15.956270217895508\n",
      "Epoch : 178 || Train Loss : 0.22225873172283173 || Val Loss : 15.923928260803223\n",
      "Epoch : 179 || Train Loss : 0.2144312709569931 || Val Loss : 15.908336639404297\n",
      "Epoch : 180 || Train Loss : 0.19921958446502686 || Val Loss : 15.929999351501465\n",
      "Epoch : 181 || Train Loss : 0.23598681390285492 || Val Loss : 15.952247619628906\n",
      "Epoch : 182 || Train Loss : 0.24077211320400238 || Val Loss : 16.048030853271484\n",
      "Epoch : 183 || Train Loss : 0.23517726361751556 || Val Loss : 15.913742065429688\n",
      "Epoch : 184 || Train Loss : 0.22777371108531952 || Val Loss : 15.888463973999023\n",
      "Epoch : 185 || Train Loss : 0.21139052510261536 || Val Loss : 15.904852867126465\n",
      "Epoch : 186 || Train Loss : 0.18781845271587372 || Val Loss : 15.956167221069336\n",
      "Epoch : 187 || Train Loss : 0.18700475990772247 || Val Loss : 15.92139720916748\n",
      "Epoch : 188 || Train Loss : 0.1775241494178772 || Val Loss : 15.859018325805664\n",
      "Epoch : 189 || Train Loss : 0.19597752392292023 || Val Loss : 15.85197925567627\n",
      "Epoch : 190 || Train Loss : 0.19032959640026093 || Val Loss : 15.894129753112793\n",
      "Epoch : 191 || Train Loss : 0.18725821375846863 || Val Loss : 15.890654563903809\n",
      "Epoch : 192 || Train Loss : 0.1844499707221985 || Val Loss : 15.907999992370605\n",
      "Epoch : 193 || Train Loss : 0.20664763450622559 || Val Loss : 15.885268211364746\n",
      "Epoch : 194 || Train Loss : 0.21389257907867432 || Val Loss : 15.88278865814209\n",
      "Epoch : 195 || Train Loss : 0.19829025864601135 || Val Loss : 15.868345260620117\n",
      "Epoch : 196 || Train Loss : 0.17490117251873016 || Val Loss : 15.931812286376953\n",
      "Epoch : 197 || Train Loss : 0.19007478654384613 || Val Loss : 15.933023452758789\n",
      "Epoch : 198 || Train Loss : 0.19487318396568298 || Val Loss : 15.89052677154541\n",
      "Epoch : 199 || Train Loss : 0.17299918830394745 || Val Loss : 15.975672721862793\n",
      "Epoch : 200 || Train Loss : 0.2160787135362625 || Val Loss : 15.885870933532715\n",
      "Epoch : 201 || Train Loss : 0.2029387503862381 || Val Loss : 15.902704238891602\n",
      "Epoch : 202 || Train Loss : 0.16662482917308807 || Val Loss : 15.89117431640625\n",
      "Epoch : 203 || Train Loss : 0.15873847901821136 || Val Loss : 15.943802833557129\n",
      "Epoch : 204 || Train Loss : 0.1742744892835617 || Val Loss : 15.87526798248291\n",
      "Epoch : 205 || Train Loss : 0.1795445680618286 || Val Loss : 15.907273292541504\n",
      "Epoch : 206 || Train Loss : 0.16961444914340973 || Val Loss : 15.852388381958008\n",
      "Epoch : 207 || Train Loss : 0.17291618883609772 || Val Loss : 15.804831504821777\n",
      "Epoch : 208 || Train Loss : 0.19287951290607452 || Val Loss : 15.87690258026123\n",
      "Epoch : 209 || Train Loss : 0.17535455524921417 || Val Loss : 15.909440040588379\n",
      "Epoch : 210 || Train Loss : 0.1554228514432907 || Val Loss : 15.934175491333008\n",
      "Epoch : 211 || Train Loss : 0.15294016897678375 || Val Loss : 15.92695140838623\n",
      "Epoch : 212 || Train Loss : 0.14935167133808136 || Val Loss : 15.908613204956055\n",
      "Epoch : 213 || Train Loss : 0.17007504403591156 || Val Loss : 15.893646240234375\n",
      "Epoch : 214 || Train Loss : 0.2068639099597931 || Val Loss : 15.861961364746094\n",
      "Epoch : 215 || Train Loss : 0.15010076761245728 || Val Loss : 15.864151954650879\n",
      "Epoch : 216 || Train Loss : 0.17577791213989258 || Val Loss : 15.812393188476562\n",
      "Epoch : 217 || Train Loss : 0.15037213265895844 || Val Loss : 15.812259674072266\n",
      "Epoch : 218 || Train Loss : 0.14667832851409912 || Val Loss : 15.867069244384766\n",
      "Epoch : 219 || Train Loss : 0.15250863134860992 || Val Loss : 15.850056648254395\n",
      "Epoch : 220 || Train Loss : 0.14788199961185455 || Val Loss : 15.93282413482666\n",
      "Epoch : 221 || Train Loss : 0.15693601965904236 || Val Loss : 15.94287109375\n",
      "Epoch : 222 || Train Loss : 0.1442638337612152 || Val Loss : 15.866142272949219\n",
      "Epoch : 223 || Train Loss : 0.15517710149288177 || Val Loss : 15.83082103729248\n",
      "Epoch : 224 || Train Loss : 0.1881168782711029 || Val Loss : 15.886642456054688\n",
      "Epoch : 225 || Train Loss : 0.15948522090911865 || Val Loss : 15.786968231201172\n",
      "Epoch : 226 || Train Loss : 0.2046511024236679 || Val Loss : 15.87232494354248\n",
      "Epoch : 227 || Train Loss : 0.15546859800815582 || Val Loss : 15.831660270690918\n",
      "Epoch : 228 || Train Loss : 0.14040911197662354 || Val Loss : 15.836054801940918\n",
      "Epoch : 229 || Train Loss : 0.12990480661392212 || Val Loss : 15.816240310668945\n",
      "Epoch : 230 || Train Loss : 0.13759279251098633 || Val Loss : 15.792411804199219\n",
      "Epoch : 231 || Train Loss : 0.1438303291797638 || Val Loss : 15.787483215332031\n",
      "Epoch : 232 || Train Loss : 0.14747847616672516 || Val Loss : 15.870240211486816\n",
      "Epoch : 233 || Train Loss : 0.14394740760326385 || Val Loss : 15.888195991516113\n",
      "Epoch : 234 || Train Loss : 0.13190056383609772 || Val Loss : 15.796977043151855\n",
      "Epoch : 235 || Train Loss : 0.13784436881542206 || Val Loss : 15.826595306396484\n",
      "Epoch : 236 || Train Loss : 0.13560786843299866 || Val Loss : 15.790417671203613\n",
      "Epoch : 237 || Train Loss : 0.14845353364944458 || Val Loss : 15.832595825195312\n",
      "Epoch : 238 || Train Loss : 0.14315925538539886 || Val Loss : 15.782992362976074\n",
      "Epoch : 239 || Train Loss : 0.12984256446361542 || Val Loss : 15.793669700622559\n",
      "Epoch : 240 || Train Loss : 0.14530342817306519 || Val Loss : 15.877419471740723\n",
      "Epoch : 241 || Train Loss : 0.1283608078956604 || Val Loss : 15.811836242675781\n",
      "Epoch : 242 || Train Loss : 0.13646046817302704 || Val Loss : 15.843997955322266\n",
      "Epoch : 243 || Train Loss : 0.12371539324522018 || Val Loss : 15.842635154724121\n",
      "Epoch : 244 || Train Loss : 0.13496993482112885 || Val Loss : 15.836109161376953\n",
      "Epoch : 245 || Train Loss : 0.13333576917648315 || Val Loss : 15.760358810424805\n",
      "Epoch : 246 || Train Loss : 0.12493892014026642 || Val Loss : 15.794266700744629\n",
      "Epoch : 247 || Train Loss : 0.1356809139251709 || Val Loss : 15.826869010925293\n",
      "Epoch : 248 || Train Loss : 0.1266552358865738 || Val Loss : 15.854924201965332\n",
      "Epoch : 249 || Train Loss : 0.139543816447258 || Val Loss : 15.79239273071289\n",
      "Epoch : 250 || Train Loss : 0.11690393835306168 || Val Loss : 15.798174858093262\n",
      "Epoch : 251 || Train Loss : 0.1303582489490509 || Val Loss : 15.770172119140625\n",
      "Epoch : 252 || Train Loss : 0.11813425272703171 || Val Loss : 15.801304817199707\n",
      "Epoch : 253 || Train Loss : 0.11937816441059113 || Val Loss : 15.804340362548828\n",
      "Epoch : 254 || Train Loss : 0.12333416938781738 || Val Loss : 15.776698112487793\n",
      "Epoch : 255 || Train Loss : 0.1227930411696434 || Val Loss : 15.746295928955078\n",
      "Epoch : 256 || Train Loss : 0.12154443562030792 || Val Loss : 15.743509292602539\n",
      "Epoch : 257 || Train Loss : 0.16429749131202698 || Val Loss : 15.782673835754395\n",
      "Epoch : 258 || Train Loss : 0.10201574862003326 || Val Loss : 15.766613006591797\n",
      "Epoch : 259 || Train Loss : 0.12372207641601562 || Val Loss : 15.764267921447754\n",
      "Epoch : 260 || Train Loss : 0.11993038654327393 || Val Loss : 15.721616744995117\n",
      "Epoch : 261 || Train Loss : 0.1201268658041954 || Val Loss : 15.785076141357422\n",
      "Epoch : 262 || Train Loss : 0.11932659149169922 || Val Loss : 15.695000648498535\n",
      "Epoch : 263 || Train Loss : 0.11405322700738907 || Val Loss : 15.781349182128906\n",
      "Epoch : 264 || Train Loss : 0.10280698537826538 || Val Loss : 15.834427833557129\n",
      "Epoch : 265 || Train Loss : 0.09439884126186371 || Val Loss : 15.854314804077148\n",
      "Epoch : 266 || Train Loss : 0.10850923508405685 || Val Loss : 15.774093627929688\n",
      "Epoch : 267 || Train Loss : 0.11896312236785889 || Val Loss : 15.80853271484375\n",
      "Epoch : 268 || Train Loss : 0.10439453274011612 || Val Loss : 15.767993927001953\n",
      "Epoch : 269 || Train Loss : 0.10253254324197769 || Val Loss : 15.807576179504395\n",
      "Epoch : 270 || Train Loss : 0.1105145812034607 || Val Loss : 15.774983406066895\n",
      "Epoch : 271 || Train Loss : 0.10246652364730835 || Val Loss : 15.787046432495117\n",
      "Epoch : 272 || Train Loss : 0.10164693742990494 || Val Loss : 15.721341133117676\n",
      "Epoch : 273 || Train Loss : 0.10782139748334885 || Val Loss : 15.7877197265625\n",
      "Epoch : 274 || Train Loss : 0.10299606621265411 || Val Loss : 15.75085735321045\n",
      "Epoch : 275 || Train Loss : 0.10975857824087143 || Val Loss : 15.7701416015625\n",
      "Epoch : 276 || Train Loss : 0.10520179569721222 || Val Loss : 15.747693061828613\n",
      "Epoch : 277 || Train Loss : 0.10672350972890854 || Val Loss : 15.766426086425781\n",
      "Epoch : 278 || Train Loss : 0.15083733201026917 || Val Loss : 15.747391700744629\n",
      "Epoch : 279 || Train Loss : 0.09086205810308456 || Val Loss : 15.714315414428711\n",
      "Epoch : 280 || Train Loss : 0.10363259166479111 || Val Loss : 15.806330680847168\n",
      "Epoch : 281 || Train Loss : 0.09214083850383759 || Val Loss : 15.75381088256836\n",
      "Epoch : 282 || Train Loss : 0.10751434415578842 || Val Loss : 15.764047622680664\n",
      "Epoch : 283 || Train Loss : 0.09041757136583328 || Val Loss : 15.760225296020508\n",
      "Epoch : 284 || Train Loss : 0.09079017490148544 || Val Loss : 15.762557983398438\n",
      "Epoch : 285 || Train Loss : 0.11133205890655518 || Val Loss : 15.748175621032715\n",
      "Epoch : 286 || Train Loss : 0.09124734252691269 || Val Loss : 15.780963897705078\n",
      "Epoch : 287 || Train Loss : 0.1004997044801712 || Val Loss : 15.701687812805176\n",
      "Epoch : 288 || Train Loss : 0.09318745136260986 || Val Loss : 15.739211082458496\n",
      "Epoch : 289 || Train Loss : 0.10541713237762451 || Val Loss : 15.73913860321045\n",
      "Epoch : 290 || Train Loss : 0.09375070780515671 || Val Loss : 15.750503540039062\n",
      "Epoch : 291 || Train Loss : 0.08201222866773605 || Val Loss : 15.802005767822266\n",
      "Epoch : 292 || Train Loss : 0.10375668108463287 || Val Loss : 15.795408248901367\n",
      "Epoch : 293 || Train Loss : 0.09008611738681793 || Val Loss : 15.767899513244629\n",
      "Epoch : 294 || Train Loss : 0.08399259299039841 || Val Loss : 15.778587341308594\n",
      "Epoch : 295 || Train Loss : 0.08649343252182007 || Val Loss : 15.753527641296387\n",
      "Epoch : 296 || Train Loss : 0.08719935268163681 || Val Loss : 15.796103477478027\n",
      "Epoch : 297 || Train Loss : 0.09809901565313339 || Val Loss : 15.7879638671875\n",
      "Epoch : 298 || Train Loss : 0.09245777875185013 || Val Loss : 15.785102844238281\n",
      "Epoch : 299 || Train Loss : 0.08894633501768112 || Val Loss : 15.746830940246582\n",
      "Epoch : 300 || Train Loss : 0.08086024969816208 || Val Loss : 15.76506233215332\n",
      "Epoch : 301 || Train Loss : 0.09814143180847168 || Val Loss : 15.847288131713867\n",
      "Epoch : 302 || Train Loss : 0.08468516916036606 || Val Loss : 15.824885368347168\n",
      "Epoch : 303 || Train Loss : 0.0751916915178299 || Val Loss : 15.734006881713867\n",
      "Epoch : 304 || Train Loss : 0.09525544196367264 || Val Loss : 15.820408821105957\n",
      "Epoch : 305 || Train Loss : 0.08395126461982727 || Val Loss : 15.794538497924805\n",
      "Epoch : 306 || Train Loss : 0.07364385575056076 || Val Loss : 15.80716609954834\n",
      "Epoch : 307 || Train Loss : 0.07549245655536652 || Val Loss : 15.796841621398926\n",
      "Epoch : 308 || Train Loss : 0.08329575508832932 || Val Loss : 15.810698509216309\n",
      "Epoch : 309 || Train Loss : 0.0919637456536293 || Val Loss : 15.808841705322266\n",
      "Epoch : 310 || Train Loss : 0.07344275712966919 || Val Loss : 15.794036865234375\n",
      "Epoch : 311 || Train Loss : 0.07068543136119843 || Val Loss : 15.773368835449219\n",
      "Epoch : 312 || Train Loss : 0.08400332927703857 || Val Loss : 15.765483856201172\n",
      "Epoch : 313 || Train Loss : 0.09928614646196365 || Val Loss : 15.773031234741211\n",
      "Epoch : 314 || Train Loss : 0.07526104897260666 || Val Loss : 15.792628288269043\n",
      "Epoch : 315 || Train Loss : 0.07239212840795517 || Val Loss : 15.681892395019531\n",
      "Epoch : 316 || Train Loss : 0.07903840392827988 || Val Loss : 15.814513206481934\n",
      "Epoch : 317 || Train Loss : 0.08463918417692184 || Val Loss : 15.735594749450684\n",
      "Epoch : 318 || Train Loss : 0.09614972025156021 || Val Loss : 15.716504096984863\n",
      "Epoch : 319 || Train Loss : 0.09710171073675156 || Val Loss : 15.765024185180664\n",
      "Epoch : 320 || Train Loss : 0.07089919596910477 || Val Loss : 15.712984085083008\n",
      "Epoch : 321 || Train Loss : 0.09478707611560822 || Val Loss : 15.888713836669922\n",
      "Epoch : 322 || Train Loss : 0.06819244474172592 || Val Loss : 15.74828052520752\n",
      "Epoch : 323 || Train Loss : 0.0810481533408165 || Val Loss : 15.747004508972168\n",
      "Epoch : 324 || Train Loss : 0.08592675626277924 || Val Loss : 15.754117012023926\n",
      "Epoch : 325 || Train Loss : 0.06864943355321884 || Val Loss : 15.752333641052246\n",
      "Epoch : 326 || Train Loss : 0.08611011505126953 || Val Loss : 15.783529281616211\n",
      "Epoch : 327 || Train Loss : 0.08403132855892181 || Val Loss : 15.743885040283203\n",
      "Epoch : 328 || Train Loss : 0.07105298340320587 || Val Loss : 15.738027572631836\n",
      "Epoch : 329 || Train Loss : 0.095391646027565 || Val Loss : 15.780097961425781\n",
      "Epoch : 330 || Train Loss : 0.07165303081274033 || Val Loss : 15.736621856689453\n",
      "Epoch : 331 || Train Loss : 0.06935588270425797 || Val Loss : 15.756643295288086\n",
      "Epoch : 332 || Train Loss : 0.08730382472276688 || Val Loss : 15.735361099243164\n",
      "Epoch : 333 || Train Loss : 0.08089543879032135 || Val Loss : 15.754023551940918\n",
      "Epoch : 334 || Train Loss : 0.06574124842882156 || Val Loss : 15.722643852233887\n",
      "Epoch : 335 || Train Loss : 0.08223136514425278 || Val Loss : 15.723677635192871\n",
      "Epoch : 336 || Train Loss : 0.08033622801303864 || Val Loss : 15.774833679199219\n",
      "Epoch : 337 || Train Loss : 0.0629982277750969 || Val Loss : 15.780367851257324\n",
      "Epoch : 338 || Train Loss : 0.062078844755887985 || Val Loss : 15.721023559570312\n",
      "Epoch : 339 || Train Loss : 0.06726591289043427 || Val Loss : 15.682028770446777\n",
      "Epoch : 340 || Train Loss : 0.08122079819440842 || Val Loss : 15.715886116027832\n",
      "Epoch : 341 || Train Loss : 0.06976857781410217 || Val Loss : 15.718276977539062\n",
      "Epoch : 342 || Train Loss : 0.07627739757299423 || Val Loss : 15.726604461669922\n",
      "Epoch : 343 || Train Loss : 0.06956980377435684 || Val Loss : 15.69951057434082\n",
      "Epoch : 344 || Train Loss : 0.06478651612997055 || Val Loss : 15.683382987976074\n",
      "Epoch : 345 || Train Loss : 0.06903969496488571 || Val Loss : 15.688301086425781\n",
      "Epoch : 346 || Train Loss : 0.06351892650127411 || Val Loss : 15.747438430786133\n",
      "Epoch : 347 || Train Loss : 0.06549986451864243 || Val Loss : 15.759251594543457\n",
      "Epoch : 348 || Train Loss : 0.06733522564172745 || Val Loss : 15.71601390838623\n",
      "Epoch : 349 || Train Loss : 0.06696180254220963 || Val Loss : 15.755082130432129\n",
      "Epoch : 350 || Train Loss : 0.05987318232655525 || Val Loss : 15.758702278137207\n",
      "Epoch : 351 || Train Loss : 0.06235141307115555 || Val Loss : 15.712579727172852\n",
      "Epoch : 352 || Train Loss : 0.07281678169965744 || Val Loss : 15.772290229797363\n",
      "Epoch : 353 || Train Loss : 0.07005813717842102 || Val Loss : 15.760859489440918\n",
      "Epoch : 354 || Train Loss : 0.06797317415475845 || Val Loss : 15.763764381408691\n",
      "Epoch : 355 || Train Loss : 0.07073159515857697 || Val Loss : 15.757570266723633\n",
      "Epoch : 356 || Train Loss : 0.06607548147439957 || Val Loss : 15.677539825439453\n",
      "Epoch : 357 || Train Loss : 0.06526836007833481 || Val Loss : 15.773618698120117\n",
      "Epoch : 358 || Train Loss : 0.06821062415838242 || Val Loss : 15.827516555786133\n",
      "Epoch : 359 || Train Loss : 0.05890210345387459 || Val Loss : 15.759414672851562\n",
      "Epoch : 360 || Train Loss : 0.07102840393781662 || Val Loss : 15.781957626342773\n",
      "Epoch : 361 || Train Loss : 0.06246614083647728 || Val Loss : 15.77495002746582\n",
      "Epoch : 362 || Train Loss : 0.05836779996752739 || Val Loss : 15.71766185760498\n",
      "Epoch : 363 || Train Loss : 0.06938552856445312 || Val Loss : 15.752760887145996\n",
      "Epoch : 364 || Train Loss : 0.06631758064031601 || Val Loss : 15.791387557983398\n",
      "Epoch : 365 || Train Loss : 0.055362071841955185 || Val Loss : 15.784934043884277\n",
      "Epoch : 366 || Train Loss : 0.06637313961982727 || Val Loss : 15.763246536254883\n",
      "Epoch : 367 || Train Loss : 0.060064222663640976 || Val Loss : 15.795794486999512\n",
      "Epoch : 368 || Train Loss : 0.055775295943021774 || Val Loss : 15.834303855895996\n",
      "Epoch : 369 || Train Loss : 0.060594189912080765 || Val Loss : 15.815521240234375\n",
      "Epoch : 370 || Train Loss : 0.05757954344153404 || Val Loss : 15.830408096313477\n",
      "Epoch : 371 || Train Loss : 0.05486496910452843 || Val Loss : 15.77204418182373\n",
      "Epoch : 372 || Train Loss : 0.06067776679992676 || Val Loss : 15.719021797180176\n",
      "Epoch : 373 || Train Loss : 0.06221281364560127 || Val Loss : 15.840740203857422\n",
      "Epoch : 374 || Train Loss : 0.07129092514514923 || Val Loss : 15.835137367248535\n",
      "Epoch : 375 || Train Loss : 0.05971661955118179 || Val Loss : 15.804874420166016\n",
      "Epoch : 376 || Train Loss : 0.052243638783693314 || Val Loss : 15.79577922821045\n",
      "Epoch : 377 || Train Loss : 0.06727977842092514 || Val Loss : 15.791584968566895\n",
      "Epoch : 378 || Train Loss : 0.05399313196539879 || Val Loss : 15.82232666015625\n",
      "Epoch : 379 || Train Loss : 0.053145237267017365 || Val Loss : 15.88044261932373\n",
      "Epoch : 380 || Train Loss : 0.08439701050519943 || Val Loss : 15.76374626159668\n",
      "Epoch : 381 || Train Loss : 0.06375075876712799 || Val Loss : 15.796814918518066\n",
      "Epoch : 382 || Train Loss : 0.06737091392278671 || Val Loss : 15.798776626586914\n",
      "Epoch : 383 || Train Loss : 0.06592720001935959 || Val Loss : 15.822855949401855\n",
      "Epoch : 384 || Train Loss : 0.05693181976675987 || Val Loss : 15.889360427856445\n",
      "Epoch : 385 || Train Loss : 0.07704833894968033 || Val Loss : 15.798763275146484\n",
      "Epoch : 386 || Train Loss : 0.05376293882727623 || Val Loss : 15.869421005249023\n",
      "Epoch : 387 || Train Loss : 0.06422675400972366 || Val Loss : 15.82257080078125\n",
      "Epoch : 388 || Train Loss : 0.07847228646278381 || Val Loss : 15.826486587524414\n",
      "Epoch : 389 || Train Loss : 0.04754532128572464 || Val Loss : 15.822610855102539\n",
      "Epoch : 390 || Train Loss : 0.04909618943929672 || Val Loss : 15.823203086853027\n",
      "Epoch : 391 || Train Loss : 0.04951123520731926 || Val Loss : 15.853036880493164\n",
      "Epoch : 392 || Train Loss : 0.04994061961770058 || Val Loss : 15.830474853515625\n",
      "Epoch : 393 || Train Loss : 0.05554179102182388 || Val Loss : 15.870749473571777\n",
      "Epoch : 394 || Train Loss : 0.050970204174518585 || Val Loss : 15.835464477539062\n",
      "Epoch : 395 || Train Loss : 0.052904076874256134 || Val Loss : 15.829924583435059\n",
      "Epoch : 396 || Train Loss : 0.05303629860281944 || Val Loss : 15.855814933776855\n",
      "Epoch : 397 || Train Loss : 0.04707090184092522 || Val Loss : 15.813309669494629\n",
      "Epoch : 398 || Train Loss : 0.06615910679101944 || Val Loss : 15.855916023254395\n",
      "Epoch : 399 || Train Loss : 0.04392088204622269 || Val Loss : 15.792267799377441\n",
      "Epoch : 400 || Train Loss : 0.04414600506424904 || Val Loss : 15.792919158935547\n",
      "Epoch : 401 || Train Loss : 0.052239175885915756 || Val Loss : 15.803492546081543\n",
      "Epoch : 402 || Train Loss : 0.06874673813581467 || Val Loss : 15.856402397155762\n",
      "Epoch : 403 || Train Loss : 0.07503160089254379 || Val Loss : 15.763839721679688\n",
      "Epoch : 404 || Train Loss : 0.048709675669670105 || Val Loss : 15.772744178771973\n",
      "Epoch : 405 || Train Loss : 0.0482797808945179 || Val Loss : 15.833529472351074\n",
      "Epoch : 406 || Train Loss : 0.06766390055418015 || Val Loss : 15.763790130615234\n",
      "Epoch : 407 || Train Loss : 0.04582470282912254 || Val Loss : 15.843696594238281\n",
      "Epoch : 408 || Train Loss : 0.0637846514582634 || Val Loss : 15.82041072845459\n",
      "Epoch : 409 || Train Loss : 0.049717530608177185 || Val Loss : 15.830031394958496\n",
      "Epoch : 410 || Train Loss : 0.04067583009600639 || Val Loss : 15.779614448547363\n",
      "Epoch : 411 || Train Loss : 0.0475396029651165 || Val Loss : 15.805656433105469\n",
      "Epoch : 412 || Train Loss : 0.07935738563537598 || Val Loss : 15.878015518188477\n",
      "Epoch : 413 || Train Loss : 0.04754099249839783 || Val Loss : 15.804991722106934\n",
      "Epoch : 414 || Train Loss : 0.04739539697766304 || Val Loss : 15.825920104980469\n",
      "Epoch : 415 || Train Loss : 0.05480460077524185 || Val Loss : 15.930713653564453\n",
      "Epoch : 416 || Train Loss : 0.0424630343914032 || Val Loss : 15.847346305847168\n",
      "Epoch : 417 || Train Loss : 0.046666938811540604 || Val Loss : 15.814184188842773\n",
      "Epoch : 418 || Train Loss : 0.05101725459098816 || Val Loss : 15.786155700683594\n",
      "Epoch : 419 || Train Loss : 0.054993629455566406 || Val Loss : 15.838973999023438\n",
      "Epoch : 420 || Train Loss : 0.04790693148970604 || Val Loss : 15.741339683532715\n",
      "Epoch : 421 || Train Loss : 0.04559607058763504 || Val Loss : 15.813287734985352\n",
      "Epoch : 422 || Train Loss : 0.05266658216714859 || Val Loss : 15.812309265136719\n",
      "Epoch : 423 || Train Loss : 0.04423631355166435 || Val Loss : 15.790017127990723\n",
      "Epoch : 424 || Train Loss : 0.06105530261993408 || Val Loss : 15.879223823547363\n",
      "Epoch : 425 || Train Loss : 0.04849860817193985 || Val Loss : 15.824308395385742\n",
      "Epoch : 426 || Train Loss : 0.04586448892951012 || Val Loss : 15.785736083984375\n",
      "Epoch : 427 || Train Loss : 0.04737742617726326 || Val Loss : 15.832799911499023\n",
      "Epoch : 428 || Train Loss : 0.04380742833018303 || Val Loss : 15.788352966308594\n",
      "Epoch : 429 || Train Loss : 0.050640176981687546 || Val Loss : 15.838528633117676\n",
      "Epoch : 430 || Train Loss : 0.04634151607751846 || Val Loss : 15.761606216430664\n",
      "Epoch : 431 || Train Loss : 0.053188979625701904 || Val Loss : 15.783014297485352\n",
      "Epoch : 432 || Train Loss : 0.044560156762599945 || Val Loss : 15.808365821838379\n",
      "Epoch : 433 || Train Loss : 0.05280753970146179 || Val Loss : 15.81760025024414\n",
      "Epoch : 434 || Train Loss : 0.045687660574913025 || Val Loss : 15.808126449584961\n",
      "Epoch : 435 || Train Loss : 0.05208885669708252 || Val Loss : 15.889989852905273\n",
      "Epoch : 436 || Train Loss : 0.04956129193305969 || Val Loss : 15.803628921508789\n",
      "Epoch : 437 || Train Loss : 0.03869106248021126 || Val Loss : 15.913971900939941\n",
      "Epoch : 438 || Train Loss : 0.03601900488138199 || Val Loss : 15.845107078552246\n",
      "Epoch : 439 || Train Loss : 0.05367076396942139 || Val Loss : 15.815114974975586\n",
      "Epoch : 440 || Train Loss : 0.04071520268917084 || Val Loss : 15.845193862915039\n",
      "Epoch : 441 || Train Loss : 0.04734211042523384 || Val Loss : 15.876937866210938\n",
      "Epoch : 442 || Train Loss : 0.04894018545746803 || Val Loss : 15.818222045898438\n",
      "Epoch : 443 || Train Loss : 0.044120486825704575 || Val Loss : 15.849833488464355\n",
      "Epoch : 444 || Train Loss : 0.044428568333387375 || Val Loss : 15.9041748046875\n",
      "Epoch : 445 || Train Loss : 0.05122761055827141 || Val Loss : 15.871041297912598\n",
      "Epoch : 446 || Train Loss : 0.057339709252119064 || Val Loss : 15.861838340759277\n",
      "Epoch : 447 || Train Loss : 0.042994942516088486 || Val Loss : 15.834057807922363\n",
      "Epoch : 448 || Train Loss : 0.03700026497244835 || Val Loss : 15.849836349487305\n",
      "Epoch : 449 || Train Loss : 0.04128878191113472 || Val Loss : 15.823841094970703\n",
      "Epoch : 450 || Train Loss : 0.04229756444692612 || Val Loss : 15.811901092529297\n",
      "Epoch : 451 || Train Loss : 0.036146149039268494 || Val Loss : 15.823883056640625\n",
      "Epoch : 452 || Train Loss : 0.04096553102135658 || Val Loss : 15.840728759765625\n",
      "Epoch : 453 || Train Loss : 0.04205366596579552 || Val Loss : 15.81637191772461\n",
      "Epoch : 454 || Train Loss : 0.039302341639995575 || Val Loss : 15.826006889343262\n",
      "Epoch : 455 || Train Loss : 0.03936382010579109 || Val Loss : 15.862832069396973\n",
      "Epoch : 456 || Train Loss : 0.05151890590786934 || Val Loss : 15.852285385131836\n",
      "Epoch : 457 || Train Loss : 0.053370267152786255 || Val Loss : 15.816278457641602\n",
      "Epoch : 458 || Train Loss : 0.03552616760134697 || Val Loss : 15.888653755187988\n",
      "Epoch : 459 || Train Loss : 0.05867034196853638 || Val Loss : 15.767533302307129\n",
      "Epoch : 460 || Train Loss : 0.04161665961146355 || Val Loss : 15.771810531616211\n",
      "Epoch : 461 || Train Loss : 0.04460529237985611 || Val Loss : 15.809013366699219\n",
      "Epoch : 462 || Train Loss : 0.033145055174827576 || Val Loss : 15.791871070861816\n",
      "Epoch : 463 || Train Loss : 0.0587623231112957 || Val Loss : 15.850998878479004\n",
      "Epoch : 464 || Train Loss : 0.04050672799348831 || Val Loss : 15.784997940063477\n",
      "Epoch : 465 || Train Loss : 0.04366534948348999 || Val Loss : 15.838622093200684\n",
      "Epoch : 466 || Train Loss : 0.042373597621917725 || Val Loss : 15.798194885253906\n",
      "Epoch : 467 || Train Loss : 0.03584834560751915 || Val Loss : 15.814190864562988\n",
      "Epoch : 468 || Train Loss : 0.04702199250459671 || Val Loss : 15.811887741088867\n",
      "Epoch : 469 || Train Loss : 0.04413481429219246 || Val Loss : 15.822693824768066\n",
      "Epoch : 470 || Train Loss : 0.04771712049841881 || Val Loss : 15.864045143127441\n",
      "Epoch : 471 || Train Loss : 0.0418318472802639 || Val Loss : 15.792856216430664\n",
      "Epoch : 472 || Train Loss : 0.043559860438108444 || Val Loss : 15.80215835571289\n",
      "Epoch : 473 || Train Loss : 0.04709392413496971 || Val Loss : 15.80567741394043\n",
      "Epoch : 474 || Train Loss : 0.037438586354255676 || Val Loss : 15.871782302856445\n",
      "Epoch : 475 || Train Loss : 0.041269488632678986 || Val Loss : 15.742098808288574\n",
      "Epoch : 476 || Train Loss : 0.0560014434158802 || Val Loss : 15.816597938537598\n",
      "Epoch : 477 || Train Loss : 0.04083624482154846 || Val Loss : 15.783381462097168\n",
      "Epoch : 478 || Train Loss : 0.03514763340353966 || Val Loss : 15.889933586120605\n",
      "Epoch : 479 || Train Loss : 0.03796558827161789 || Val Loss : 15.757543563842773\n",
      "Epoch : 480 || Train Loss : 0.04185736924409866 || Val Loss : 15.758121490478516\n",
      "Epoch : 481 || Train Loss : 0.04678124934434891 || Val Loss : 15.822346687316895\n",
      "Epoch : 482 || Train Loss : 0.07212813198566437 || Val Loss : 15.851631164550781\n",
      "Epoch : 483 || Train Loss : 0.038641899824142456 || Val Loss : 15.842281341552734\n",
      "Epoch : 484 || Train Loss : 0.034931641072034836 || Val Loss : 15.801553726196289\n",
      "Epoch : 485 || Train Loss : 0.04007420688867569 || Val Loss : 15.872177124023438\n",
      "Epoch : 486 || Train Loss : 0.03173274174332619 || Val Loss : 15.811403274536133\n",
      "Epoch : 487 || Train Loss : 0.044825922697782516 || Val Loss : 15.820097923278809\n",
      "Epoch : 488 || Train Loss : 0.03975458815693855 || Val Loss : 15.805132865905762\n",
      "Epoch : 489 || Train Loss : 0.05188218504190445 || Val Loss : 15.838500022888184\n",
      "Epoch : 490 || Train Loss : 0.037119198590517044 || Val Loss : 15.788888931274414\n",
      "Epoch : 491 || Train Loss : 0.0611729621887207 || Val Loss : 15.772331237792969\n",
      "Epoch : 492 || Train Loss : 0.042386244982481 || Val Loss : 15.79004192352295\n",
      "Epoch : 493 || Train Loss : 0.0344383530318737 || Val Loss : 15.827751159667969\n",
      "Epoch : 494 || Train Loss : 0.03640693053603172 || Val Loss : 15.820351600646973\n",
      "Epoch : 495 || Train Loss : 0.0418749637901783 || Val Loss : 15.865824699401855\n",
      "Epoch : 496 || Train Loss : 0.041062477976083755 || Val Loss : 15.842206001281738\n",
      "Epoch : 497 || Train Loss : 0.05438491329550743 || Val Loss : 15.802385330200195\n",
      "Epoch : 498 || Train Loss : 0.047838542610406876 || Val Loss : 15.811227798461914\n",
      "Epoch : 499 || Train Loss : 0.07663517445325851 || Val Loss : 15.892899513244629\n",
      "Epoch : 500 || Train Loss : 0.05248798057436943 || Val Loss : 15.791341781616211\n",
      "Epoch : 501 || Train Loss : 0.03662647306919098 || Val Loss : 15.7978515625\n",
      "Epoch : 502 || Train Loss : 0.04955735802650452 || Val Loss : 15.793014526367188\n",
      "Epoch : 503 || Train Loss : 0.03259774297475815 || Val Loss : 15.793831825256348\n",
      "Epoch : 504 || Train Loss : 0.030953479930758476 || Val Loss : 15.854912757873535\n",
      "Epoch : 505 || Train Loss : 0.03195495903491974 || Val Loss : 15.76954174041748\n",
      "Epoch : 506 || Train Loss : 0.03365909308195114 || Val Loss : 15.814863204956055\n",
      "Epoch : 507 || Train Loss : 0.03635406121611595 || Val Loss : 15.834519386291504\n",
      "Epoch : 508 || Train Loss : 0.09037607163190842 || Val Loss : 15.815666198730469\n",
      "Epoch : 509 || Train Loss : 0.04804399237036705 || Val Loss : 15.833359718322754\n",
      "Epoch : 510 || Train Loss : 0.04282207041978836 || Val Loss : 15.873425483703613\n",
      "Epoch : 511 || Train Loss : 0.03455978259444237 || Val Loss : 15.819194793701172\n",
      "Epoch : 512 || Train Loss : 0.03644358739256859 || Val Loss : 15.816606521606445\n",
      "Epoch : 513 || Train Loss : 0.036213625222444534 || Val Loss : 15.89531421661377\n",
      "Epoch : 514 || Train Loss : 0.04275663569569588 || Val Loss : 15.86927318572998\n",
      "Epoch : 515 || Train Loss : 0.07937158644199371 || Val Loss : 15.773323059082031\n",
      "Epoch : 516 || Train Loss : 0.04284602776169777 || Val Loss : 15.8363676071167\n",
      "Epoch : 517 || Train Loss : 0.034251246601343155 || Val Loss : 15.805951118469238\n",
      "Epoch : 518 || Train Loss : 0.035240307450294495 || Val Loss : 15.792315483093262\n",
      "Epoch : 519 || Train Loss : 0.033006198704242706 || Val Loss : 15.791391372680664\n",
      "Epoch : 520 || Train Loss : 0.03266817331314087 || Val Loss : 15.819021224975586\n",
      "Epoch : 521 || Train Loss : 0.06436433643102646 || Val Loss : 15.794249534606934\n",
      "Epoch : 522 || Train Loss : 0.04736607149243355 || Val Loss : 15.836990356445312\n",
      "Epoch : 523 || Train Loss : 0.03971013054251671 || Val Loss : 15.761007308959961\n",
      "Epoch : 524 || Train Loss : 0.03957999125123024 || Val Loss : 15.89721393585205\n",
      "Epoch : 525 || Train Loss : 0.04005228355526924 || Val Loss : 15.822293281555176\n",
      "Epoch : 526 || Train Loss : 0.03051222860813141 || Val Loss : 15.832277297973633\n",
      "Epoch : 527 || Train Loss : 0.033296436071395874 || Val Loss : 15.776590347290039\n",
      "Epoch : 528 || Train Loss : 0.030198732390999794 || Val Loss : 15.78917121887207\n",
      "Epoch : 529 || Train Loss : 0.03389046713709831 || Val Loss : 15.795937538146973\n",
      "Epoch : 530 || Train Loss : 0.04548037052154541 || Val Loss : 15.84385871887207\n",
      "Epoch : 531 || Train Loss : 0.033178653568029404 || Val Loss : 15.82910442352295\n",
      "Epoch : 532 || Train Loss : 0.03500150144100189 || Val Loss : 15.884549140930176\n",
      "Epoch : 533 || Train Loss : 0.04149014130234718 || Val Loss : 15.791692733764648\n",
      "Epoch : 534 || Train Loss : 0.08676153421401978 || Val Loss : 15.764083862304688\n",
      "Epoch : 535 || Train Loss : 0.04907577857375145 || Val Loss : 15.788745880126953\n",
      "Epoch : 536 || Train Loss : 0.03318895027041435 || Val Loss : 15.744760513305664\n",
      "Epoch : 537 || Train Loss : 0.038164038211107254 || Val Loss : 15.762160301208496\n",
      "Epoch : 538 || Train Loss : 0.03362175449728966 || Val Loss : 15.803583145141602\n",
      "Epoch : 539 || Train Loss : 0.07100768387317657 || Val Loss : 15.847871780395508\n",
      "Epoch : 540 || Train Loss : 0.06173961982131004 || Val Loss : 15.800603866577148\n",
      "Epoch : 541 || Train Loss : 0.05004971846938133 || Val Loss : 15.798627853393555\n",
      "Epoch : 542 || Train Loss : 0.049346257001161575 || Val Loss : 15.772025108337402\n",
      "Epoch : 543 || Train Loss : 0.04084949567914009 || Val Loss : 15.788139343261719\n",
      "Epoch : 544 || Train Loss : 0.02870543673634529 || Val Loss : 15.810955047607422\n",
      "Epoch : 545 || Train Loss : 0.03392946347594261 || Val Loss : 15.740347862243652\n",
      "Epoch : 546 || Train Loss : 0.04281334951519966 || Val Loss : 15.815597534179688\n",
      "Epoch : 547 || Train Loss : 0.03316168114542961 || Val Loss : 15.848764419555664\n",
      "Epoch : 548 || Train Loss : 0.04509824514389038 || Val Loss : 15.800607681274414\n",
      "Epoch : 549 || Train Loss : 0.040592730045318604 || Val Loss : 15.818975448608398\n",
      "Epoch : 550 || Train Loss : 0.030252421274781227 || Val Loss : 15.784453392028809\n",
      "Epoch : 551 || Train Loss : 0.03356662020087242 || Val Loss : 15.782210350036621\n",
      "Epoch : 552 || Train Loss : 0.033672451972961426 || Val Loss : 15.781364440917969\n",
      "Epoch : 553 || Train Loss : 0.030251706019043922 || Val Loss : 15.764257431030273\n",
      "Epoch : 554 || Train Loss : 0.03106955997645855 || Val Loss : 15.878896713256836\n",
      "Epoch : 555 || Train Loss : 0.029065430164337158 || Val Loss : 15.905106544494629\n",
      "Epoch : 556 || Train Loss : 0.037435561418533325 || Val Loss : 15.850056648254395\n",
      "Epoch : 557 || Train Loss : 0.028497353196144104 || Val Loss : 15.78034496307373\n",
      "Epoch : 558 || Train Loss : 0.03665005788207054 || Val Loss : 15.786238670349121\n",
      "Epoch : 559 || Train Loss : 0.03446584939956665 || Val Loss : 15.735288619995117\n",
      "Epoch : 560 || Train Loss : 0.029384959489107132 || Val Loss : 15.795516014099121\n",
      "Epoch : 561 || Train Loss : 0.030896712094545364 || Val Loss : 15.796626091003418\n",
      "Epoch : 562 || Train Loss : 0.04438188299536705 || Val Loss : 15.858440399169922\n",
      "Epoch : 563 || Train Loss : 0.03016764298081398 || Val Loss : 15.84621524810791\n",
      "Epoch : 564 || Train Loss : 0.06863035261631012 || Val Loss : 15.769941329956055\n",
      "Epoch : 565 || Train Loss : 0.0346645712852478 || Val Loss : 15.894347190856934\n",
      "Epoch : 566 || Train Loss : 0.02815410867333412 || Val Loss : 15.843151092529297\n",
      "Epoch : 567 || Train Loss : 0.0718197226524353 || Val Loss : 15.876081466674805\n",
      "Epoch : 568 || Train Loss : 0.061194758862257004 || Val Loss : 15.781545639038086\n",
      "Epoch : 569 || Train Loss : 0.029111875221133232 || Val Loss : 15.807127952575684\n",
      "Epoch : 570 || Train Loss : 0.03629019483923912 || Val Loss : 15.828828811645508\n",
      "Epoch : 571 || Train Loss : 0.03255167603492737 || Val Loss : 15.898799896240234\n",
      "Epoch : 572 || Train Loss : 0.027852846309542656 || Val Loss : 15.865985870361328\n",
      "Epoch : 573 || Train Loss : 0.035291220992803574 || Val Loss : 15.810430526733398\n",
      "Epoch : 574 || Train Loss : 0.03883824497461319 || Val Loss : 15.886415481567383\n",
      "Epoch : 575 || Train Loss : 0.03903524950146675 || Val Loss : 15.79605484008789\n",
      "Epoch : 576 || Train Loss : 0.02594195120036602 || Val Loss : 15.843542098999023\n",
      "Epoch : 577 || Train Loss : 0.0354587659239769 || Val Loss : 15.844615936279297\n",
      "Epoch : 578 || Train Loss : 0.04053722321987152 || Val Loss : 15.857592582702637\n",
      "Epoch : 579 || Train Loss : 0.03394359350204468 || Val Loss : 15.795926094055176\n",
      "Epoch : 580 || Train Loss : 0.031244996935129166 || Val Loss : 15.905716896057129\n",
      "Epoch : 581 || Train Loss : 0.049717433750629425 || Val Loss : 15.80338191986084\n",
      "Epoch : 582 || Train Loss : 0.03186213970184326 || Val Loss : 15.785025596618652\n",
      "Epoch : 583 || Train Loss : 0.043198782950639725 || Val Loss : 15.889627456665039\n",
      "Epoch : 584 || Train Loss : 0.03125527501106262 || Val Loss : 15.891247749328613\n",
      "Epoch : 585 || Train Loss : 0.04078776016831398 || Val Loss : 15.95580768585205\n",
      "Epoch : 586 || Train Loss : 0.03055715560913086 || Val Loss : 15.833885192871094\n",
      "Epoch : 587 || Train Loss : 0.05629966780543327 || Val Loss : 15.834043502807617\n",
      "Epoch : 588 || Train Loss : 0.03727191686630249 || Val Loss : 15.867888450622559\n",
      "Epoch : 589 || Train Loss : 0.033792104572057724 || Val Loss : 15.862268447875977\n",
      "Epoch : 590 || Train Loss : 0.03445778414607048 || Val Loss : 15.83885383605957\n",
      "Epoch : 591 || Train Loss : 0.029395734891295433 || Val Loss : 15.787532806396484\n",
      "Epoch : 592 || Train Loss : 0.03995305299758911 || Val Loss : 15.868753433227539\n",
      "Epoch : 593 || Train Loss : 0.036003150045871735 || Val Loss : 15.826245307922363\n",
      "Epoch : 594 || Train Loss : 0.03480587527155876 || Val Loss : 15.815996170043945\n",
      "Epoch : 595 || Train Loss : 0.028581583872437477 || Val Loss : 15.8351411819458\n",
      "Epoch : 596 || Train Loss : 0.03249896690249443 || Val Loss : 15.832301139831543\n",
      "Epoch : 597 || Train Loss : 0.04270363971590996 || Val Loss : 15.872986793518066\n",
      "Epoch : 598 || Train Loss : 0.05141338333487511 || Val Loss : 15.872901916503906\n",
      "Epoch : 599 || Train Loss : 0.04066629335284233 || Val Loss : 15.799273490905762\n",
      "Epoch : 600 || Train Loss : 0.029930943623185158 || Val Loss : 15.862421035766602\n",
      "Epoch : 601 || Train Loss : 0.030146760866045952 || Val Loss : 15.906856536865234\n",
      "Epoch : 602 || Train Loss : 0.028907163068652153 || Val Loss : 15.790453910827637\n",
      "Epoch : 603 || Train Loss : 0.03812967985868454 || Val Loss : 15.832354545593262\n",
      "Epoch : 604 || Train Loss : 0.03159736096858978 || Val Loss : 15.738370895385742\n",
      "Epoch : 605 || Train Loss : 0.03157040476799011 || Val Loss : 15.866325378417969\n",
      "Epoch : 606 || Train Loss : 0.07299666851758957 || Val Loss : 15.868820190429688\n",
      "Epoch : 607 || Train Loss : 0.036903221160173416 || Val Loss : 15.753725051879883\n",
      "Epoch : 608 || Train Loss : 0.054519545286893845 || Val Loss : 15.874215126037598\n",
      "Epoch : 609 || Train Loss : 0.03912023827433586 || Val Loss : 15.876087188720703\n",
      "Epoch : 610 || Train Loss : 0.0327436588704586 || Val Loss : 15.805436134338379\n",
      "Epoch : 611 || Train Loss : 0.04355762526392937 || Val Loss : 15.837204933166504\n",
      "Epoch : 612 || Train Loss : 0.06384606659412384 || Val Loss : 15.865882873535156\n",
      "Epoch : 613 || Train Loss : 0.03931080177426338 || Val Loss : 15.846529006958008\n",
      "Epoch : 614 || Train Loss : 0.03875856474041939 || Val Loss : 15.88888168334961\n",
      "Epoch : 615 || Train Loss : 0.02688419260084629 || Val Loss : 15.802413940429688\n",
      "Epoch : 616 || Train Loss : 0.028932297602295876 || Val Loss : 15.886645317077637\n",
      "Epoch : 617 || Train Loss : 0.02615453116595745 || Val Loss : 15.873700141906738\n",
      "Epoch : 618 || Train Loss : 0.03573702648282051 || Val Loss : 15.842020988464355\n",
      "Epoch : 619 || Train Loss : 0.07785096764564514 || Val Loss : 15.814099311828613\n",
      "Epoch : 620 || Train Loss : 0.034317683428525925 || Val Loss : 15.853142738342285\n",
      "Epoch : 621 || Train Loss : 0.03587318956851959 || Val Loss : 15.824230194091797\n",
      "Epoch : 622 || Train Loss : 0.029651252552866936 || Val Loss : 15.797012329101562\n",
      "Epoch : 623 || Train Loss : 0.03965451940894127 || Val Loss : 15.808971405029297\n",
      "Epoch : 624 || Train Loss : 0.029059136286377907 || Val Loss : 15.856781959533691\n",
      "Epoch : 625 || Train Loss : 0.07550471276044846 || Val Loss : 15.83168888092041\n",
      "Epoch : 626 || Train Loss : 0.03447926044464111 || Val Loss : 15.781329154968262\n",
      "Epoch : 627 || Train Loss : 0.03948832303285599 || Val Loss : 15.772823333740234\n",
      "Epoch : 628 || Train Loss : 0.06201530247926712 || Val Loss : 15.814054489135742\n",
      "Epoch : 629 || Train Loss : 0.029643256217241287 || Val Loss : 15.78921890258789\n",
      "Epoch : 630 || Train Loss : 0.03179438039660454 || Val Loss : 15.82331657409668\n",
      "Epoch : 631 || Train Loss : 0.02401968650519848 || Val Loss : 15.740785598754883\n",
      "Epoch : 632 || Train Loss : 0.03231578320264816 || Val Loss : 15.824581146240234\n",
      "Epoch : 633 || Train Loss : 0.03616625443100929 || Val Loss : 15.833144187927246\n",
      "Epoch : 634 || Train Loss : 0.03442836180329323 || Val Loss : 15.81665325164795\n",
      "Epoch : 635 || Train Loss : 0.03422233834862709 || Val Loss : 15.783787727355957\n",
      "Epoch : 636 || Train Loss : 0.04205089062452316 || Val Loss : 15.809903144836426\n",
      "Epoch : 637 || Train Loss : 0.0282380823045969 || Val Loss : 15.862639427185059\n",
      "Epoch : 638 || Train Loss : 0.029616763815283775 || Val Loss : 15.836268424987793\n",
      "Epoch : 639 || Train Loss : 0.02673817053437233 || Val Loss : 15.854755401611328\n",
      "Epoch : 640 || Train Loss : 0.042179763317108154 || Val Loss : 15.863748550415039\n",
      "Epoch : 641 || Train Loss : 0.027117852121591568 || Val Loss : 15.853728294372559\n",
      "Epoch : 642 || Train Loss : 0.028604665771126747 || Val Loss : 15.761857032775879\n",
      "Epoch : 643 || Train Loss : 0.03399830684065819 || Val Loss : 15.830699920654297\n",
      "Epoch : 644 || Train Loss : 0.02876409702003002 || Val Loss : 15.78004264831543\n",
      "Epoch : 645 || Train Loss : 0.027513865381479263 || Val Loss : 15.802966117858887\n",
      "Epoch : 646 || Train Loss : 0.02833256497979164 || Val Loss : 15.738788604736328\n",
      "Epoch : 647 || Train Loss : 0.025751933455467224 || Val Loss : 15.737143516540527\n",
      "Epoch : 648 || Train Loss : 0.040103595703840256 || Val Loss : 15.783745765686035\n",
      "Epoch : 649 || Train Loss : 0.029412660747766495 || Val Loss : 15.8046293258667\n",
      "Epoch : 650 || Train Loss : 0.03338783234357834 || Val Loss : 15.854080200195312\n",
      "Epoch : 651 || Train Loss : 0.02751627005636692 || Val Loss : 15.811582565307617\n",
      "Epoch : 652 || Train Loss : 0.02530721202492714 || Val Loss : 15.842473983764648\n",
      "Epoch : 653 || Train Loss : 0.03207589313387871 || Val Loss : 15.808731079101562\n",
      "Epoch : 654 || Train Loss : 0.05309863016009331 || Val Loss : 15.729427337646484\n",
      "Epoch : 655 || Train Loss : 0.03357144445180893 || Val Loss : 15.76412296295166\n",
      "Epoch : 656 || Train Loss : 0.029986722394824028 || Val Loss : 15.71006965637207\n",
      "Epoch : 657 || Train Loss : 0.03993844613432884 || Val Loss : 15.764969825744629\n",
      "Epoch : 658 || Train Loss : 0.031002530828118324 || Val Loss : 15.738483428955078\n",
      "Epoch : 659 || Train Loss : 0.03299863263964653 || Val Loss : 15.833524703979492\n",
      "Epoch : 660 || Train Loss : 0.036575790494680405 || Val Loss : 15.79467487335205\n",
      "Epoch : 661 || Train Loss : 0.03085719421505928 || Val Loss : 15.785628318786621\n",
      "Epoch : 662 || Train Loss : 0.02585711143910885 || Val Loss : 15.814040184020996\n",
      "Epoch : 663 || Train Loss : 0.026969505473971367 || Val Loss : 15.754898071289062\n",
      "Epoch : 664 || Train Loss : 0.0703984946012497 || Val Loss : 15.85257625579834\n",
      "Epoch : 665 || Train Loss : 0.027400171384215355 || Val Loss : 15.874008178710938\n",
      "Epoch : 666 || Train Loss : 0.03398311138153076 || Val Loss : 15.800078392028809\n",
      "Epoch : 667 || Train Loss : 0.032341744750738144 || Val Loss : 15.80813980102539\n",
      "Epoch : 668 || Train Loss : 0.02880885638296604 || Val Loss : 15.797971725463867\n",
      "Epoch : 669 || Train Loss : 0.045680202543735504 || Val Loss : 15.894789695739746\n",
      "Epoch : 670 || Train Loss : 0.031502652913331985 || Val Loss : 15.838155746459961\n",
      "Epoch : 671 || Train Loss : 0.04758797958493233 || Val Loss : 15.861261367797852\n",
      "Epoch : 672 || Train Loss : 0.028895968571305275 || Val Loss : 15.90501594543457\n",
      "Epoch : 673 || Train Loss : 0.03894844278693199 || Val Loss : 15.838791847229004\n",
      "Epoch : 674 || Train Loss : 0.033182524144649506 || Val Loss : 15.85252857208252\n",
      "Epoch : 675 || Train Loss : 0.029964763671159744 || Val Loss : 15.746232986450195\n",
      "Epoch : 676 || Train Loss : 0.03017023764550686 || Val Loss : 15.900327682495117\n",
      "Epoch : 677 || Train Loss : 0.03839148208498955 || Val Loss : 15.758210182189941\n",
      "Epoch : 678 || Train Loss : 0.038198936730623245 || Val Loss : 15.8041353225708\n",
      "Epoch : 679 || Train Loss : 0.025911932811141014 || Val Loss : 15.772953987121582\n",
      "Epoch : 680 || Train Loss : 0.03371007367968559 || Val Loss : 15.870208740234375\n",
      "Epoch : 681 || Train Loss : 0.0591127835214138 || Val Loss : 15.803820610046387\n",
      "Epoch : 682 || Train Loss : 0.03335174173116684 || Val Loss : 15.84721851348877\n",
      "Epoch : 683 || Train Loss : 0.03483273461461067 || Val Loss : 15.823338508605957\n",
      "Epoch : 684 || Train Loss : 0.027313847094774246 || Val Loss : 15.839066505432129\n",
      "Epoch : 685 || Train Loss : 0.027076220139861107 || Val Loss : 15.79316234588623\n",
      "Epoch : 686 || Train Loss : 0.03062569536268711 || Val Loss : 15.827370643615723\n",
      "Epoch : 687 || Train Loss : 0.02700621262192726 || Val Loss : 15.819019317626953\n",
      "Epoch : 688 || Train Loss : 0.03366848826408386 || Val Loss : 15.872672080993652\n",
      "Epoch : 689 || Train Loss : 0.033857788890600204 || Val Loss : 15.839316368103027\n",
      "Epoch : 690 || Train Loss : 0.028667891398072243 || Val Loss : 15.847301483154297\n",
      "Epoch : 691 || Train Loss : 0.029189467430114746 || Val Loss : 15.875067710876465\n",
      "Epoch : 692 || Train Loss : 0.02839258685708046 || Val Loss : 15.852422714233398\n",
      "Epoch : 693 || Train Loss : 0.03495107963681221 || Val Loss : 15.882339477539062\n",
      "Epoch : 694 || Train Loss : 0.0359683632850647 || Val Loss : 15.856244087219238\n",
      "Epoch : 695 || Train Loss : 0.04012829437851906 || Val Loss : 15.811050415039062\n",
      "Epoch : 696 || Train Loss : 0.03848421201109886 || Val Loss : 15.783150672912598\n",
      "Epoch : 697 || Train Loss : 0.03939414769411087 || Val Loss : 15.818309783935547\n",
      "Epoch : 698 || Train Loss : 0.03981110453605652 || Val Loss : 15.825336456298828\n",
      "Epoch : 699 || Train Loss : 0.032667066901922226 || Val Loss : 15.850706100463867\n",
      "Epoch : 700 || Train Loss : 0.025153666734695435 || Val Loss : 15.882594108581543\n",
      "Epoch : 701 || Train Loss : 0.04084331542253494 || Val Loss : 15.819853782653809\n",
      "Epoch : 702 || Train Loss : 0.02873905375599861 || Val Loss : 15.823958396911621\n",
      "Epoch : 703 || Train Loss : 0.051606547087430954 || Val Loss : 15.828539848327637\n",
      "Epoch : 704 || Train Loss : 0.04865407198667526 || Val Loss : 15.78769588470459\n",
      "Epoch : 705 || Train Loss : 0.0372784249484539 || Val Loss : 15.786226272583008\n",
      "Epoch : 706 || Train Loss : 0.02946208231151104 || Val Loss : 15.753022193908691\n",
      "Epoch : 707 || Train Loss : 0.027749864384531975 || Val Loss : 15.854968070983887\n",
      "Epoch : 708 || Train Loss : 0.02675323188304901 || Val Loss : 15.832966804504395\n",
      "Epoch : 709 || Train Loss : 0.03633011505007744 || Val Loss : 15.753880500793457\n",
      "Epoch : 710 || Train Loss : 0.02676239423453808 || Val Loss : 15.827335357666016\n",
      "Epoch : 711 || Train Loss : 0.05934690311551094 || Val Loss : 15.752084732055664\n",
      "Epoch : 712 || Train Loss : 0.023655354976654053 || Val Loss : 15.8124361038208\n",
      "Epoch : 713 || Train Loss : 0.043836839497089386 || Val Loss : 15.771252632141113\n",
      "Epoch : 714 || Train Loss : 0.023142606019973755 || Val Loss : 15.856536865234375\n",
      "Epoch : 715 || Train Loss : 0.027842318639159203 || Val Loss : 15.72373104095459\n",
      "Epoch : 716 || Train Loss : 0.036726415157318115 || Val Loss : 15.748873710632324\n",
      "Epoch : 717 || Train Loss : 0.02918400801718235 || Val Loss : 15.725001335144043\n",
      "Epoch : 718 || Train Loss : 0.03207413852214813 || Val Loss : 15.739834785461426\n",
      "Epoch : 719 || Train Loss : 0.030508533120155334 || Val Loss : 15.717181205749512\n",
      "Epoch : 720 || Train Loss : 0.02561582624912262 || Val Loss : 15.841654777526855\n",
      "Epoch : 721 || Train Loss : 0.051774393767118454 || Val Loss : 15.762887954711914\n",
      "Epoch : 722 || Train Loss : 0.0263336431235075 || Val Loss : 15.79738998413086\n",
      "Epoch : 723 || Train Loss : 0.02616475522518158 || Val Loss : 15.749652862548828\n",
      "Epoch : 724 || Train Loss : 0.02950703538954258 || Val Loss : 15.910004615783691\n",
      "Epoch : 725 || Train Loss : 0.030701279640197754 || Val Loss : 15.811635971069336\n",
      "Epoch : 726 || Train Loss : 0.02467970736324787 || Val Loss : 15.813199043273926\n",
      "Epoch : 727 || Train Loss : 0.029655788093805313 || Val Loss : 15.833357810974121\n",
      "Epoch : 728 || Train Loss : 0.03230980411171913 || Val Loss : 15.850947380065918\n",
      "Epoch : 729 || Train Loss : 0.031658243387937546 || Val Loss : 15.788487434387207\n",
      "Epoch : 730 || Train Loss : 0.028818894177675247 || Val Loss : 15.806506156921387\n",
      "Epoch : 731 || Train Loss : 0.0308372862637043 || Val Loss : 15.838244438171387\n",
      "Epoch : 732 || Train Loss : 0.028252189978957176 || Val Loss : 15.79322624206543\n",
      "Epoch : 733 || Train Loss : 0.03369223326444626 || Val Loss : 15.803685188293457\n",
      "Epoch : 734 || Train Loss : 0.024465909227728844 || Val Loss : 15.780596733093262\n",
      "Epoch : 735 || Train Loss : 0.027350107207894325 || Val Loss : 15.832265853881836\n",
      "Epoch : 736 || Train Loss : 0.03132139891386032 || Val Loss : 15.825414657592773\n",
      "Epoch : 737 || Train Loss : 0.026119014248251915 || Val Loss : 15.830713272094727\n",
      "Epoch : 738 || Train Loss : 0.04501335322856903 || Val Loss : 15.807849884033203\n",
      "Epoch : 739 || Train Loss : 0.024567343294620514 || Val Loss : 15.766081809997559\n",
      "Epoch : 740 || Train Loss : 0.051593512296676636 || Val Loss : 15.778915405273438\n",
      "Epoch : 741 || Train Loss : 0.03573377802968025 || Val Loss : 15.857087135314941\n",
      "Epoch : 742 || Train Loss : 0.026169223710894585 || Val Loss : 15.87027645111084\n",
      "Epoch : 743 || Train Loss : 0.061388421803712845 || Val Loss : 15.784293174743652\n",
      "Epoch : 744 || Train Loss : 0.024213949218392372 || Val Loss : 15.847681999206543\n",
      "Epoch : 745 || Train Loss : 0.027241041883826256 || Val Loss : 15.812164306640625\n",
      "Epoch : 746 || Train Loss : 0.027986763045191765 || Val Loss : 15.884308815002441\n",
      "Epoch : 747 || Train Loss : 0.025935126468539238 || Val Loss : 15.837027549743652\n",
      "Epoch : 748 || Train Loss : 0.030196169391274452 || Val Loss : 15.814711570739746\n",
      "Epoch : 749 || Train Loss : 0.027414804324507713 || Val Loss : 15.765829086303711\n",
      "Epoch : 750 || Train Loss : 0.025551388040184975 || Val Loss : 15.83839225769043\n",
      "Epoch : 751 || Train Loss : 0.051924776285886765 || Val Loss : 15.8409423828125\n",
      "Epoch : 752 || Train Loss : 0.033270806074142456 || Val Loss : 15.891155242919922\n",
      "Epoch : 753 || Train Loss : 0.026669833809137344 || Val Loss : 15.77164363861084\n",
      "Epoch : 754 || Train Loss : 0.02616221085190773 || Val Loss : 15.80618953704834\n",
      "Epoch : 755 || Train Loss : 0.030376216396689415 || Val Loss : 15.833958625793457\n",
      "Epoch : 756 || Train Loss : 0.03112857975065708 || Val Loss : 15.875092506408691\n",
      "Epoch : 757 || Train Loss : 0.02802835963666439 || Val Loss : 15.858713150024414\n",
      "Epoch : 758 || Train Loss : 0.024359693750739098 || Val Loss : 15.851629257202148\n",
      "Epoch : 759 || Train Loss : 0.025224601849913597 || Val Loss : 15.802245140075684\n",
      "Epoch : 760 || Train Loss : 0.02570711076259613 || Val Loss : 15.897550582885742\n",
      "Epoch : 761 || Train Loss : 0.02908184565603733 || Val Loss : 15.845272064208984\n",
      "Epoch : 762 || Train Loss : 0.031092703342437744 || Val Loss : 15.837791442871094\n",
      "Epoch : 763 || Train Loss : 0.03663736581802368 || Val Loss : 15.869101524353027\n",
      "Epoch : 764 || Train Loss : 0.03024311363697052 || Val Loss : 15.813728332519531\n",
      "Epoch : 765 || Train Loss : 0.03126033768057823 || Val Loss : 15.810169219970703\n",
      "Epoch : 766 || Train Loss : 0.029073327779769897 || Val Loss : 15.833995819091797\n",
      "Epoch : 767 || Train Loss : 0.04652940109372139 || Val Loss : 15.781278610229492\n",
      "Epoch : 768 || Train Loss : 0.0237222108989954 || Val Loss : 15.884074211120605\n",
      "Epoch : 769 || Train Loss : 0.027256814762949944 || Val Loss : 15.75407600402832\n",
      "Epoch : 770 || Train Loss : 0.04048847779631615 || Val Loss : 15.88151741027832\n",
      "Epoch : 771 || Train Loss : 0.05620063468813896 || Val Loss : 15.809633255004883\n",
      "Epoch : 772 || Train Loss : 0.030877089127898216 || Val Loss : 15.76579475402832\n",
      "Epoch : 773 || Train Loss : 0.023725222796201706 || Val Loss : 15.883479118347168\n",
      "Epoch : 774 || Train Loss : 0.02930487133562565 || Val Loss : 15.918767929077148\n",
      "Epoch : 775 || Train Loss : 0.030936582013964653 || Val Loss : 15.890275955200195\n",
      "Epoch : 776 || Train Loss : 0.04288841038942337 || Val Loss : 15.871612548828125\n",
      "Epoch : 777 || Train Loss : 0.03929010033607483 || Val Loss : 15.86386775970459\n",
      "Epoch : 778 || Train Loss : 0.02475838176906109 || Val Loss : 15.843969345092773\n",
      "Epoch : 779 || Train Loss : 0.04747888445854187 || Val Loss : 15.892684936523438\n",
      "Epoch : 780 || Train Loss : 0.03223934397101402 || Val Loss : 15.876558303833008\n",
      "Epoch : 781 || Train Loss : 0.023753946647047997 || Val Loss : 15.857343673706055\n",
      "Epoch : 782 || Train Loss : 0.025463184341788292 || Val Loss : 15.866617202758789\n",
      "Epoch : 783 || Train Loss : 0.03241802752017975 || Val Loss : 15.908963203430176\n",
      "Epoch : 784 || Train Loss : 0.02420789934694767 || Val Loss : 15.88547134399414\n",
      "Epoch : 785 || Train Loss : 0.026447448879480362 || Val Loss : 15.946484565734863\n",
      "Epoch : 786 || Train Loss : 0.03261394798755646 || Val Loss : 15.933961868286133\n",
      "Epoch : 787 || Train Loss : 0.031149405986070633 || Val Loss : 15.866799354553223\n",
      "Epoch : 788 || Train Loss : 0.02653144858777523 || Val Loss : 15.898566246032715\n",
      "Epoch : 789 || Train Loss : 0.06210240721702576 || Val Loss : 15.869562149047852\n",
      "Epoch : 790 || Train Loss : 0.02798774652183056 || Val Loss : 15.964214324951172\n",
      "Epoch : 791 || Train Loss : 0.025268876925110817 || Val Loss : 15.888489723205566\n",
      "Epoch : 792 || Train Loss : 0.028855277225375175 || Val Loss : 15.884469032287598\n",
      "Epoch : 793 || Train Loss : 0.030653540045022964 || Val Loss : 15.898209571838379\n",
      "Epoch : 794 || Train Loss : 0.059690117835998535 || Val Loss : 15.947097778320312\n",
      "Epoch : 795 || Train Loss : 0.0330270454287529 || Val Loss : 15.864126205444336\n",
      "Epoch : 796 || Train Loss : 0.03051828406751156 || Val Loss : 15.930187225341797\n",
      "Epoch : 797 || Train Loss : 0.02529110386967659 || Val Loss : 15.898355484008789\n",
      "Epoch : 798 || Train Loss : 0.047626424580812454 || Val Loss : 15.899867057800293\n",
      "Epoch : 799 || Train Loss : 0.035354819148778915 || Val Loss : 15.85825252532959\n",
      "Epoch : 800 || Train Loss : 0.02951687015593052 || Val Loss : 15.754640579223633\n",
      "Epoch : 801 || Train Loss : 0.028402581810951233 || Val Loss : 15.864043235778809\n",
      "Epoch : 802 || Train Loss : 0.02282005362212658 || Val Loss : 15.822927474975586\n",
      "Epoch : 803 || Train Loss : 0.035630542784929276 || Val Loss : 15.800755500793457\n",
      "Epoch : 804 || Train Loss : 0.027763625606894493 || Val Loss : 15.911267280578613\n",
      "Epoch : 805 || Train Loss : 0.025942062959074974 || Val Loss : 15.8834810256958\n",
      "Epoch : 806 || Train Loss : 0.031314171850681305 || Val Loss : 15.944500923156738\n",
      "Epoch : 807 || Train Loss : 0.025489378720521927 || Val Loss : 15.859444618225098\n",
      "Epoch : 808 || Train Loss : 0.03606167808175087 || Val Loss : 15.873624801635742\n",
      "Epoch : 809 || Train Loss : 0.02713102102279663 || Val Loss : 15.79883098602295\n",
      "Epoch : 810 || Train Loss : 0.029037630185484886 || Val Loss : 15.81340503692627\n",
      "Epoch : 811 || Train Loss : 0.05448770523071289 || Val Loss : 15.850236892700195\n",
      "Epoch : 812 || Train Loss : 0.025966325774788857 || Val Loss : 15.889469146728516\n",
      "Epoch : 813 || Train Loss : 0.025549007579684258 || Val Loss : 15.854255676269531\n",
      "Epoch : 814 || Train Loss : 0.036990921944379807 || Val Loss : 15.810562133789062\n",
      "Epoch : 815 || Train Loss : 0.03785309940576553 || Val Loss : 15.82783031463623\n",
      "Epoch : 816 || Train Loss : 0.03848269581794739 || Val Loss : 15.8341646194458\n",
      "Epoch : 817 || Train Loss : 0.05635141208767891 || Val Loss : 15.82530403137207\n",
      "Epoch : 818 || Train Loss : 0.032148730009794235 || Val Loss : 15.883173942565918\n",
      "Epoch : 819 || Train Loss : 0.03149426728487015 || Val Loss : 15.787575721740723\n",
      "Epoch : 820 || Train Loss : 0.034226927906274796 || Val Loss : 15.861176490783691\n",
      "Epoch : 821 || Train Loss : 0.04225122556090355 || Val Loss : 15.862748146057129\n",
      "Epoch : 822 || Train Loss : 0.03508181869983673 || Val Loss : 15.76076602935791\n",
      "Epoch : 823 || Train Loss : 0.03021562471985817 || Val Loss : 15.847977638244629\n",
      "Epoch : 824 || Train Loss : 0.027570098638534546 || Val Loss : 15.861042022705078\n",
      "Epoch : 825 || Train Loss : 0.027060827240347862 || Val Loss : 15.96237850189209\n",
      "Epoch : 826 || Train Loss : 0.02782604470849037 || Val Loss : 15.83797550201416\n",
      "Epoch : 827 || Train Loss : 0.024395672604441643 || Val Loss : 15.800161361694336\n",
      "Epoch : 828 || Train Loss : 0.042254891246557236 || Val Loss : 15.751580238342285\n",
      "Epoch : 829 || Train Loss : 0.028850257396697998 || Val Loss : 15.797270774841309\n",
      "Epoch : 830 || Train Loss : 0.02435447834432125 || Val Loss : 15.887937545776367\n",
      "Epoch : 831 || Train Loss : 0.04743485525250435 || Val Loss : 15.843414306640625\n",
      "Epoch : 832 || Train Loss : 0.03355109691619873 || Val Loss : 15.810625076293945\n",
      "Epoch : 833 || Train Loss : 0.028037309646606445 || Val Loss : 15.866323471069336\n",
      "Epoch : 834 || Train Loss : 0.048350509256124496 || Val Loss : 15.85749626159668\n",
      "Epoch : 835 || Train Loss : 0.02417341247200966 || Val Loss : 15.834249496459961\n",
      "Epoch : 836 || Train Loss : 0.041709329932928085 || Val Loss : 15.887282371520996\n",
      "Epoch : 837 || Train Loss : 0.028541598469018936 || Val Loss : 15.839681625366211\n",
      "Epoch : 838 || Train Loss : 0.030913669615983963 || Val Loss : 15.793936729431152\n",
      "Epoch : 839 || Train Loss : 0.026928329840302467 || Val Loss : 15.875665664672852\n",
      "Epoch : 840 || Train Loss : 0.041487760841846466 || Val Loss : 15.936274528503418\n",
      "Epoch : 841 || Train Loss : 0.05341286584734917 || Val Loss : 15.752223014831543\n",
      "Epoch : 842 || Train Loss : 0.047834329307079315 || Val Loss : 15.779563903808594\n",
      "Epoch : 843 || Train Loss : 0.029653150588274002 || Val Loss : 15.810709953308105\n",
      "Epoch : 844 || Train Loss : 0.028254015371203423 || Val Loss : 15.791703224182129\n",
      "Epoch : 845 || Train Loss : 0.0386960469186306 || Val Loss : 15.82715129852295\n",
      "Epoch : 846 || Train Loss : 0.034782957285642624 || Val Loss : 15.778921127319336\n",
      "Epoch : 847 || Train Loss : 0.05946902185678482 || Val Loss : 15.895851135253906\n",
      "Epoch : 848 || Train Loss : 0.026295825839042664 || Val Loss : 15.853996276855469\n",
      "Epoch : 849 || Train Loss : 0.07358145713806152 || Val Loss : 15.75659465789795\n",
      "Epoch : 850 || Train Loss : 0.025131959468126297 || Val Loss : 15.814779281616211\n",
      "Epoch : 851 || Train Loss : 0.04337019473314285 || Val Loss : 15.885000228881836\n",
      "Epoch : 852 || Train Loss : 0.02810705080628395 || Val Loss : 15.928486824035645\n",
      "Epoch : 853 || Train Loss : 0.02631491795182228 || Val Loss : 15.871085166931152\n",
      "Epoch : 854 || Train Loss : 0.031461622565984726 || Val Loss : 15.846989631652832\n",
      "Epoch : 855 || Train Loss : 0.031627289950847626 || Val Loss : 15.840551376342773\n",
      "Epoch : 856 || Train Loss : 0.027808362618088722 || Val Loss : 15.847023963928223\n",
      "Epoch : 857 || Train Loss : 0.031032806262373924 || Val Loss : 15.835248947143555\n",
      "Epoch : 858 || Train Loss : 0.03025241009891033 || Val Loss : 15.812734603881836\n",
      "Epoch : 859 || Train Loss : 0.029022013768553734 || Val Loss : 15.817031860351562\n",
      "Epoch : 860 || Train Loss : 0.025699252262711525 || Val Loss : 15.877690315246582\n",
      "Epoch : 861 || Train Loss : 0.033498793840408325 || Val Loss : 15.87465763092041\n",
      "Epoch : 862 || Train Loss : 0.028904620558023453 || Val Loss : 15.795612335205078\n",
      "Epoch : 863 || Train Loss : 0.021786978468298912 || Val Loss : 15.822324752807617\n",
      "Epoch : 864 || Train Loss : 0.031289201229810715 || Val Loss : 15.904953956604004\n",
      "Epoch : 865 || Train Loss : 0.04201408848166466 || Val Loss : 15.899450302124023\n",
      "Epoch : 866 || Train Loss : 0.025660259649157524 || Val Loss : 15.898348808288574\n",
      "Epoch : 867 || Train Loss : 0.031566981226205826 || Val Loss : 15.900113105773926\n",
      "Epoch : 868 || Train Loss : 0.037425603717565536 || Val Loss : 15.965760231018066\n",
      "Epoch : 869 || Train Loss : 0.029689548537135124 || Val Loss : 15.897100448608398\n",
      "Epoch : 870 || Train Loss : 0.03768475726246834 || Val Loss : 15.960026741027832\n",
      "Epoch : 871 || Train Loss : 0.02641134522855282 || Val Loss : 15.976655960083008\n",
      "Epoch : 872 || Train Loss : 0.03706909343600273 || Val Loss : 15.909965515136719\n",
      "Epoch : 873 || Train Loss : 0.027533693239092827 || Val Loss : 15.908212661743164\n",
      "Epoch : 874 || Train Loss : 0.029635174199938774 || Val Loss : 15.891068458557129\n",
      "Epoch : 875 || Train Loss : 0.027279479429125786 || Val Loss : 15.876864433288574\n",
      "Epoch : 876 || Train Loss : 0.036923062056303024 || Val Loss : 15.870166778564453\n",
      "Epoch : 877 || Train Loss : 0.024410663172602654 || Val Loss : 15.916882514953613\n",
      "Epoch : 878 || Train Loss : 0.03621596097946167 || Val Loss : 15.909197807312012\n",
      "Epoch : 879 || Train Loss : 0.03322950750589371 || Val Loss : 15.873233795166016\n",
      "Epoch : 880 || Train Loss : 0.02615259401500225 || Val Loss : 15.942390441894531\n",
      "Epoch : 881 || Train Loss : 0.02774936333298683 || Val Loss : 15.790371894836426\n",
      "Epoch : 882 || Train Loss : 0.023615164682269096 || Val Loss : 16.00059700012207\n",
      "Epoch : 883 || Train Loss : 0.031497806310653687 || Val Loss : 15.915312767028809\n",
      "Epoch : 884 || Train Loss : 0.025276845321059227 || Val Loss : 15.883102416992188\n",
      "Epoch : 885 || Train Loss : 0.026048138737678528 || Val Loss : 15.883448600769043\n",
      "Epoch : 886 || Train Loss : 0.028876198455691338 || Val Loss : 15.848026275634766\n",
      "Epoch : 887 || Train Loss : 0.055039744824171066 || Val Loss : 15.861339569091797\n",
      "Epoch : 888 || Train Loss : 0.022915976122021675 || Val Loss : 15.832979202270508\n",
      "Epoch : 889 || Train Loss : 0.030002165585756302 || Val Loss : 15.920496940612793\n",
      "Epoch : 890 || Train Loss : 0.03008975461125374 || Val Loss : 15.890356063842773\n",
      "Epoch : 891 || Train Loss : 0.027586905285716057 || Val Loss : 15.868379592895508\n",
      "Epoch : 892 || Train Loss : 0.04806157574057579 || Val Loss : 15.8626070022583\n",
      "Epoch : 893 || Train Loss : 0.024566594511270523 || Val Loss : 15.900679588317871\n",
      "Epoch : 894 || Train Loss : 0.027043236419558525 || Val Loss : 15.88926887512207\n",
      "Epoch : 895 || Train Loss : 0.05418597534298897 || Val Loss : 15.869956970214844\n",
      "Epoch : 896 || Train Loss : 0.045511394739151 || Val Loss : 15.823200225830078\n",
      "Epoch : 897 || Train Loss : 0.023743852972984314 || Val Loss : 15.828164100646973\n",
      "Epoch : 898 || Train Loss : 0.026746559888124466 || Val Loss : 15.816835403442383\n",
      "Epoch : 899 || Train Loss : 0.026835812255740166 || Val Loss : 15.83026123046875\n",
      "Epoch : 900 || Train Loss : 0.026090050116181374 || Val Loss : 15.813206672668457\n",
      "Epoch : 901 || Train Loss : 0.025217503309249878 || Val Loss : 15.799768447875977\n",
      "Epoch : 902 || Train Loss : 0.030513141304254532 || Val Loss : 15.898865699768066\n",
      "Epoch : 903 || Train Loss : 0.027765441685914993 || Val Loss : 15.88486385345459\n",
      "Epoch : 904 || Train Loss : 0.023399831727147102 || Val Loss : 15.869550704956055\n",
      "Epoch : 905 || Train Loss : 0.02365584298968315 || Val Loss : 15.893025398254395\n",
      "Epoch : 906 || Train Loss : 0.03789151832461357 || Val Loss : 15.890308380126953\n",
      "Epoch : 907 || Train Loss : 0.033548202365636826 || Val Loss : 15.830031394958496\n",
      "Epoch : 908 || Train Loss : 0.02690986357629299 || Val Loss : 15.814029693603516\n",
      "Epoch : 909 || Train Loss : 0.027083903551101685 || Val Loss : 15.855429649353027\n",
      "Epoch : 910 || Train Loss : 0.036172326654195786 || Val Loss : 15.877487182617188\n",
      "Epoch : 911 || Train Loss : 0.02596035599708557 || Val Loss : 15.864218711853027\n",
      "Epoch : 912 || Train Loss : 0.023772550746798515 || Val Loss : 15.872349739074707\n",
      "Epoch : 913 || Train Loss : 0.030260538682341576 || Val Loss : 15.817362785339355\n",
      "Epoch : 914 || Train Loss : 0.02347787842154503 || Val Loss : 15.795207977294922\n",
      "Epoch : 915 || Train Loss : 0.025283409282565117 || Val Loss : 15.96892261505127\n",
      "Epoch : 916 || Train Loss : 0.025711623951792717 || Val Loss : 15.872522354125977\n",
      "Epoch : 917 || Train Loss : 0.03016364388167858 || Val Loss : 15.904342651367188\n",
      "Epoch : 918 || Train Loss : 0.05659903958439827 || Val Loss : 15.906074523925781\n",
      "Epoch : 919 || Train Loss : 0.03117612563073635 || Val Loss : 15.892797470092773\n",
      "Epoch : 920 || Train Loss : 0.05487889051437378 || Val Loss : 15.910943031311035\n",
      "Epoch : 921 || Train Loss : 0.03518852964043617 || Val Loss : 15.847784996032715\n",
      "Epoch : 922 || Train Loss : 0.029346821829676628 || Val Loss : 15.97293758392334\n",
      "Epoch : 923 || Train Loss : 0.023766204714775085 || Val Loss : 15.878754615783691\n",
      "Epoch : 924 || Train Loss : 0.031272683292627335 || Val Loss : 15.907489776611328\n",
      "Epoch : 925 || Train Loss : 0.03433097526431084 || Val Loss : 15.890708923339844\n",
      "Epoch : 926 || Train Loss : 0.0626092180609703 || Val Loss : 15.917204856872559\n",
      "Epoch : 927 || Train Loss : 0.03511108085513115 || Val Loss : 15.898964881896973\n",
      "Epoch : 928 || Train Loss : 0.03237345814704895 || Val Loss : 15.933835983276367\n",
      "Epoch : 929 || Train Loss : 0.023044683039188385 || Val Loss : 15.916406631469727\n",
      "Epoch : 930 || Train Loss : 0.03154132887721062 || Val Loss : 15.938118934631348\n",
      "Epoch : 931 || Train Loss : 0.052485205233097076 || Val Loss : 15.856463432312012\n",
      "Epoch : 932 || Train Loss : 0.025388825684785843 || Val Loss : 15.873220443725586\n",
      "Epoch : 933 || Train Loss : 0.035021375864744186 || Val Loss : 15.910703659057617\n",
      "Epoch : 934 || Train Loss : 0.04356659576296806 || Val Loss : 15.87204647064209\n",
      "Epoch : 935 || Train Loss : 0.03242424130439758 || Val Loss : 15.888690948486328\n",
      "Epoch : 936 || Train Loss : 0.023882905021309853 || Val Loss : 15.911258697509766\n",
      "Epoch : 937 || Train Loss : 0.04408621788024902 || Val Loss : 15.915651321411133\n",
      "Epoch : 938 || Train Loss : 0.028913108631968498 || Val Loss : 15.941034317016602\n",
      "Epoch : 939 || Train Loss : 0.04653189331293106 || Val Loss : 15.924312591552734\n",
      "Epoch : 940 || Train Loss : 0.025652319192886353 || Val Loss : 15.888848304748535\n",
      "Epoch : 941 || Train Loss : 0.03130967915058136 || Val Loss : 15.909652709960938\n",
      "Epoch : 942 || Train Loss : 0.031092045828700066 || Val Loss : 15.91458797454834\n",
      "Epoch : 943 || Train Loss : 0.0691412165760994 || Val Loss : 15.956061363220215\n",
      "Epoch : 944 || Train Loss : 0.028101280331611633 || Val Loss : 15.873785018920898\n",
      "Epoch : 945 || Train Loss : 0.028870543465018272 || Val Loss : 15.951883316040039\n",
      "Epoch : 946 || Train Loss : 0.028463473543524742 || Val Loss : 15.916637420654297\n",
      "Epoch : 947 || Train Loss : 0.03667913004755974 || Val Loss : 15.859760284423828\n",
      "Epoch : 948 || Train Loss : 0.029457557946443558 || Val Loss : 15.838574409484863\n",
      "Epoch : 949 || Train Loss : 0.027322715148329735 || Val Loss : 15.846014976501465\n",
      "Epoch : 950 || Train Loss : 0.02640666626393795 || Val Loss : 15.951042175292969\n",
      "Epoch : 951 || Train Loss : 0.030785003677010536 || Val Loss : 15.78947925567627\n",
      "Epoch : 952 || Train Loss : 0.032325778156518936 || Val Loss : 15.921420097351074\n",
      "Epoch : 953 || Train Loss : 0.025650203227996826 || Val Loss : 15.8599853515625\n",
      "Epoch : 954 || Train Loss : 0.0344434529542923 || Val Loss : 15.902350425720215\n",
      "Epoch : 955 || Train Loss : 0.0297250896692276 || Val Loss : 15.90661907196045\n",
      "Epoch : 956 || Train Loss : 0.030636781826615334 || Val Loss : 15.832144737243652\n",
      "Epoch : 957 || Train Loss : 0.024159910157322884 || Val Loss : 15.907154083251953\n",
      "Epoch : 958 || Train Loss : 0.029973749071359634 || Val Loss : 15.886646270751953\n",
      "Epoch : 959 || Train Loss : 0.03402426838874817 || Val Loss : 15.908241271972656\n",
      "Epoch : 960 || Train Loss : 0.029866859316825867 || Val Loss : 15.846001625061035\n",
      "Epoch : 961 || Train Loss : 0.028856784105300903 || Val Loss : 15.883918762207031\n",
      "Epoch : 962 || Train Loss : 0.028448987752199173 || Val Loss : 15.845154762268066\n",
      "Epoch : 963 || Train Loss : 0.04331355169415474 || Val Loss : 15.87065601348877\n",
      "Epoch : 964 || Train Loss : 0.028293659910559654 || Val Loss : 15.925972938537598\n",
      "Epoch : 965 || Train Loss : 0.03688094764947891 || Val Loss : 15.879741668701172\n",
      "Epoch : 966 || Train Loss : 0.028369111940264702 || Val Loss : 15.856096267700195\n",
      "Epoch : 967 || Train Loss : 0.02205435000360012 || Val Loss : 15.932782173156738\n",
      "Epoch : 968 || Train Loss : 0.028779162093997 || Val Loss : 15.943135261535645\n",
      "Epoch : 969 || Train Loss : 0.040212906897068024 || Val Loss : 15.898741722106934\n",
      "Epoch : 970 || Train Loss : 0.022733023390173912 || Val Loss : 15.880950927734375\n",
      "Epoch : 971 || Train Loss : 0.03942045941948891 || Val Loss : 15.923672676086426\n",
      "Epoch : 972 || Train Loss : 0.02296379767358303 || Val Loss : 15.88911247253418\n",
      "Epoch : 973 || Train Loss : 0.02629302255809307 || Val Loss : 15.874594688415527\n",
      "Epoch : 974 || Train Loss : 0.027783721685409546 || Val Loss : 15.891294479370117\n",
      "Epoch : 975 || Train Loss : 0.07341965287923813 || Val Loss : 15.926899909973145\n",
      "Epoch : 976 || Train Loss : 0.024153703823685646 || Val Loss : 15.855605125427246\n",
      "Epoch : 977 || Train Loss : 0.031097739934921265 || Val Loss : 15.850707054138184\n",
      "Epoch : 978 || Train Loss : 0.028261715546250343 || Val Loss : 15.834779739379883\n",
      "Epoch : 979 || Train Loss : 0.026713011786341667 || Val Loss : 15.830931663513184\n",
      "Epoch : 980 || Train Loss : 0.04326215013861656 || Val Loss : 15.887480735778809\n",
      "Epoch : 981 || Train Loss : 0.02371845208108425 || Val Loss : 15.840688705444336\n",
      "Epoch : 982 || Train Loss : 0.02615370787680149 || Val Loss : 15.839521408081055\n",
      "Epoch : 983 || Train Loss : 0.045112546533346176 || Val Loss : 15.96409797668457\n",
      "Epoch : 984 || Train Loss : 0.025781288743019104 || Val Loss : 15.910655975341797\n",
      "Epoch : 985 || Train Loss : 0.023227188736200333 || Val Loss : 15.873847007751465\n",
      "Epoch : 986 || Train Loss : 0.04798367619514465 || Val Loss : 15.793477058410645\n",
      "Epoch : 987 || Train Loss : 0.028638651594519615 || Val Loss : 15.81641960144043\n",
      "Epoch : 988 || Train Loss : 0.027132157236337662 || Val Loss : 15.912752151489258\n",
      "Epoch : 989 || Train Loss : 0.03682441636919975 || Val Loss : 15.771537780761719\n",
      "Epoch : 990 || Train Loss : 0.030380835756659508 || Val Loss : 15.813943862915039\n",
      "Epoch : 991 || Train Loss : 0.026038968935608864 || Val Loss : 15.761662483215332\n",
      "Epoch : 992 || Train Loss : 0.03095838986337185 || Val Loss : 15.788064002990723\n",
      "Epoch : 993 || Train Loss : 0.027101978659629822 || Val Loss : 15.865327835083008\n",
      "Epoch : 994 || Train Loss : 0.03225186467170715 || Val Loss : 15.852669715881348\n",
      "Epoch : 995 || Train Loss : 0.022140955552458763 || Val Loss : 15.820207595825195\n",
      "Epoch : 996 || Train Loss : 0.026733029633760452 || Val Loss : 15.880243301391602\n",
      "Epoch : 997 || Train Loss : 0.02604563906788826 || Val Loss : 15.79179573059082\n",
      "Epoch : 998 || Train Loss : 0.0409080870449543 || Val Loss : 15.930840492248535\n",
      "Epoch : 999 || Train Loss : 0.0332660973072052 || Val Loss : 15.859322547912598\n",
      "Epoch : 1000 || Train Loss : 0.03550402447581291 || Val Loss : 15.789423942565918\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    curr_tr_loss = 0\n",
    "    curr_val_loss = 0\n",
    "    for X,y in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        output = model(X)\n",
    "        loss = loss_function(output.view(-1), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        curr_tr_loss += loss.div(train_batch_size)\n",
    "    train_losses.append(curr_tr_loss.div(len(train_dataloader)).item())\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #validation:\n",
    "    for X,y in val_dataloader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        output = model(X)\n",
    "        loss = loss_function(output.view(-1), y)\n",
    "\n",
    "        curr_val_loss += loss.div(val_batch_size)\n",
    "    val_losses.append(curr_val_loss.div(len(val_dataloader)).item())\n",
    "    \n",
    "    print(f'Epoch : {e} || Train Loss : {curr_tr_loss.div(len(train_dataloader)).item()} || Val Loss : {curr_val_loss.div(len(val_dataloader)).item()}')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e00c6c5-0aea-402c-959d-2c00153c30a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2)=plt.subplots(1,2)\n",
    "ax1.plot(train_losses)\n",
    "ax2.plot(val_losses)\n",
    "ax1.set_title(\"Train Loss\")\n",
    "ax2.set_title(\"Val Loss\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.tight_layout()\n",
    "fig.savefig('DLSLab1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dcc08a5-46a6-4192-881b-907762bdf9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_hidden, num_inputs, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm1 = nn.LSTM(hidden_size=num_hidden,input_size = num_inputs, num_layers = num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size =num_hidden, hidden_size=num_hidden, num_layers = num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(num_hidden,512)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(512,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(f'Input size : {x.size()}')\n",
    "        num_samples = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, num_samples, self.num_hidden).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, num_samples, self.num_hidden).requires_grad_()\n",
    "        h0,c0 = h0.to(device), c0.to(device)\n",
    "        #print(f'Hidden State size : {h0.size()}')\n",
    "        #print(f'Context vector size : {c0.size()}')\n",
    "        out, (hn, cn) = self.lstm1(x, (h0.detach(), c0.detach()))\n",
    "        #print(f' LSTM output size : {out.size()}')\n",
    "        #print(f'FC input size {out[:,:,-1].size()}')\n",
    "        out = self.fc1(out[:,-1,:])\n",
    "        #print(f'FC1 output size : {out.size()}')\n",
    "        out = self.fc2(out)\n",
    "        #print(f'Final output size : {out.size()}')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b8d8fb8-8778-4027-ab28-816f51eaaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 512\n",
    "num_layers = 5\n",
    "model = LSTM(num_hidden,1, num_layers).to(device)\n",
    "model.train()\n",
    "lr = 0.00001\n",
    "optimizer = optim.SGD(model.parameters(),lr = lr,weight_decay =1e-3)\n",
    "loss_function = nn.MSELoss()\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a17df7e9-1095-4311-8262-c4805a609613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm1): LSTM(1, 512, num_layers=5, batch_first=True)\n",
      "  (lstm2): LSTM(512, 512, num_layers=5, batch_first=True)\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8841476-e2dd-4a13-a27c-c3447c608417",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 || Train Loss : 4.3708600997924805 || Val Loss : 34.71645736694336\n",
      "Epoch : 2 || Train Loss : 4.33778190612793 || Val Loss : 34.71269989013672\n",
      "Epoch : 3 || Train Loss : 4.751068592071533 || Val Loss : 34.70872116088867\n",
      "Epoch : 4 || Train Loss : 4.777568340301514 || Val Loss : 34.70473861694336\n",
      "Epoch : 5 || Train Loss : 4.264047145843506 || Val Loss : 34.70100784301758\n",
      "Epoch : 6 || Train Loss : 4.457099437713623 || Val Loss : 34.69715118408203\n",
      "Epoch : 7 || Train Loss : 4.604611873626709 || Val Loss : 34.6932487487793\n",
      "Epoch : 8 || Train Loss : 4.340853214263916 || Val Loss : 34.68946838378906\n",
      "Epoch : 9 || Train Loss : 4.680459499359131 || Val Loss : 34.68553924560547\n",
      "Epoch : 10 || Train Loss : 4.568441867828369 || Val Loss : 34.6816291809082\n",
      "Epoch : 11 || Train Loss : 4.371097564697266 || Val Loss : 34.67782974243164\n",
      "Epoch : 12 || Train Loss : 4.532794952392578 || Val Loss : 34.67393493652344\n",
      "Epoch : 13 || Train Loss : 4.428988456726074 || Val Loss : 34.67012405395508\n",
      "Epoch : 14 || Train Loss : 4.429842948913574 || Val Loss : 34.66631317138672\n",
      "Epoch : 15 || Train Loss : 4.480157852172852 || Val Loss : 34.662445068359375\n",
      "Epoch : 16 || Train Loss : 4.648146152496338 || Val Loss : 34.65850830078125\n",
      "Epoch : 17 || Train Loss : 4.31677770614624 || Val Loss : 34.65475082397461\n",
      "Epoch : 18 || Train Loss : 4.662635326385498 || Val Loss : 34.65078353881836\n",
      "Epoch : 19 || Train Loss : 4.579474449157715 || Val Loss : 34.64686965942383\n",
      "Epoch : 20 || Train Loss : 4.293593883514404 || Val Loss : 34.64310073852539\n",
      "Epoch : 21 || Train Loss : 4.441234111785889 || Val Loss : 34.639244079589844\n",
      "Epoch : 22 || Train Loss : 4.4926557540893555 || Val Loss : 34.635345458984375\n",
      "Epoch : 23 || Train Loss : 4.810025691986084 || Val Loss : 34.63132095336914\n",
      "Epoch : 24 || Train Loss : 4.517297267913818 || Val Loss : 34.62744140625\n",
      "Epoch : 25 || Train Loss : 4.591839790344238 || Val Loss : 34.62349319458008\n",
      "Epoch : 26 || Train Loss : 4.213979244232178 || Val Loss : 34.61973190307617\n",
      "Epoch : 27 || Train Loss : 4.372338771820068 || Val Loss : 34.61591339111328\n",
      "Epoch : 28 || Train Loss : 4.5204572677612305 || Val Loss : 34.6120491027832\n",
      "Epoch : 29 || Train Loss : 4.431085109710693 || Val Loss : 34.608158111572266\n",
      "Epoch : 30 || Train Loss : 4.4306511878967285 || Val Loss : 34.604270935058594\n",
      "Epoch : 31 || Train Loss : 4.514115810394287 || Val Loss : 34.600372314453125\n",
      "Epoch : 32 || Train Loss : 4.502480983734131 || Val Loss : 34.59647750854492\n",
      "Epoch : 33 || Train Loss : 4.583479881286621 || Val Loss : 34.59251022338867\n",
      "Epoch : 34 || Train Loss : 4.504782199859619 || Val Loss : 34.58858108520508\n",
      "Epoch : 35 || Train Loss : 4.279469966888428 || Val Loss : 34.584747314453125\n",
      "Epoch : 36 || Train Loss : 4.353578567504883 || Val Loss : 34.58086395263672\n",
      "Epoch : 37 || Train Loss : 4.4768571853637695 || Val Loss : 34.5768928527832\n",
      "Epoch : 38 || Train Loss : 4.263319969177246 || Val Loss : 34.57305908203125\n",
      "Epoch : 39 || Train Loss : 4.189888954162598 || Val Loss : 34.56924819946289\n",
      "Epoch : 40 || Train Loss : 4.488190650939941 || Val Loss : 34.56526565551758\n",
      "Epoch : 41 || Train Loss : 4.295144557952881 || Val Loss : 34.5614013671875\n",
      "Epoch : 42 || Train Loss : 4.377110958099365 || Val Loss : 34.557491302490234\n",
      "Epoch : 43 || Train Loss : 4.396961212158203 || Val Loss : 34.553550720214844\n",
      "Epoch : 44 || Train Loss : 4.497111797332764 || Val Loss : 34.54958724975586\n",
      "Epoch : 45 || Train Loss : 4.295389652252197 || Val Loss : 34.54569625854492\n",
      "Epoch : 46 || Train Loss : 4.349985599517822 || Val Loss : 34.541744232177734\n",
      "Epoch : 47 || Train Loss : 4.395538330078125 || Val Loss : 34.53776931762695\n",
      "Epoch : 48 || Train Loss : 4.394658088684082 || Val Loss : 34.53378677368164\n",
      "Epoch : 49 || Train Loss : 4.226853370666504 || Val Loss : 34.529884338378906\n",
      "Epoch : 50 || Train Loss : 4.654719829559326 || Val Loss : 34.525760650634766\n",
      "Epoch : 51 || Train Loss : 4.46834135055542 || Val Loss : 34.52170181274414\n",
      "Epoch : 52 || Train Loss : 4.402303218841553 || Val Loss : 34.5176887512207\n",
      "Epoch : 53 || Train Loss : 4.291712760925293 || Val Loss : 34.51376724243164\n",
      "Epoch : 54 || Train Loss : 4.346702575683594 || Val Loss : 34.5097770690918\n",
      "Epoch : 55 || Train Loss : 4.333868026733398 || Val Loss : 34.50579071044922\n",
      "Epoch : 56 || Train Loss : 4.19985818862915 || Val Loss : 34.50185775756836\n",
      "Epoch : 57 || Train Loss : 4.4789814949035645 || Val Loss : 34.49775314331055\n",
      "Epoch : 58 || Train Loss : 4.373933792114258 || Val Loss : 34.49372863769531\n",
      "Epoch : 59 || Train Loss : 4.311234474182129 || Val Loss : 34.489681243896484\n",
      "Epoch : 60 || Train Loss : 4.616331577301025 || Val Loss : 34.48550033569336\n",
      "Epoch : 61 || Train Loss : 4.2376017570495605 || Val Loss : 34.48146057128906\n",
      "Epoch : 62 || Train Loss : 4.405454635620117 || Val Loss : 34.47732162475586\n",
      "Epoch : 63 || Train Loss : 4.472048759460449 || Val Loss : 34.473114013671875\n",
      "Epoch : 64 || Train Loss : 4.224372863769531 || Val Loss : 34.46907043457031\n",
      "Epoch : 65 || Train Loss : 4.461864948272705 || Val Loss : 34.46488952636719\n",
      "Epoch : 66 || Train Loss : 4.270175933837891 || Val Loss : 34.460784912109375\n",
      "Epoch : 67 || Train Loss : 4.684491157531738 || Val Loss : 34.45648193359375\n",
      "Epoch : 68 || Train Loss : 4.227808952331543 || Val Loss : 34.45237731933594\n",
      "Epoch : 69 || Train Loss : 4.48376989364624 || Val Loss : 34.448116302490234\n",
      "Epoch : 70 || Train Loss : 4.423366546630859 || Val Loss : 34.44390106201172\n",
      "Epoch : 71 || Train Loss : 4.2650885581970215 || Val Loss : 34.43980407714844\n",
      "Epoch : 72 || Train Loss : 4.667843341827393 || Val Loss : 34.43540573120117\n",
      "Epoch : 73 || Train Loss : 4.405091762542725 || Val Loss : 34.43113327026367\n",
      "Epoch : 74 || Train Loss : 4.3110151290893555 || Val Loss : 34.42690658569336\n",
      "Epoch : 75 || Train Loss : 4.167214393615723 || Val Loss : 34.422786712646484\n",
      "Epoch : 76 || Train Loss : 4.4343438148498535 || Val Loss : 34.41850662231445\n",
      "Epoch : 77 || Train Loss : 4.481822490692139 || Val Loss : 34.414146423339844\n",
      "Epoch : 78 || Train Loss : 4.283084869384766 || Val Loss : 34.40988540649414\n",
      "Epoch : 79 || Train Loss : 4.446237564086914 || Val Loss : 34.4055061340332\n",
      "Epoch : 80 || Train Loss : 4.409718036651611 || Val Loss : 34.40118408203125\n",
      "Epoch : 81 || Train Loss : 4.435948848724365 || Val Loss : 34.39680862426758\n",
      "Epoch : 82 || Train Loss : 4.385540962219238 || Val Loss : 34.39240646362305\n",
      "Epoch : 83 || Train Loss : 4.302700042724609 || Val Loss : 34.388023376464844\n",
      "Epoch : 84 || Train Loss : 4.369937419891357 || Val Loss : 34.38360595703125\n",
      "Epoch : 85 || Train Loss : 4.274547100067139 || Val Loss : 34.37919616699219\n",
      "Epoch : 86 || Train Loss : 4.515109539031982 || Val Loss : 34.3746337890625\n",
      "Epoch : 87 || Train Loss : 4.304640293121338 || Val Loss : 34.37018585205078\n",
      "Epoch : 88 || Train Loss : 4.3632025718688965 || Val Loss : 34.36572265625\n",
      "Epoch : 89 || Train Loss : 4.347714424133301 || Val Loss : 34.361228942871094\n",
      "Epoch : 90 || Train Loss : 3.977442502975464 || Val Loss : 34.35695266723633\n",
      "Epoch : 91 || Train Loss : 4.538946628570557 || Val Loss : 34.35233688354492\n",
      "Epoch : 92 || Train Loss : 4.369637966156006 || Val Loss : 34.3477897644043\n",
      "Epoch : 93 || Train Loss : 4.4810895919799805 || Val Loss : 34.34316635131836\n",
      "Epoch : 94 || Train Loss : 4.420450687408447 || Val Loss : 34.338539123535156\n",
      "Epoch : 95 || Train Loss : 4.374409198760986 || Val Loss : 34.33392333984375\n",
      "Epoch : 96 || Train Loss : 4.3196258544921875 || Val Loss : 34.32931137084961\n",
      "Epoch : 97 || Train Loss : 4.372103214263916 || Val Loss : 34.324676513671875\n",
      "Epoch : 98 || Train Loss : 4.532216548919678 || Val Loss : 34.319915771484375\n",
      "Epoch : 99 || Train Loss : 4.636728286743164 || Val Loss : 34.31504821777344\n",
      "Epoch : 100 || Train Loss : 4.539488315582275 || Val Loss : 34.31022644042969\n",
      "Epoch : 101 || Train Loss : 4.602890491485596 || Val Loss : 34.30533218383789\n",
      "Epoch : 102 || Train Loss : 4.380759239196777 || Val Loss : 34.30058670043945\n",
      "Epoch : 103 || Train Loss : 4.223830699920654 || Val Loss : 34.295902252197266\n",
      "Epoch : 104 || Train Loss : 4.256226539611816 || Val Loss : 34.29114532470703\n",
      "Epoch : 105 || Train Loss : 4.365872383117676 || Val Loss : 34.286338806152344\n",
      "Epoch : 106 || Train Loss : 4.40067720413208 || Val Loss : 34.28147506713867\n",
      "Epoch : 107 || Train Loss : 4.233117580413818 || Val Loss : 34.27671813964844\n",
      "Epoch : 108 || Train Loss : 4.156169414520264 || Val Loss : 34.272003173828125\n",
      "Epoch : 109 || Train Loss : 4.003234386444092 || Val Loss : 34.267364501953125\n",
      "Epoch : 110 || Train Loss : 4.2709879875183105 || Val Loss : 34.26249313354492\n",
      "Epoch : 111 || Train Loss : 4.268075466156006 || Val Loss : 34.25759506225586\n",
      "Epoch : 112 || Train Loss : 4.6985182762146 || Val Loss : 34.25238037109375\n",
      "Epoch : 113 || Train Loss : 4.131428241729736 || Val Loss : 34.24747085571289\n",
      "Epoch : 114 || Train Loss : 4.465435981750488 || Val Loss : 34.242366790771484\n",
      "Epoch : 115 || Train Loss : 4.066817283630371 || Val Loss : 34.237525939941406\n",
      "Epoch : 116 || Train Loss : 4.265842914581299 || Val Loss : 34.23248291015625\n",
      "Epoch : 117 || Train Loss : 4.5063300132751465 || Val Loss : 34.227230072021484\n",
      "Epoch : 118 || Train Loss : 4.573393821716309 || Val Loss : 34.22190475463867\n",
      "Epoch : 119 || Train Loss : 4.296583652496338 || Val Loss : 34.21675109863281\n",
      "Epoch : 120 || Train Loss : 4.336191654205322 || Val Loss : 34.211524963378906\n",
      "Epoch : 121 || Train Loss : 4.1455864906311035 || Val Loss : 34.206424713134766\n",
      "Epoch : 122 || Train Loss : 4.36507511138916 || Val Loss : 34.201168060302734\n",
      "Epoch : 123 || Train Loss : 4.1738481521606445 || Val Loss : 34.19601821899414\n",
      "Epoch : 124 || Train Loss : 4.516258239746094 || Val Loss : 34.19055938720703\n",
      "Epoch : 125 || Train Loss : 4.2959818840026855 || Val Loss : 34.18525695800781\n",
      "Epoch : 126 || Train Loss : 4.189389705657959 || Val Loss : 34.17997360229492\n",
      "Epoch : 127 || Train Loss : 4.217680931091309 || Val Loss : 34.1746826171875\n",
      "Epoch : 128 || Train Loss : 4.447145462036133 || Val Loss : 34.16912841796875\n",
      "Epoch : 129 || Train Loss : 4.524383544921875 || Val Loss : 34.16355514526367\n",
      "Epoch : 130 || Train Loss : 4.416797637939453 || Val Loss : 34.15795135498047\n",
      "Epoch : 131 || Train Loss : 4.1476263999938965 || Val Loss : 34.15255355834961\n",
      "Epoch : 132 || Train Loss : 4.124855995178223 || Val Loss : 34.14711380004883\n",
      "Epoch : 133 || Train Loss : 4.328493595123291 || Val Loss : 34.14156723022461\n",
      "Epoch : 134 || Train Loss : 4.18253231048584 || Val Loss : 34.136009216308594\n",
      "Epoch : 135 || Train Loss : 4.153554439544678 || Val Loss : 34.130455017089844\n",
      "Epoch : 136 || Train Loss : 4.310091972351074 || Val Loss : 34.12472915649414\n",
      "Epoch : 137 || Train Loss : 4.216283321380615 || Val Loss : 34.1190185546875\n",
      "Epoch : 138 || Train Loss : 4.0288166999816895 || Val Loss : 34.113433837890625\n",
      "Epoch : 139 || Train Loss : 4.296505928039551 || Val Loss : 34.107627868652344\n",
      "Epoch : 140 || Train Loss : 4.322844982147217 || Val Loss : 34.10174560546875\n",
      "Epoch : 141 || Train Loss : 4.196822166442871 || Val Loss : 34.09587860107422\n",
      "Epoch : 142 || Train Loss : 4.360185146331787 || Val Loss : 34.08987045288086\n",
      "Epoch : 143 || Train Loss : 4.132708549499512 || Val Loss : 34.084014892578125\n",
      "Epoch : 144 || Train Loss : 4.4735236167907715 || Val Loss : 34.077850341796875\n",
      "Epoch : 145 || Train Loss : 4.094231605529785 || Val Loss : 34.071956634521484\n",
      "Epoch : 146 || Train Loss : 4.437105655670166 || Val Loss : 34.0656623840332\n",
      "Epoch : 147 || Train Loss : 4.289845943450928 || Val Loss : 34.05948257446289\n",
      "Epoch : 148 || Train Loss : 4.224114418029785 || Val Loss : 34.053314208984375\n",
      "Epoch : 149 || Train Loss : 4.094006538391113 || Val Loss : 34.04720687866211\n",
      "Epoch : 150 || Train Loss : 4.195619106292725 || Val Loss : 34.041072845458984\n",
      "Epoch : 151 || Train Loss : 4.396938800811768 || Val Loss : 34.034664154052734\n",
      "Epoch : 152 || Train Loss : 4.211558818817139 || Val Loss : 34.028350830078125\n",
      "Epoch : 153 || Train Loss : 4.130306720733643 || Val Loss : 34.022098541259766\n",
      "Epoch : 154 || Train Loss : 4.355230808258057 || Val Loss : 34.01560592651367\n",
      "Epoch : 155 || Train Loss : 4.570550441741943 || Val Loss : 34.00883483886719\n",
      "Epoch : 156 || Train Loss : 4.467105865478516 || Val Loss : 34.002132415771484\n",
      "Epoch : 157 || Train Loss : 4.312811374664307 || Val Loss : 33.99551010131836\n",
      "Epoch : 158 || Train Loss : 4.179894924163818 || Val Loss : 33.98894500732422\n",
      "Epoch : 159 || Train Loss : 4.568051815032959 || Val Loss : 33.98198699951172\n",
      "Epoch : 160 || Train Loss : 4.556343078613281 || Val Loss : 33.97502899169922\n",
      "Epoch : 161 || Train Loss : 4.20354700088501 || Val Loss : 33.96833419799805\n",
      "Epoch : 162 || Train Loss : 4.3143391609191895 || Val Loss : 33.961421966552734\n",
      "Epoch : 163 || Train Loss : 4.197925090789795 || Val Loss : 33.954532623291016\n",
      "Epoch : 164 || Train Loss : 4.613410949707031 || Val Loss : 33.94720458984375\n",
      "Epoch : 165 || Train Loss : 4.128598213195801 || Val Loss : 33.94032287597656\n",
      "Epoch : 166 || Train Loss : 4.284112453460693 || Val Loss : 33.933250427246094\n",
      "Epoch : 167 || Train Loss : 4.29796838760376 || Val Loss : 33.926029205322266\n",
      "Epoch : 168 || Train Loss : 4.263243198394775 || Val Loss : 33.91880416870117\n",
      "Epoch : 169 || Train Loss : 4.295700550079346 || Val Loss : 33.91154861450195\n",
      "Epoch : 170 || Train Loss : 4.245977878570557 || Val Loss : 33.90421676635742\n",
      "Epoch : 171 || Train Loss : 4.1783318519592285 || Val Loss : 33.89695358276367\n",
      "Epoch : 172 || Train Loss : 3.9969234466552734 || Val Loss : 33.889766693115234\n",
      "Epoch : 173 || Train Loss : 4.514173984527588 || Val Loss : 33.88200378417969\n",
      "Epoch : 174 || Train Loss : 4.179227352142334 || Val Loss : 33.87453079223633\n",
      "Epoch : 175 || Train Loss : 4.174549102783203 || Val Loss : 33.86691665649414\n",
      "Epoch : 176 || Train Loss : 4.207549571990967 || Val Loss : 33.859283447265625\n",
      "Epoch : 177 || Train Loss : 4.286426067352295 || Val Loss : 33.85139465332031\n",
      "Epoch : 178 || Train Loss : 4.2624430656433105 || Val Loss : 33.84353256225586\n",
      "Epoch : 179 || Train Loss : 4.145765781402588 || Val Loss : 33.83572769165039\n",
      "Epoch : 180 || Train Loss : 4.262103080749512 || Val Loss : 33.82770538330078\n",
      "Epoch : 181 || Train Loss : 3.977686643600464 || Val Loss : 33.8199348449707\n",
      "Epoch : 182 || Train Loss : 4.131825923919678 || Val Loss : 33.81192398071289\n",
      "Epoch : 183 || Train Loss : 4.1873087882995605 || Val Loss : 33.80381393432617\n",
      "Epoch : 184 || Train Loss : 4.290747165679932 || Val Loss : 33.79544448852539\n",
      "Epoch : 185 || Train Loss : 4.221798896789551 || Val Loss : 33.78702163696289\n",
      "Epoch : 186 || Train Loss : 4.436600685119629 || Val Loss : 33.77840042114258\n",
      "Epoch : 187 || Train Loss : 4.231990337371826 || Val Loss : 33.76980209350586\n",
      "Epoch : 188 || Train Loss : 4.104478359222412 || Val Loss : 33.76134490966797\n",
      "Epoch : 189 || Train Loss : 4.227222442626953 || Val Loss : 33.752681732177734\n",
      "Epoch : 190 || Train Loss : 4.211499214172363 || Val Loss : 33.74392318725586\n",
      "Epoch : 191 || Train Loss : 4.368087291717529 || Val Loss : 33.734886169433594\n",
      "Epoch : 192 || Train Loss : 4.241302490234375 || Val Loss : 33.72585678100586\n",
      "Epoch : 193 || Train Loss : 4.202579021453857 || Val Loss : 33.71684646606445\n",
      "Epoch : 194 || Train Loss : 4.12864875793457 || Val Loss : 33.70782470703125\n",
      "Epoch : 195 || Train Loss : 4.342273235321045 || Val Loss : 33.69835662841797\n",
      "Epoch : 196 || Train Loss : 4.185849666595459 || Val Loss : 33.689064025878906\n",
      "Epoch : 197 || Train Loss : 4.2309417724609375 || Val Loss : 33.67958450317383\n",
      "Epoch : 198 || Train Loss : 4.415572166442871 || Val Loss : 33.66965866088867\n",
      "Epoch : 199 || Train Loss : 4.005795478820801 || Val Loss : 33.66025161743164\n",
      "Epoch : 200 || Train Loss : 4.036525249481201 || Val Loss : 33.65070724487305\n",
      "Epoch : 201 || Train Loss : 4.3874664306640625 || Val Loss : 33.640621185302734\n",
      "Epoch : 202 || Train Loss : 4.476811408996582 || Val Loss : 33.63028335571289\n",
      "Epoch : 203 || Train Loss : 4.069487571716309 || Val Loss : 33.62031555175781\n",
      "Epoch : 204 || Train Loss : 4.23521614074707 || Val Loss : 33.61009979248047\n",
      "Epoch : 205 || Train Loss : 4.172110080718994 || Val Loss : 33.59970474243164\n",
      "Epoch : 206 || Train Loss : 4.028433322906494 || Val Loss : 33.58949279785156\n",
      "Epoch : 207 || Train Loss : 4.083820343017578 || Val Loss : 33.579097747802734\n",
      "Epoch : 208 || Train Loss : 4.193755626678467 || Val Loss : 33.568458557128906\n",
      "Epoch : 209 || Train Loss : 4.170054912567139 || Val Loss : 33.55762481689453\n",
      "Epoch : 210 || Train Loss : 4.243236541748047 || Val Loss : 33.5466423034668\n",
      "Epoch : 211 || Train Loss : 4.188817501068115 || Val Loss : 33.53553771972656\n",
      "Epoch : 212 || Train Loss : 3.8252079486846924 || Val Loss : 33.52495193481445\n",
      "Epoch : 213 || Train Loss : 3.8926472663879395 || Val Loss : 33.514095306396484\n",
      "Epoch : 214 || Train Loss : 4.241218566894531 || Val Loss : 33.50261688232422\n",
      "Epoch : 215 || Train Loss : 4.237117290496826 || Val Loss : 33.49097442626953\n",
      "Epoch : 216 || Train Loss : 4.0248870849609375 || Val Loss : 33.47944641113281\n",
      "Epoch : 217 || Train Loss : 4.02979040145874 || Val Loss : 33.46772766113281\n",
      "Epoch : 218 || Train Loss : 4.259044647216797 || Val Loss : 33.45553207397461\n",
      "Epoch : 219 || Train Loss : 4.00078010559082 || Val Loss : 33.443626403808594\n",
      "Epoch : 220 || Train Loss : 4.186453342437744 || Val Loss : 33.431148529052734\n",
      "Epoch : 221 || Train Loss : 4.086544990539551 || Val Loss : 33.41868591308594\n",
      "Epoch : 222 || Train Loss : 4.0613837242126465 || Val Loss : 33.40618133544922\n",
      "Epoch : 223 || Train Loss : 3.9535224437713623 || Val Loss : 33.393760681152344\n",
      "Epoch : 224 || Train Loss : 4.027585506439209 || Val Loss : 33.38090133666992\n",
      "Epoch : 225 || Train Loss : 4.148746490478516 || Val Loss : 33.36762619018555\n",
      "Epoch : 226 || Train Loss : 3.748553991317749 || Val Loss : 33.35506820678711\n",
      "Epoch : 227 || Train Loss : 3.960486650466919 || Val Loss : 33.341819763183594\n",
      "Epoch : 228 || Train Loss : 4.493210792541504 || Val Loss : 33.327335357666016\n",
      "Epoch : 229 || Train Loss : 3.8750343322753906 || Val Loss : 33.313785552978516\n",
      "Epoch : 230 || Train Loss : 4.123700141906738 || Val Loss : 33.29977035522461\n",
      "Epoch : 231 || Train Loss : 3.9840781688690186 || Val Loss : 33.28566360473633\n",
      "Epoch : 232 || Train Loss : 4.032468795776367 || Val Loss : 33.271263122558594\n",
      "Epoch : 233 || Train Loss : 3.9597890377044678 || Val Loss : 33.25675582885742\n",
      "Epoch : 234 || Train Loss : 4.0954718589782715 || Val Loss : 33.24174118041992\n",
      "Epoch : 235 || Train Loss : 4.012274265289307 || Val Loss : 33.226783752441406\n",
      "Epoch : 236 || Train Loss : 4.2246809005737305 || Val Loss : 33.2109260559082\n",
      "Epoch : 237 || Train Loss : 4.078326225280762 || Val Loss : 33.19539260864258\n",
      "Epoch : 238 || Train Loss : 3.9003407955169678 || Val Loss : 33.17988967895508\n",
      "Epoch : 239 || Train Loss : 3.809404134750366 || Val Loss : 33.16438293457031\n",
      "Epoch : 240 || Train Loss : 3.938197374343872 || Val Loss : 33.14829635620117\n",
      "Epoch : 241 || Train Loss : 4.165454864501953 || Val Loss : 33.1312370300293\n",
      "Epoch : 242 || Train Loss : 3.943084716796875 || Val Loss : 33.11451721191406\n",
      "Epoch : 243 || Train Loss : 3.985441207885742 || Val Loss : 33.09735107421875\n",
      "Epoch : 244 || Train Loss : 3.838548421859741 || Val Loss : 33.08039474487305\n",
      "Epoch : 245 || Train Loss : 3.9127814769744873 || Val Loss : 33.06303787231445\n",
      "Epoch : 246 || Train Loss : 3.9915168285369873 || Val Loss : 33.045082092285156\n",
      "Epoch : 247 || Train Loss : 4.17879581451416 || Val Loss : 33.02627182006836\n",
      "Epoch : 248 || Train Loss : 4.061187744140625 || Val Loss : 33.007347106933594\n",
      "Epoch : 249 || Train Loss : 3.9179253578186035 || Val Loss : 32.988521575927734\n",
      "Epoch : 250 || Train Loss : 3.930483341217041 || Val Loss : 32.96937561035156\n",
      "Epoch : 251 || Train Loss : 3.7861313819885254 || Val Loss : 32.95020294189453\n",
      "Epoch : 252 || Train Loss : 3.975203037261963 || Val Loss : 32.93025207519531\n",
      "Epoch : 253 || Train Loss : 4.117410182952881 || Val Loss : 32.9095573425293\n",
      "Epoch : 254 || Train Loss : 4.160220146179199 || Val Loss : 32.88835525512695\n",
      "Epoch : 255 || Train Loss : 4.257732391357422 || Val Loss : 32.866485595703125\n",
      "Epoch : 256 || Train Loss : 4.036468982696533 || Val Loss : 32.84452438354492\n",
      "Epoch : 257 || Train Loss : 4.187695026397705 || Val Loss : 32.82194900512695\n",
      "Epoch : 258 || Train Loss : 4.061938762664795 || Val Loss : 32.79890060424805\n",
      "Epoch : 259 || Train Loss : 3.9765822887420654 || Val Loss : 32.77568817138672\n",
      "Epoch : 260 || Train Loss : 3.8875985145568848 || Val Loss : 32.7523193359375\n",
      "Epoch : 261 || Train Loss : 3.818232774734497 || Val Loss : 32.72876739501953\n",
      "Epoch : 262 || Train Loss : 3.9766438007354736 || Val Loss : 32.70390701293945\n",
      "Epoch : 263 || Train Loss : 3.89715313911438 || Val Loss : 32.678871154785156\n",
      "Epoch : 264 || Train Loss : 3.760855197906494 || Val Loss : 32.65382766723633\n",
      "Epoch : 265 || Train Loss : 3.847539186477661 || Val Loss : 32.62794494628906\n",
      "Epoch : 266 || Train Loss : 3.853541612625122 || Val Loss : 32.601531982421875\n",
      "Epoch : 267 || Train Loss : 4.121572494506836 || Val Loss : 32.57337188720703\n",
      "Epoch : 268 || Train Loss : 3.9143924713134766 || Val Loss : 32.54570007324219\n",
      "Epoch : 269 || Train Loss : 3.6377499103546143 || Val Loss : 32.518165588378906\n",
      "Epoch : 270 || Train Loss : 3.7043254375457764 || Val Loss : 32.49015808105469\n",
      "Epoch : 271 || Train Loss : 3.820272445678711 || Val Loss : 32.46042251586914\n",
      "Epoch : 272 || Train Loss : 3.9443867206573486 || Val Loss : 32.42934036254883\n",
      "Epoch : 273 || Train Loss : 3.9557597637176514 || Val Loss : 32.3974494934082\n",
      "Epoch : 274 || Train Loss : 3.8185651302337646 || Val Loss : 32.36545181274414\n",
      "Epoch : 275 || Train Loss : 3.6307544708251953 || Val Loss : 32.33379364013672\n",
      "Epoch : 276 || Train Loss : 3.5827014446258545 || Val Loss : 32.30112838745117\n",
      "Epoch : 277 || Train Loss : 3.8977630138397217 || Val Loss : 32.265968322753906\n",
      "Epoch : 278 || Train Loss : 3.9151580333709717 || Val Loss : 32.22956085205078\n",
      "Epoch : 279 || Train Loss : 3.567354679107666 || Val Loss : 32.19432067871094\n",
      "Epoch : 280 || Train Loss : 3.6838290691375732 || Val Loss : 32.15693283081055\n",
      "Epoch : 281 || Train Loss : 3.5939319133758545 || Val Loss : 32.11931610107422\n",
      "Epoch : 282 || Train Loss : 3.8006043434143066 || Val Loss : 32.07890701293945\n",
      "Epoch : 283 || Train Loss : 3.8208298683166504 || Val Loss : 32.036827087402344\n",
      "Epoch : 284 || Train Loss : 3.7250001430511475 || Val Loss : 31.994844436645508\n",
      "Epoch : 285 || Train Loss : 3.4485490322113037 || Val Loss : 31.953447341918945\n",
      "Epoch : 286 || Train Loss : 3.5932393074035645 || Val Loss : 31.90977668762207\n",
      "Epoch : 287 || Train Loss : 3.741375684738159 || Val Loss : 31.86312484741211\n",
      "Epoch : 288 || Train Loss : 3.8295915126800537 || Val Loss : 31.81361198425293\n",
      "Epoch : 289 || Train Loss : 3.609570264816284 || Val Loss : 31.765066146850586\n",
      "Epoch : 290 || Train Loss : 3.737908124923706 || Val Loss : 31.712921142578125\n",
      "Epoch : 291 || Train Loss : 3.6551406383514404 || Val Loss : 31.65980339050293\n",
      "Epoch : 292 || Train Loss : 3.5853517055511475 || Val Loss : 31.605300903320312\n",
      "Epoch : 293 || Train Loss : 3.6344354152679443 || Val Loss : 31.547557830810547\n",
      "Epoch : 294 || Train Loss : 3.7216897010803223 || Val Loss : 31.486515045166016\n",
      "Epoch : 295 || Train Loss : 3.421917676925659 || Val Loss : 31.427047729492188\n",
      "Epoch : 296 || Train Loss : 3.8295083045959473 || Val Loss : 31.36072540283203\n",
      "Epoch : 297 || Train Loss : 3.411181688308716 || Val Loss : 31.2960205078125\n",
      "Epoch : 298 || Train Loss : 3.4638421535491943 || Val Loss : 31.227201461791992\n",
      "Epoch : 299 || Train Loss : 3.5762898921966553 || Val Loss : 31.154762268066406\n",
      "Epoch : 300 || Train Loss : 3.3024849891662598 || Val Loss : 31.082950592041016\n",
      "Epoch : 301 || Train Loss : 3.287654161453247 || Val Loss : 31.00780487060547\n",
      "Epoch : 302 || Train Loss : 3.332702398300171 || Val Loss : 30.928579330444336\n",
      "Epoch : 303 || Train Loss : 3.377577543258667 || Val Loss : 30.844297409057617\n",
      "Epoch : 304 || Train Loss : 3.219635009765625 || Val Loss : 30.759157180786133\n",
      "Epoch : 305 || Train Loss : 3.268742799758911 || Val Loss : 30.66938591003418\n",
      "Epoch : 306 || Train Loss : 3.4502925872802734 || Val Loss : 30.569625854492188\n",
      "Epoch : 307 || Train Loss : 3.4388275146484375 || Val Loss : 30.465028762817383\n",
      "Epoch : 308 || Train Loss : 3.2819173336029053 || Val Loss : 30.357271194458008\n",
      "Epoch : 309 || Train Loss : 3.324737310409546 || Val Loss : 30.245424270629883\n",
      "Epoch : 310 || Train Loss : 3.2191312313079834 || Val Loss : 30.128734588623047\n",
      "Epoch : 311 || Train Loss : 3.121467351913452 || Val Loss : 30.008075714111328\n",
      "Epoch : 312 || Train Loss : 3.0704550743103027 || Val Loss : 29.882606506347656\n",
      "Epoch : 313 || Train Loss : 3.342529296875 || Val Loss : 29.740251541137695\n",
      "Epoch : 314 || Train Loss : 2.86208176612854 || Val Loss : 29.604156494140625\n",
      "Epoch : 315 || Train Loss : 2.8387534618377686 || Val Loss : 29.461156845092773\n",
      "Epoch : 316 || Train Loss : 3.074126958847046 || Val Loss : 29.300804138183594\n",
      "Epoch : 317 || Train Loss : 3.285165548324585 || Val Loss : 29.121828079223633\n",
      "Epoch : 318 || Train Loss : 3.1550538539886475 || Val Loss : 28.93705940246582\n",
      "Epoch : 319 || Train Loss : 2.9154956340789795 || Val Loss : 28.751285552978516\n",
      "Epoch : 320 || Train Loss : 2.669699192047119 || Val Loss : 28.565397262573242\n",
      "Epoch : 321 || Train Loss : 2.7812092304229736 || Val Loss : 28.36232566833496\n",
      "Epoch : 322 || Train Loss : 2.7062251567840576 || Val Loss : 28.147659301757812\n",
      "Epoch : 323 || Train Loss : 2.4985172748565674 || Val Loss : 27.937116622924805\n",
      "Epoch : 324 || Train Loss : 2.7764575481414795 || Val Loss : 27.692913055419922\n",
      "Epoch : 325 || Train Loss : 2.678187608718872 || Val Loss : 27.438634872436523\n",
      "Epoch : 326 || Train Loss : 2.4822733402252197 || Val Loss : 27.182613372802734\n",
      "Epoch : 327 || Train Loss : 2.6480884552001953 || Val Loss : 26.9011287689209\n",
      "Epoch : 328 || Train Loss : 2.294670820236206 || Val Loss : 26.630107879638672\n",
      "Epoch : 329 || Train Loss : 2.2448925971984863 || Val Loss : 26.354434967041016\n",
      "Epoch : 330 || Train Loss : 2.369558334350586 || Val Loss : 26.038373947143555\n",
      "Epoch : 331 || Train Loss : 2.130220413208008 || Val Loss : 25.7398624420166\n",
      "Epoch : 332 || Train Loss : 2.1474461555480957 || Val Loss : 25.4222354888916\n",
      "Epoch : 333 || Train Loss : 2.207524538040161 || Val Loss : 25.0795841217041\n",
      "Epoch : 334 || Train Loss : 1.9268935918807983 || Val Loss : 24.760602951049805\n",
      "Epoch : 335 || Train Loss : 1.8779081106185913 || Val Loss : 24.430513381958008\n",
      "Epoch : 336 || Train Loss : 2.00040864944458 || Val Loss : 24.076662063598633\n",
      "Epoch : 337 || Train Loss : 1.6793845891952515 || Val Loss : 23.751205444335938\n",
      "Epoch : 338 || Train Loss : 1.710386872291565 || Val Loss : 23.421953201293945\n",
      "Epoch : 339 || Train Loss : 1.7763630151748657 || Val Loss : 23.066749572753906\n",
      "Epoch : 340 || Train Loss : 1.4936970472335815 || Val Loss : 22.76670265197754\n",
      "Epoch : 341 || Train Loss : 1.6953884363174438 || Val Loss : 22.40061378479004\n",
      "Epoch : 342 || Train Loss : 1.6070759296417236 || Val Loss : 22.060747146606445\n",
      "Epoch : 343 || Train Loss : 1.5589715242385864 || Val Loss : 21.71954345703125\n",
      "Epoch : 344 || Train Loss : 1.5268750190734863 || Val Loss : 21.37202262878418\n",
      "Epoch : 345 || Train Loss : 1.518415927886963 || Val Loss : 21.032371520996094\n",
      "Epoch : 346 || Train Loss : 1.4898873567581177 || Val Loss : 20.718687057495117\n",
      "Epoch : 347 || Train Loss : 1.3244860172271729 || Val Loss : 20.43891143798828\n",
      "Epoch : 348 || Train Loss : 1.476584553718567 || Val Loss : 20.10616111755371\n",
      "Epoch : 349 || Train Loss : 1.2943344116210938 || Val Loss : 19.836427688598633\n",
      "Epoch : 350 || Train Loss : 1.290049433708191 || Val Loss : 19.604915618896484\n",
      "Epoch : 351 || Train Loss : 1.1728299856185913 || Val Loss : 19.395709991455078\n",
      "Epoch : 352 || Train Loss : 1.2126072645187378 || Val Loss : 19.16868019104004\n",
      "Epoch : 353 || Train Loss : 1.2271335124969482 || Val Loss : 18.915895462036133\n",
      "Epoch : 354 || Train Loss : 1.1789222955703735 || Val Loss : 18.701107025146484\n",
      "Epoch : 355 || Train Loss : 1.2253928184509277 || Val Loss : 18.48466682434082\n",
      "Epoch : 356 || Train Loss : 1.2134058475494385 || Val Loss : 18.2327823638916\n",
      "Epoch : 357 || Train Loss : 1.1033438444137573 || Val Loss : 18.08592414855957\n",
      "Epoch : 358 || Train Loss : 1.198193907737732 || Val Loss : 17.910537719726562\n",
      "Epoch : 359 || Train Loss : 1.095594048500061 || Val Loss : 17.74135398864746\n",
      "Epoch : 360 || Train Loss : 1.1299716234207153 || Val Loss : 17.586320877075195\n",
      "Epoch : 361 || Train Loss : 1.1783154010772705 || Val Loss : 17.432592391967773\n",
      "Epoch : 362 || Train Loss : 1.2123230695724487 || Val Loss : 17.251352310180664\n",
      "Epoch : 363 || Train Loss : 1.1082372665405273 || Val Loss : 17.088693618774414\n",
      "Epoch : 364 || Train Loss : 1.0678194761276245 || Val Loss : 16.967456817626953\n",
      "Epoch : 365 || Train Loss : 1.073369026184082 || Val Loss : 16.872953414916992\n",
      "Epoch : 366 || Train Loss : 1.1044872999191284 || Val Loss : 16.77094841003418\n",
      "Epoch : 367 || Train Loss : 1.059676170349121 || Val Loss : 16.68140411376953\n",
      "Epoch : 368 || Train Loss : 1.020538091659546 || Val Loss : 16.634658813476562\n",
      "Epoch : 369 || Train Loss : 1.0819690227508545 || Val Loss : 16.53229331970215\n",
      "Epoch : 370 || Train Loss : 0.9894076585769653 || Val Loss : 16.454322814941406\n",
      "Epoch : 371 || Train Loss : 1.0103644132614136 || Val Loss : 16.37456512451172\n",
      "Epoch : 372 || Train Loss : 1.0149229764938354 || Val Loss : 16.281021118164062\n",
      "Epoch : 373 || Train Loss : 0.9517729878425598 || Val Loss : 16.204147338867188\n",
      "Epoch : 374 || Train Loss : 0.914567768573761 || Val Loss : 16.11699676513672\n",
      "Epoch : 375 || Train Loss : 1.085667610168457 || Val Loss : 15.941868782043457\n",
      "Epoch : 376 || Train Loss : 0.9738836288452148 || Val Loss : 15.861543655395508\n",
      "Epoch : 377 || Train Loss : 0.9367190599441528 || Val Loss : 15.773326873779297\n",
      "Epoch : 378 || Train Loss : 0.8848466277122498 || Val Loss : 15.707968711853027\n",
      "Epoch : 379 || Train Loss : 0.9329757690429688 || Val Loss : 15.551614761352539\n",
      "Epoch : 380 || Train Loss : 0.8806034326553345 || Val Loss : 15.3966646194458\n",
      "Epoch : 381 || Train Loss : 0.9118505716323853 || Val Loss : 15.231213569641113\n",
      "Epoch : 382 || Train Loss : 0.8778613209724426 || Val Loss : 15.092028617858887\n",
      "Epoch : 383 || Train Loss : 0.9028669595718384 || Val Loss : 14.886311531066895\n",
      "Epoch : 384 || Train Loss : 0.8497010469436646 || Val Loss : 14.732705116271973\n",
      "Epoch : 385 || Train Loss : 0.8007848858833313 || Val Loss : 14.660429000854492\n",
      "Epoch : 386 || Train Loss : 0.767763614654541 || Val Loss : 14.534501075744629\n",
      "Epoch : 387 || Train Loss : 0.7452698349952698 || Val Loss : 14.363492012023926\n",
      "Epoch : 388 || Train Loss : 0.7150729894638062 || Val Loss : 14.203446388244629\n",
      "Epoch : 389 || Train Loss : 0.7036003470420837 || Val Loss : 14.068236351013184\n",
      "Epoch : 390 || Train Loss : 0.6587671041488647 || Val Loss : 13.919678688049316\n",
      "Epoch : 391 || Train Loss : 0.6408597826957703 || Val Loss : 13.731279373168945\n",
      "Epoch : 392 || Train Loss : 0.6265881657600403 || Val Loss : 13.56350326538086\n",
      "Epoch : 393 || Train Loss : 0.6202368140220642 || Val Loss : 13.340751647949219\n",
      "Epoch : 394 || Train Loss : 0.5823485255241394 || Val Loss : 13.188334465026855\n",
      "Epoch : 395 || Train Loss : 0.5172227025032043 || Val Loss : 13.031373977661133\n",
      "Epoch : 396 || Train Loss : 0.4978327453136444 || Val Loss : 12.810333251953125\n",
      "Epoch : 397 || Train Loss : 0.5009763240814209 || Val Loss : 12.580373764038086\n",
      "Epoch : 398 || Train Loss : 0.40615740418434143 || Val Loss : 12.410608291625977\n",
      "Epoch : 399 || Train Loss : 0.45037609338760376 || Val Loss : 12.235315322875977\n",
      "Epoch : 400 || Train Loss : 0.3976646661758423 || Val Loss : 12.022865295410156\n",
      "Epoch : 401 || Train Loss : 0.3639698326587677 || Val Loss : 11.810434341430664\n",
      "Epoch : 402 || Train Loss : 0.3240038752555847 || Val Loss : 11.631361961364746\n",
      "Epoch : 403 || Train Loss : 0.33002787828445435 || Val Loss : 11.427498817443848\n",
      "Epoch : 404 || Train Loss : 0.3265269696712494 || Val Loss : 11.17923641204834\n",
      "Epoch : 405 || Train Loss : 0.27160292863845825 || Val Loss : 10.990285873413086\n",
      "Epoch : 406 || Train Loss : 0.2835005819797516 || Val Loss : 10.781570434570312\n",
      "Epoch : 407 || Train Loss : 0.26646289229393005 || Val Loss : 10.566717147827148\n",
      "Epoch : 408 || Train Loss : 0.2419768124818802 || Val Loss : 10.437524795532227\n",
      "Epoch : 409 || Train Loss : 0.21025405824184418 || Val Loss : 10.276662826538086\n",
      "Epoch : 410 || Train Loss : 0.22056818008422852 || Val Loss : 10.133419036865234\n",
      "Epoch : 411 || Train Loss : 0.2001657485961914 || Val Loss : 9.971569061279297\n",
      "Epoch : 412 || Train Loss : 0.1859569400548935 || Val Loss : 9.825871467590332\n",
      "Epoch : 413 || Train Loss : 0.17167668044567108 || Val Loss : 9.683439254760742\n",
      "Epoch : 414 || Train Loss : 0.18810021877288818 || Val Loss : 9.543439865112305\n",
      "Epoch : 415 || Train Loss : 0.15281011164188385 || Val Loss : 9.421062469482422\n",
      "Epoch : 416 || Train Loss : 0.15968862175941467 || Val Loss : 9.34040641784668\n",
      "Epoch : 417 || Train Loss : 0.19475813210010529 || Val Loss : 9.229059219360352\n",
      "Epoch : 418 || Train Loss : 0.16341134905815125 || Val Loss : 9.04766845703125\n",
      "Epoch : 419 || Train Loss : 0.14820614457130432 || Val Loss : 8.989060401916504\n",
      "Epoch : 420 || Train Loss : 0.16324865818023682 || Val Loss : 8.97383975982666\n",
      "Epoch : 421 || Train Loss : 0.16021494567394257 || Val Loss : 8.812228202819824\n",
      "Epoch : 422 || Train Loss : 0.1393604874610901 || Val Loss : 8.672335624694824\n",
      "Epoch : 423 || Train Loss : 0.1322939395904541 || Val Loss : 9.30384349822998\n",
      "Epoch : 424 || Train Loss : 0.31046998500823975 || Val Loss : 8.942666053771973\n",
      "Epoch : 425 || Train Loss : 0.15698204934597015 || Val Loss : 8.83716869354248\n",
      "Epoch : 426 || Train Loss : 0.13000790774822235 || Val Loss : 8.726759910583496\n",
      "Epoch : 427 || Train Loss : 0.14304250478744507 || Val Loss : 8.543481826782227\n",
      "Epoch : 428 || Train Loss : 0.11543246358633041 || Val Loss : 8.436738014221191\n",
      "Epoch : 429 || Train Loss : 0.1157415434718132 || Val Loss : 8.493247032165527\n",
      "Epoch : 430 || Train Loss : 0.1269567757844925 || Val Loss : 8.302545547485352\n",
      "Epoch : 431 || Train Loss : 0.11635222285985947 || Val Loss : 8.202302932739258\n",
      "Epoch : 432 || Train Loss : 0.09174259752035141 || Val Loss : 8.031756401062012\n",
      "Epoch : 433 || Train Loss : 0.10823507606983185 || Val Loss : 7.988757133483887\n",
      "Epoch : 434 || Train Loss : 0.08759238570928574 || Val Loss : 7.944665908813477\n",
      "Epoch : 435 || Train Loss : 0.09268204122781754 || Val Loss : 7.774159908294678\n",
      "Epoch : 436 || Train Loss : 0.09653580188751221 || Val Loss : 7.719577789306641\n",
      "Epoch : 437 || Train Loss : 0.10007841885089874 || Val Loss : 7.881129741668701\n",
      "Epoch : 438 || Train Loss : 0.09161576628684998 || Val Loss : 7.631959915161133\n",
      "Epoch : 439 || Train Loss : 0.0889907032251358 || Val Loss : 7.623011589050293\n",
      "Epoch : 440 || Train Loss : 0.07768232375383377 || Val Loss : 7.4830002784729\n",
      "Epoch : 441 || Train Loss : 0.1000031977891922 || Val Loss : 7.450127601623535\n",
      "Epoch : 442 || Train Loss : 0.07554169744253159 || Val Loss : 7.396255970001221\n",
      "Epoch : 443 || Train Loss : 0.08473267406225204 || Val Loss : 7.436683177947998\n",
      "Epoch : 444 || Train Loss : 0.08333226293325424 || Val Loss : 7.362800598144531\n",
      "Epoch : 445 || Train Loss : 0.07962221652269363 || Val Loss : 7.157022953033447\n",
      "Epoch : 446 || Train Loss : 0.07572227716445923 || Val Loss : 7.207574367523193\n",
      "Epoch : 447 || Train Loss : 0.06749358028173447 || Val Loss : 7.044955730438232\n",
      "Epoch : 448 || Train Loss : 0.08485480397939682 || Val Loss : 7.1247992515563965\n",
      "Epoch : 449 || Train Loss : 0.06449537724256516 || Val Loss : 7.006835460662842\n",
      "Epoch : 450 || Train Loss : 0.07465743273496628 || Val Loss : 6.9994025230407715\n",
      "Epoch : 451 || Train Loss : 0.06466863304376602 || Val Loss : 7.060670375823975\n",
      "Epoch : 452 || Train Loss : 0.10176217555999756 || Val Loss : 6.987802505493164\n",
      "Epoch : 453 || Train Loss : 0.06479974836111069 || Val Loss : 6.912412166595459\n",
      "Epoch : 454 || Train Loss : 0.06932637095451355 || Val Loss : 6.921698093414307\n",
      "Epoch : 455 || Train Loss : 0.07131592929363251 || Val Loss : 6.817260265350342\n",
      "Epoch : 456 || Train Loss : 0.057618677616119385 || Val Loss : 6.84201717376709\n",
      "Epoch : 457 || Train Loss : 0.06208080053329468 || Val Loss : 6.75926399230957\n",
      "Epoch : 458 || Train Loss : 0.05806008726358414 || Val Loss : 6.6599626541137695\n",
      "Epoch : 459 || Train Loss : 0.06300773471593857 || Val Loss : 6.77126932144165\n",
      "Epoch : 460 || Train Loss : 0.07465407252311707 || Val Loss : 6.68898344039917\n",
      "Epoch : 461 || Train Loss : 0.06242731958627701 || Val Loss : 6.647878646850586\n",
      "Epoch : 462 || Train Loss : 0.04290381819009781 || Val Loss : 6.6071953773498535\n",
      "Epoch : 463 || Train Loss : 0.052713792771101 || Val Loss : 6.523252964019775\n",
      "Epoch : 464 || Train Loss : 0.06255924701690674 || Val Loss : 6.571842670440674\n",
      "Epoch : 465 || Train Loss : 0.05342070385813713 || Val Loss : 6.489799976348877\n",
      "Epoch : 466 || Train Loss : 0.06496580690145493 || Val Loss : 6.509513854980469\n",
      "Epoch : 467 || Train Loss : 0.03928409144282341 || Val Loss : 6.452147483825684\n",
      "Epoch : 468 || Train Loss : 0.055501341819763184 || Val Loss : 6.572477340698242\n",
      "Epoch : 469 || Train Loss : 0.09116537123918533 || Val Loss : 6.513129711151123\n",
      "Epoch : 470 || Train Loss : 0.05611146613955498 || Val Loss : 6.403473377227783\n",
      "Epoch : 471 || Train Loss : 0.05089735612273216 || Val Loss : 6.385318279266357\n",
      "Epoch : 472 || Train Loss : 0.05101453885436058 || Val Loss : 6.276900768280029\n",
      "Epoch : 473 || Train Loss : 0.07236098498106003 || Val Loss : 6.475269317626953\n",
      "Epoch : 474 || Train Loss : 0.11854590475559235 || Val Loss : 6.445382118225098\n",
      "Epoch : 475 || Train Loss : 0.04227614030241966 || Val Loss : 6.390781879425049\n",
      "Epoch : 476 || Train Loss : 0.04317815229296684 || Val Loss : 6.320013046264648\n",
      "Epoch : 477 || Train Loss : 0.04673532769083977 || Val Loss : 6.302988529205322\n",
      "Epoch : 478 || Train Loss : 0.04304204881191254 || Val Loss : 6.207356929779053\n",
      "Epoch : 479 || Train Loss : 0.06056005880236626 || Val Loss : 6.269491672515869\n",
      "Epoch : 480 || Train Loss : 0.04836143180727959 || Val Loss : 6.182582378387451\n",
      "Epoch : 481 || Train Loss : 0.04873780161142349 || Val Loss : 6.2213358879089355\n",
      "Epoch : 482 || Train Loss : 0.0475524365901947 || Val Loss : 6.132894039154053\n",
      "Epoch : 483 || Train Loss : 0.04888240620493889 || Val Loss : 6.171681880950928\n",
      "Epoch : 484 || Train Loss : 0.0361907072365284 || Val Loss : 6.094303131103516\n",
      "Epoch : 485 || Train Loss : 0.051333941519260406 || Val Loss : 6.116706848144531\n",
      "Epoch : 486 || Train Loss : 0.04357212036848068 || Val Loss : 6.022093296051025\n",
      "Epoch : 487 || Train Loss : 0.05151791498064995 || Val Loss : 6.0720930099487305\n",
      "Epoch : 488 || Train Loss : 0.04957548528909683 || Val Loss : 5.985776424407959\n",
      "Epoch : 489 || Train Loss : 0.04487474635243416 || Val Loss : 6.006709575653076\n",
      "Epoch : 490 || Train Loss : 0.03540610894560814 || Val Loss : 5.938022136688232\n",
      "Epoch : 491 || Train Loss : 0.04667436704039574 || Val Loss : 5.9923200607299805\n",
      "Epoch : 492 || Train Loss : 0.051207005977630615 || Val Loss : 5.897100925445557\n",
      "Epoch : 493 || Train Loss : 0.04653279483318329 || Val Loss : 5.963345527648926\n",
      "Epoch : 494 || Train Loss : 0.04147184640169144 || Val Loss : 5.883848667144775\n",
      "Epoch : 495 || Train Loss : 0.04717236012220383 || Val Loss : 6.020783424377441\n",
      "Epoch : 496 || Train Loss : 0.0656658336520195 || Val Loss : 5.912416458129883\n",
      "Epoch : 497 || Train Loss : 0.03170524165034294 || Val Loss : 5.899865627288818\n",
      "Epoch : 498 || Train Loss : 0.029464250430464745 || Val Loss : 5.873825550079346\n",
      "Epoch : 499 || Train Loss : 0.031220007687807083 || Val Loss : 5.835171699523926\n",
      "Epoch : 500 || Train Loss : 0.030474403873085976 || Val Loss : 5.793259620666504\n",
      "Epoch : 501 || Train Loss : 0.028763914480805397 || Val Loss : 5.8373212814331055\n",
      "Epoch : 502 || Train Loss : 0.05658204108476639 || Val Loss : 5.755941390991211\n",
      "Epoch : 503 || Train Loss : 0.03627368062734604 || Val Loss : 5.784239292144775\n",
      "Epoch : 504 || Train Loss : 0.040473636239767075 || Val Loss : 5.697714328765869\n",
      "Epoch : 505 || Train Loss : 0.03963567689061165 || Val Loss : 5.751892566680908\n",
      "Epoch : 506 || Train Loss : 0.03435619920492172 || Val Loss : 5.690232753753662\n",
      "Epoch : 507 || Train Loss : 0.03529592230916023 || Val Loss : 5.757088661193848\n",
      "Epoch : 508 || Train Loss : 0.04877174645662308 || Val Loss : 5.690565586090088\n",
      "Epoch : 509 || Train Loss : 0.03177514299750328 || Val Loss : 5.63422155380249\n",
      "Epoch : 510 || Train Loss : 0.03872017562389374 || Val Loss : 5.6550140380859375\n",
      "Epoch : 511 || Train Loss : 0.030631128698587418 || Val Loss : 5.706295490264893\n",
      "Epoch : 512 || Train Loss : 0.04997407644987106 || Val Loss : 5.625185489654541\n",
      "Epoch : 513 || Train Loss : 0.029385721310973167 || Val Loss : 5.646160125732422\n",
      "Epoch : 514 || Train Loss : 0.04161268472671509 || Val Loss : 5.5969953536987305\n",
      "Epoch : 515 || Train Loss : 0.0325603187084198 || Val Loss : 5.6446990966796875\n",
      "Epoch : 516 || Train Loss : 0.04127050191164017 || Val Loss : 5.562707424163818\n",
      "Epoch : 517 || Train Loss : 0.04186324402689934 || Val Loss : 5.613625526428223\n",
      "Epoch : 518 || Train Loss : 0.03955680876970291 || Val Loss : 5.519133567810059\n",
      "Epoch : 519 || Train Loss : 0.037926312536001205 || Val Loss : 5.580317974090576\n",
      "Epoch : 520 || Train Loss : 0.03968347609043121 || Val Loss : 5.476375102996826\n",
      "Epoch : 521 || Train Loss : 0.0484606996178627 || Val Loss : 5.552524566650391\n",
      "Epoch : 522 || Train Loss : 0.035457562655210495 || Val Loss : 5.456840515136719\n",
      "Epoch : 523 || Train Loss : 0.041735853999853134 || Val Loss : 5.512972831726074\n",
      "Epoch : 524 || Train Loss : 0.02472306229174137 || Val Loss : 5.475300312042236\n",
      "Epoch : 525 || Train Loss : 0.027804750949144363 || Val Loss : 5.464261054992676\n",
      "Epoch : 526 || Train Loss : 0.04313225299119949 || Val Loss : 5.369494438171387\n",
      "Epoch : 527 || Train Loss : 0.052416663616895676 || Val Loss : 5.421262264251709\n",
      "Epoch : 528 || Train Loss : 0.028613222762942314 || Val Loss : 5.432187080383301\n",
      "Epoch : 529 || Train Loss : 0.029602820053696632 || Val Loss : 5.456092357635498\n",
      "Epoch : 530 || Train Loss : 0.043651681393384933 || Val Loss : 5.37258243560791\n",
      "Epoch : 531 || Train Loss : 0.03335728868842125 || Val Loss : 5.455328464508057\n",
      "Epoch : 532 || Train Loss : 0.03582293540239334 || Val Loss : 5.4001898765563965\n",
      "Epoch : 533 || Train Loss : 0.02344786375761032 || Val Loss : 5.423532009124756\n",
      "Epoch : 534 || Train Loss : 0.04353458806872368 || Val Loss : 5.335606575012207\n",
      "Epoch : 535 || Train Loss : 0.03507184609770775 || Val Loss : 5.408168315887451\n",
      "Epoch : 536 || Train Loss : 0.03569333627820015 || Val Loss : 5.372720718383789\n",
      "Epoch : 537 || Train Loss : 0.022928450256586075 || Val Loss : 5.347135543823242\n",
      "Epoch : 538 || Train Loss : 0.023876717314124107 || Val Loss : 5.323000431060791\n",
      "Epoch : 539 || Train Loss : 0.025601644068956375 || Val Loss : 5.326650619506836\n",
      "Epoch : 540 || Train Loss : 0.0349535308778286 || Val Loss : 5.269966125488281\n",
      "Epoch : 541 || Train Loss : 0.03326069191098213 || Val Loss : 5.311065673828125\n",
      "Epoch : 542 || Train Loss : 0.02361723594367504 || Val Loss : 5.270715713500977\n",
      "Epoch : 543 || Train Loss : 0.02542067877948284 || Val Loss : 5.271566867828369\n",
      "Epoch : 544 || Train Loss : 0.024103302508592606 || Val Loss : 5.226339340209961\n",
      "Epoch : 545 || Train Loss : 0.037037935107946396 || Val Loss : 5.309619426727295\n",
      "Epoch : 546 || Train Loss : 0.049594175070524216 || Val Loss : 5.234740734100342\n",
      "Epoch : 547 || Train Loss : 0.023104926571249962 || Val Loss : 5.246465682983398\n",
      "Epoch : 548 || Train Loss : 0.02911447361111641 || Val Loss : 5.180670738220215\n",
      "Epoch : 549 || Train Loss : 0.0422772616147995 || Val Loss : 5.269009113311768\n",
      "Epoch : 550 || Train Loss : 0.025742927566170692 || Val Loss : 5.221017360687256\n",
      "Epoch : 551 || Train Loss : 0.022086691111326218 || Val Loss : 5.191335201263428\n",
      "Epoch : 552 || Train Loss : 0.023602349683642387 || Val Loss : 5.217917442321777\n",
      "Epoch : 553 || Train Loss : 0.03648742288351059 || Val Loss : 5.133886814117432\n",
      "Epoch : 554 || Train Loss : 0.02990955486893654 || Val Loss : 5.223647117614746\n",
      "Epoch : 555 || Train Loss : 0.035542890429496765 || Val Loss : 5.11592960357666\n",
      "Epoch : 556 || Train Loss : 0.04075687751173973 || Val Loss : 5.245272636413574\n",
      "Epoch : 557 || Train Loss : 0.029025612398982048 || Val Loss : 5.175785064697266\n",
      "Epoch : 558 || Train Loss : 0.024095341563224792 || Val Loss : 5.152271270751953\n",
      "Epoch : 559 || Train Loss : 0.023106344044208527 || Val Loss : 5.125033378601074\n",
      "Epoch : 560 || Train Loss : 0.02520672418177128 || Val Loss : 5.1914825439453125\n",
      "Epoch : 561 || Train Loss : 0.03394410014152527 || Val Loss : 5.111321926116943\n",
      "Epoch : 562 || Train Loss : 0.029333103448152542 || Val Loss : 5.122877597808838\n",
      "Epoch : 563 || Train Loss : 0.022692888975143433 || Val Loss : 5.057848930358887\n",
      "Epoch : 564 || Train Loss : 0.033852096647024155 || Val Loss : 5.112370014190674\n",
      "Epoch : 565 || Train Loss : 0.020390544086694717 || Val Loss : 5.09437894821167\n",
      "Epoch : 566 || Train Loss : 0.020907552912831306 || Val Loss : 5.065990447998047\n",
      "Epoch : 567 || Train Loss : 0.02474176324903965 || Val Loss : 5.089221000671387\n",
      "Epoch : 568 || Train Loss : 0.02780078910291195 || Val Loss : 5.023565769195557\n",
      "Epoch : 569 || Train Loss : 0.030023306608200073 || Val Loss : 5.07583475112915\n",
      "Epoch : 570 || Train Loss : 0.026956865563988686 || Val Loss : 5.000235080718994\n",
      "Epoch : 571 || Train Loss : 0.029522448778152466 || Val Loss : 5.036631107330322\n",
      "Epoch : 572 || Train Loss : 0.02338426373898983 || Val Loss : 5.063502788543701\n",
      "Epoch : 573 || Train Loss : 0.03566844388842583 || Val Loss : 5.000324726104736\n",
      "Epoch : 574 || Train Loss : 0.025007102638483047 || Val Loss : 5.03745174407959\n",
      "Epoch : 575 || Train Loss : 0.02345426380634308 || Val Loss : 4.984741687774658\n",
      "Epoch : 576 || Train Loss : 0.024748366326093674 || Val Loss : 5.018787860870361\n",
      "Epoch : 577 || Train Loss : 0.02148856222629547 || Val Loss : 4.95095157623291\n",
      "Epoch : 578 || Train Loss : 0.03789280727505684 || Val Loss : 5.031838417053223\n",
      "Epoch : 579 || Train Loss : 0.02457459084689617 || Val Loss : 4.971277236938477\n",
      "Epoch : 580 || Train Loss : 0.01994297280907631 || Val Loss : 4.968517780303955\n",
      "Epoch : 581 || Train Loss : 0.020468996837735176 || Val Loss : 4.940014839172363\n",
      "Epoch : 582 || Train Loss : 0.024170901626348495 || Val Loss : 5.031449317932129\n",
      "Epoch : 583 || Train Loss : 0.035967715084552765 || Val Loss : 4.954313278198242\n",
      "Epoch : 584 || Train Loss : 0.019487682729959488 || Val Loss : 4.974091053009033\n",
      "Epoch : 585 || Train Loss : 0.022872325032949448 || Val Loss : 4.915504455566406\n",
      "Epoch : 586 || Train Loss : 0.023665068671107292 || Val Loss : 4.959341526031494\n",
      "Epoch : 587 || Train Loss : 0.020586412400007248 || Val Loss : 4.939663887023926\n",
      "Epoch : 588 || Train Loss : 0.01829688809812069 || Val Loss : 4.938015937805176\n",
      "Epoch : 589 || Train Loss : 0.023450838401913643 || Val Loss : 4.90497350692749\n",
      "Epoch : 590 || Train Loss : 0.018941842019557953 || Val Loss : 4.917825222015381\n",
      "Epoch : 591 || Train Loss : 0.023271001875400543 || Val Loss : 4.879745006561279\n",
      "Epoch : 592 || Train Loss : 0.02412641979753971 || Val Loss : 4.912384510040283\n",
      "Epoch : 593 || Train Loss : 0.03038960136473179 || Val Loss : 4.855642795562744\n",
      "Epoch : 594 || Train Loss : 0.022224536165595055 || Val Loss : 4.881495475769043\n",
      "Epoch : 595 || Train Loss : 0.017631107941269875 || Val Loss : 4.8690266609191895\n",
      "Epoch : 596 || Train Loss : 0.0187834482640028 || Val Loss : 4.831001281738281\n",
      "Epoch : 597 || Train Loss : 0.030644524842500687 || Val Loss : 4.893304824829102\n",
      "Epoch : 598 || Train Loss : 0.02730461396276951 || Val Loss : 4.850297451019287\n",
      "Epoch : 599 || Train Loss : 0.01893783174455166 || Val Loss : 4.84567403793335\n",
      "Epoch : 600 || Train Loss : 0.01849045790731907 || Val Loss : 4.838778495788574\n",
      "Epoch : 601 || Train Loss : 0.0178806371986866 || Val Loss : 4.812592506408691\n",
      "Epoch : 602 || Train Loss : 0.018571583554148674 || Val Loss : 4.854852199554443\n",
      "Epoch : 603 || Train Loss : 0.029205957427620888 || Val Loss : 4.796309471130371\n",
      "Epoch : 604 || Train Loss : 0.02272835001349449 || Val Loss : 4.835963726043701\n",
      "Epoch : 605 || Train Loss : 0.0245159063488245 || Val Loss : 4.777088642120361\n",
      "Epoch : 606 || Train Loss : 0.025601018220186234 || Val Loss : 4.854366302490234\n",
      "Epoch : 607 || Train Loss : 0.028033187612891197 || Val Loss : 4.79249906539917\n",
      "Epoch : 608 || Train Loss : 0.018223116174340248 || Val Loss : 4.8071136474609375\n",
      "Epoch : 609 || Train Loss : 0.018442340195178986 || Val Loss : 4.772510051727295\n",
      "Epoch : 610 || Train Loss : 0.02289336360991001 || Val Loss : 4.836260795593262\n",
      "Epoch : 611 || Train Loss : 0.023749342188239098 || Val Loss : 4.798847675323486\n",
      "Epoch : 612 || Train Loss : 0.0205087848007679 || Val Loss : 4.751096248626709\n",
      "Epoch : 613 || Train Loss : 0.024133015424013138 || Val Loss : 4.806385517120361\n",
      "Epoch : 614 || Train Loss : 0.02244764007627964 || Val Loss : 4.763844013214111\n",
      "Epoch : 615 || Train Loss : 0.020254218950867653 || Val Loss : 4.740866184234619\n",
      "Epoch : 616 || Train Loss : 0.019691554829478264 || Val Loss : 4.753618240356445\n",
      "Epoch : 617 || Train Loss : 0.01934260129928589 || Val Loss : 4.7172698974609375\n",
      "Epoch : 618 || Train Loss : 0.022073036059737206 || Val Loss : 4.798878192901611\n",
      "Epoch : 619 || Train Loss : 0.0346728079020977 || Val Loss : 4.739226341247559\n",
      "Epoch : 620 || Train Loss : 0.017012974247336388 || Val Loss : 4.722293853759766\n",
      "Epoch : 621 || Train Loss : 0.01725887693464756 || Val Loss : 4.723416805267334\n",
      "Epoch : 622 || Train Loss : 0.01648196391761303 || Val Loss : 4.7046613693237305\n",
      "Epoch : 623 || Train Loss : 0.020211435854434967 || Val Loss : 4.75042200088501\n",
      "Epoch : 624 || Train Loss : 0.03549087047576904 || Val Loss : 4.711148262023926\n",
      "Epoch : 625 || Train Loss : 0.019475627690553665 || Val Loss : 4.723170757293701\n",
      "Epoch : 626 || Train Loss : 0.02339230291545391 || Val Loss : 4.6631622314453125\n",
      "Epoch : 627 || Train Loss : 0.027862805873155594 || Val Loss : 4.7089033126831055\n",
      "Epoch : 628 || Train Loss : 0.01991589367389679 || Val Loss : 4.668214321136475\n",
      "Epoch : 629 || Train Loss : 0.02268938720226288 || Val Loss : 4.715844631195068\n",
      "Epoch : 630 || Train Loss : 0.0269386675208807 || Val Loss : 4.655810832977295\n",
      "Epoch : 631 || Train Loss : 0.019483504816889763 || Val Loss : 4.682218074798584\n",
      "Epoch : 632 || Train Loss : 0.021749356761574745 || Val Loss : 4.659083366394043\n",
      "Epoch : 633 || Train Loss : 0.016041487455368042 || Val Loss : 4.643054008483887\n",
      "Epoch : 634 || Train Loss : 0.01716567948460579 || Val Loss : 4.637551307678223\n",
      "Epoch : 635 || Train Loss : 0.019459597766399384 || Val Loss : 4.629950046539307\n",
      "Epoch : 636 || Train Loss : 0.016631504520773888 || Val Loss : 4.644763946533203\n",
      "Epoch : 637 || Train Loss : 0.017385749146342278 || Val Loss : 4.61554479598999\n",
      "Epoch : 638 || Train Loss : 0.020244428887963295 || Val Loss : 4.649232387542725\n",
      "Epoch : 639 || Train Loss : 0.02653164602816105 || Val Loss : 4.592241287231445\n",
      "Epoch : 640 || Train Loss : 0.02640370838344097 || Val Loss : 4.618332386016846\n",
      "Epoch : 641 || Train Loss : 0.015767201781272888 || Val Loss : 4.605660915374756\n",
      "Epoch : 642 || Train Loss : 0.01778780110180378 || Val Loss : 4.6111860275268555\n",
      "Epoch : 643 || Train Loss : 0.01857065036892891 || Val Loss : 4.575030326843262\n",
      "Epoch : 644 || Train Loss : 0.020402217283844948 || Val Loss : 4.619430065155029\n",
      "Epoch : 645 || Train Loss : 0.022112933918833733 || Val Loss : 4.6121439933776855\n",
      "Epoch : 646 || Train Loss : 0.017937149852514267 || Val Loss : 4.567431926727295\n",
      "Epoch : 647 || Train Loss : 0.021350925788283348 || Val Loss : 4.64271354675293\n",
      "Epoch : 648 || Train Loss : 0.029265863820910454 || Val Loss : 4.559291362762451\n",
      "Epoch : 649 || Train Loss : 0.02437048964202404 || Val Loss : 4.590381145477295\n",
      "Epoch : 650 || Train Loss : 0.015621277503669262 || Val Loss : 4.583807468414307\n",
      "Epoch : 651 || Train Loss : 0.018285522237420082 || Val Loss : 4.540517807006836\n",
      "Epoch : 652 || Train Loss : 0.022860322147607803 || Val Loss : 4.555384159088135\n",
      "Epoch : 653 || Train Loss : 0.0183150265365839 || Val Loss : 4.596722602844238\n",
      "Epoch : 654 || Train Loss : 0.02037390135228634 || Val Loss : 4.550518035888672\n",
      "Epoch : 655 || Train Loss : 0.018544932827353477 || Val Loss : 4.547511100769043\n",
      "Epoch : 656 || Train Loss : 0.01501474715769291 || Val Loss : 4.532581329345703\n",
      "Epoch : 657 || Train Loss : 0.01608504168689251 || Val Loss : 4.5455169677734375\n",
      "Epoch : 658 || Train Loss : 0.02138020470738411 || Val Loss : 4.510186672210693\n",
      "Epoch : 659 || Train Loss : 0.019635677337646484 || Val Loss : 4.515989303588867\n",
      "Epoch : 660 || Train Loss : 0.016487881541252136 || Val Loss : 4.523097991943359\n",
      "Epoch : 661 || Train Loss : 0.021096140146255493 || Val Loss : 4.474957466125488\n",
      "Epoch : 662 || Train Loss : 0.02459932677447796 || Val Loss : 4.528039932250977\n",
      "Epoch : 663 || Train Loss : 0.0191466324031353 || Val Loss : 4.484148025512695\n",
      "Epoch : 664 || Train Loss : 0.021637195721268654 || Val Loss : 4.509594440460205\n",
      "Epoch : 665 || Train Loss : 0.01850443333387375 || Val Loss : 4.5075554847717285\n",
      "Epoch : 666 || Train Loss : 0.01602669060230255 || Val Loss : 4.467803955078125\n",
      "Epoch : 667 || Train Loss : 0.02738829329609871 || Val Loss : 4.564341068267822\n",
      "Epoch : 668 || Train Loss : 0.021564794704318047 || Val Loss : 4.478822231292725\n",
      "Epoch : 669 || Train Loss : 0.016194913536310196 || Val Loss : 4.508362293243408\n",
      "Epoch : 670 || Train Loss : 0.014672623947262764 || Val Loss : 4.495968341827393\n",
      "Epoch : 671 || Train Loss : 0.016128402203321457 || Val Loss : 4.480684757232666\n",
      "Epoch : 672 || Train Loss : 0.01849738135933876 || Val Loss : 4.547269344329834\n",
      "Epoch : 673 || Train Loss : 0.03383226320147514 || Val Loss : 4.4743852615356445\n",
      "Epoch : 674 || Train Loss : 0.018697544932365417 || Val Loss : 4.483962059020996\n",
      "Epoch : 675 || Train Loss : 0.01879996433854103 || Val Loss : 4.46854305267334\n",
      "Epoch : 676 || Train Loss : 0.01829894259572029 || Val Loss : 4.446872234344482\n",
      "Epoch : 677 || Train Loss : 0.015624068677425385 || Val Loss : 4.4546427726745605\n",
      "Epoch : 678 || Train Loss : 0.01532509084790945 || Val Loss : 4.4366068840026855\n",
      "Epoch : 679 || Train Loss : 0.014875759370625019 || Val Loss : 4.471353054046631\n",
      "Epoch : 680 || Train Loss : 0.031700026243925095 || Val Loss : 4.401564121246338\n",
      "Epoch : 681 || Train Loss : 0.0235972311347723 || Val Loss : 4.464661121368408\n",
      "Epoch : 682 || Train Loss : 0.0179882999509573 || Val Loss : 4.411626815795898\n",
      "Epoch : 683 || Train Loss : 0.02343224361538887 || Val Loss : 4.451980113983154\n",
      "Epoch : 684 || Train Loss : 0.020235372707247734 || Val Loss : 4.4266462326049805\n",
      "Epoch : 685 || Train Loss : 0.017340539023280144 || Val Loss : 4.449533939361572\n",
      "Epoch : 686 || Train Loss : 0.022542187944054604 || Val Loss : 4.377904891967773\n",
      "Epoch : 687 || Train Loss : 0.030203981325030327 || Val Loss : 4.406400203704834\n",
      "Epoch : 688 || Train Loss : 0.01802806369960308 || Val Loss : 4.4357380867004395\n",
      "Epoch : 689 || Train Loss : 0.01916658878326416 || Val Loss : 4.3924880027771\n",
      "Epoch : 690 || Train Loss : 0.02761450782418251 || Val Loss : 4.432076454162598\n",
      "Epoch : 691 || Train Loss : 0.01830831728875637 || Val Loss : 4.4114203453063965\n",
      "Epoch : 692 || Train Loss : 0.01730925217270851 || Val Loss : 4.4054484367370605\n",
      "Epoch : 693 || Train Loss : 0.015470810234546661 || Val Loss : 4.406303882598877\n",
      "Epoch : 694 || Train Loss : 0.016732780262827873 || Val Loss : 4.395212650299072\n",
      "Epoch : 695 || Train Loss : 0.019784964621067047 || Val Loss : 4.363794803619385\n",
      "Epoch : 696 || Train Loss : 0.01878996193408966 || Val Loss : 4.41178560256958\n",
      "Epoch : 697 || Train Loss : 0.023174893110990524 || Val Loss : 4.3658447265625\n",
      "Epoch : 698 || Train Loss : 0.017174599692225456 || Val Loss : 4.377331256866455\n",
      "Epoch : 699 || Train Loss : 0.015156564302742481 || Val Loss : 4.368471622467041\n",
      "Epoch : 700 || Train Loss : 0.015195332467556 || Val Loss : 4.376961708068848\n",
      "Epoch : 701 || Train Loss : 0.016806533560156822 || Val Loss : 4.395019054412842\n",
      "Epoch : 702 || Train Loss : 0.016662782058119774 || Val Loss : 4.330680847167969\n",
      "Epoch : 703 || Train Loss : 0.02314387634396553 || Val Loss : 4.367773056030273\n",
      "Epoch : 704 || Train Loss : 0.014984706416726112 || Val Loss : 4.33969259262085\n",
      "Epoch : 705 || Train Loss : 0.015163657255470753 || Val Loss : 4.373140811920166\n",
      "Epoch : 706 || Train Loss : 0.01607070118188858 || Val Loss : 4.3477983474731445\n",
      "Epoch : 707 || Train Loss : 0.016844801604747772 || Val Loss : 4.3334126472473145\n",
      "Epoch : 708 || Train Loss : 0.019881710410118103 || Val Loss : 4.368934154510498\n",
      "Epoch : 709 || Train Loss : 0.020088601857423782 || Val Loss : 4.309854984283447\n",
      "Epoch : 710 || Train Loss : 0.02126721665263176 || Val Loss : 4.349123001098633\n",
      "Epoch : 711 || Train Loss : 0.016672609373927116 || Val Loss : 4.349298000335693\n",
      "Epoch : 712 || Train Loss : 0.018377311527729034 || Val Loss : 4.293905735015869\n",
      "Epoch : 713 || Train Loss : 0.025814270600676537 || Val Loss : 4.34157657623291\n",
      "Epoch : 714 || Train Loss : 0.01687462069094181 || Val Loss : 4.32734489440918\n",
      "Epoch : 715 || Train Loss : 0.0138836819678545 || Val Loss : 4.3305768966674805\n",
      "Epoch : 716 || Train Loss : 0.01692226529121399 || Val Loss : 4.304925441741943\n",
      "Epoch : 717 || Train Loss : 0.019153816625475883 || Val Loss : 4.359363079071045\n",
      "Epoch : 718 || Train Loss : 0.0230388380587101 || Val Loss : 4.281364917755127\n",
      "Epoch : 719 || Train Loss : 0.030100947245955467 || Val Loss : 4.327385425567627\n",
      "Epoch : 720 || Train Loss : 0.016747361049056053 || Val Loss : 4.296920299530029\n",
      "Epoch : 721 || Train Loss : 0.01780070550739765 || Val Loss : 4.310436725616455\n",
      "Epoch : 722 || Train Loss : 0.018003324046730995 || Val Loss : 4.32006311416626\n",
      "Epoch : 723 || Train Loss : 0.019460348412394524 || Val Loss : 4.268669128417969\n",
      "Epoch : 724 || Train Loss : 0.02754666842520237 || Val Loss : 4.361955165863037\n",
      "Epoch : 725 || Train Loss : 0.01865699701011181 || Val Loss : 4.305455684661865\n",
      "Epoch : 726 || Train Loss : 0.015014804899692535 || Val Loss : 4.338902473449707\n",
      "Epoch : 727 || Train Loss : 0.020614376291632652 || Val Loss : 4.265048503875732\n",
      "Epoch : 728 || Train Loss : 0.019085250794887543 || Val Loss : 4.322793483734131\n",
      "Epoch : 729 || Train Loss : 0.017830103635787964 || Val Loss : 4.272791862487793\n",
      "Epoch : 730 || Train Loss : 0.020656917244195938 || Val Loss : 4.335750579833984\n",
      "Epoch : 731 || Train Loss : 0.022603638470172882 || Val Loss : 4.290748119354248\n",
      "Epoch : 732 || Train Loss : 0.014106451533734798 || Val Loss : 4.311000347137451\n",
      "Epoch : 733 || Train Loss : 0.0194784477353096 || Val Loss : 4.278171539306641\n",
      "Epoch : 734 || Train Loss : 0.01827145926654339 || Val Loss : 4.298397541046143\n",
      "Epoch : 735 || Train Loss : 0.01589440181851387 || Val Loss : 4.319578170776367\n",
      "Epoch : 736 || Train Loss : 0.021722210571169853 || Val Loss : 4.25284481048584\n",
      "Epoch : 737 || Train Loss : 0.02063875086605549 || Val Loss : 4.288491725921631\n",
      "Epoch : 738 || Train Loss : 0.015064558945596218 || Val Loss : 4.286159992218018\n",
      "Epoch : 739 || Train Loss : 0.016156921163201332 || Val Loss : 4.281735897064209\n",
      "Epoch : 740 || Train Loss : 0.017425624653697014 || Val Loss : 4.270966053009033\n",
      "Epoch : 741 || Train Loss : 0.01720564253628254 || Val Loss : 4.278751850128174\n",
      "Epoch : 742 || Train Loss : 0.015134778805077076 || Val Loss : 4.250344753265381\n",
      "Epoch : 743 || Train Loss : 0.015580828301608562 || Val Loss : 4.263506889343262\n",
      "Epoch : 744 || Train Loss : 0.014669972471892834 || Val Loss : 4.261927604675293\n",
      "Epoch : 745 || Train Loss : 0.018027890473604202 || Val Loss : 4.280815124511719\n",
      "Epoch : 746 || Train Loss : 0.018896352499723434 || Val Loss : 4.224074363708496\n",
      "Epoch : 747 || Train Loss : 0.018007272854447365 || Val Loss : 4.26102352142334\n",
      "Epoch : 748 || Train Loss : 0.01578160747885704 || Val Loss : 4.241717338562012\n",
      "Epoch : 749 || Train Loss : 0.016722602769732475 || Val Loss : 4.196683883666992\n",
      "Epoch : 750 || Train Loss : 0.0266158115118742 || Val Loss : 4.254390239715576\n",
      "Epoch : 751 || Train Loss : 0.014558635652065277 || Val Loss : 4.242798805236816\n",
      "Epoch : 752 || Train Loss : 0.014396253041923046 || Val Loss : 4.209433555603027\n",
      "Epoch : 753 || Train Loss : 0.019321976229548454 || Val Loss : 4.24710750579834\n",
      "Epoch : 754 || Train Loss : 0.019078852608799934 || Val Loss : 4.225738048553467\n",
      "Epoch : 755 || Train Loss : 0.01490727998316288 || Val Loss : 4.209610462188721\n",
      "Epoch : 756 || Train Loss : 0.017898190766572952 || Val Loss : 4.262941360473633\n",
      "Epoch : 757 || Train Loss : 0.02113068476319313 || Val Loss : 4.1774468421936035\n",
      "Epoch : 758 || Train Loss : 0.023155758157372475 || Val Loss : 4.2005815505981445\n",
      "Epoch : 759 || Train Loss : 0.01567510887980461 || Val Loss : 4.202459812164307\n",
      "Epoch : 760 || Train Loss : 0.01752779260277748 || Val Loss : 4.292080402374268\n",
      "Epoch : 761 || Train Loss : 0.021789973601698875 || Val Loss : 4.214744567871094\n",
      "Epoch : 762 || Train Loss : 0.016894249245524406 || Val Loss : 4.245774745941162\n",
      "Epoch : 763 || Train Loss : 0.020430952310562134 || Val Loss : 4.202671527862549\n",
      "Epoch : 764 || Train Loss : 0.015569663606584072 || Val Loss : 4.191912651062012\n",
      "Epoch : 765 || Train Loss : 0.01402255892753601 || Val Loss : 4.198317527770996\n",
      "Epoch : 766 || Train Loss : 0.016033602878451347 || Val Loss : 4.171628475189209\n",
      "Epoch : 767 || Train Loss : 0.019684134051203728 || Val Loss : 4.182844638824463\n",
      "Epoch : 768 || Train Loss : 0.014085900969803333 || Val Loss : 4.1866021156311035\n",
      "Epoch : 769 || Train Loss : 0.01492127776145935 || Val Loss : 4.15905237197876\n",
      "Epoch : 770 || Train Loss : 0.023542562499642372 || Val Loss : 4.26947021484375\n",
      "Epoch : 771 || Train Loss : 0.024008382111787796 || Val Loss : 4.167742729187012\n",
      "Epoch : 772 || Train Loss : 0.019338907673954964 || Val Loss : 4.216250419616699\n",
      "Epoch : 773 || Train Loss : 0.017947709187865257 || Val Loss : 4.181728839874268\n",
      "Epoch : 774 || Train Loss : 0.014598391950130463 || Val Loss : 4.204047203063965\n",
      "Epoch : 775 || Train Loss : 0.01638762094080448 || Val Loss : 4.163168430328369\n",
      "Epoch : 776 || Train Loss : 0.01626109518110752 || Val Loss : 4.17210578918457\n",
      "Epoch : 777 || Train Loss : 0.01404684316366911 || Val Loss : 4.171139240264893\n",
      "Epoch : 778 || Train Loss : 0.014216450043022633 || Val Loss : 4.142899036407471\n",
      "Epoch : 779 || Train Loss : 0.01637955568730831 || Val Loss : 4.189950942993164\n",
      "Epoch : 780 || Train Loss : 0.02072514407336712 || Val Loss : 4.161087512969971\n",
      "Epoch : 781 || Train Loss : 0.014613660983741283 || Val Loss : 4.167181015014648\n",
      "Epoch : 782 || Train Loss : 0.01624896191060543 || Val Loss : 4.1517462730407715\n",
      "Epoch : 783 || Train Loss : 0.013564372435212135 || Val Loss : 4.169659614562988\n",
      "Epoch : 784 || Train Loss : 0.018636513501405716 || Val Loss : 4.1434125900268555\n",
      "Epoch : 785 || Train Loss : 0.016306690871715546 || Val Loss : 4.147207736968994\n",
      "Epoch : 786 || Train Loss : 0.014631086960434914 || Val Loss : 4.1594109535217285\n",
      "Epoch : 787 || Train Loss : 0.01621418446302414 || Val Loss : 4.135763645172119\n",
      "Epoch : 788 || Train Loss : 0.018017545342445374 || Val Loss : 4.200658798217773\n",
      "Epoch : 789 || Train Loss : 0.027985556051135063 || Val Loss : 4.114586353302002\n",
      "Epoch : 790 || Train Loss : 0.015855608507990837 || Val Loss : 4.168757438659668\n",
      "Epoch : 791 || Train Loss : 0.022244751453399658 || Val Loss : 4.125836372375488\n",
      "Epoch : 792 || Train Loss : 0.01621917262673378 || Val Loss : 4.1394500732421875\n",
      "Epoch : 793 || Train Loss : 0.01493049319833517 || Val Loss : 4.156874656677246\n",
      "Epoch : 794 || Train Loss : 0.015532410703599453 || Val Loss : 4.131749629974365\n",
      "Epoch : 795 || Train Loss : 0.014106030575931072 || Val Loss : 4.113770484924316\n",
      "Epoch : 796 || Train Loss : 0.01583278737962246 || Val Loss : 4.11562442779541\n",
      "Epoch : 797 || Train Loss : 0.016566965728998184 || Val Loss : 4.101769924163818\n",
      "Epoch : 798 || Train Loss : 0.016429385170340538 || Val Loss : 4.09164571762085\n",
      "Epoch : 799 || Train Loss : 0.016923407092690468 || Val Loss : 4.148085117340088\n",
      "Epoch : 800 || Train Loss : 0.025087187066674232 || Val Loss : 4.057770729064941\n",
      "Epoch : 801 || Train Loss : 0.029810745269060135 || Val Loss : 4.1552910804748535\n",
      "Epoch : 802 || Train Loss : 0.01779436506330967 || Val Loss : 4.100126266479492\n",
      "Epoch : 803 || Train Loss : 0.015526944771409035 || Val Loss : 4.099874496459961\n",
      "Epoch : 804 || Train Loss : 0.014473444782197475 || Val Loss : 4.093903064727783\n",
      "Epoch : 805 || Train Loss : 0.013810194097459316 || Val Loss : 4.089700222015381\n",
      "Epoch : 806 || Train Loss : 0.013630923815071583 || Val Loss : 4.093201160430908\n",
      "Epoch : 807 || Train Loss : 0.013298076577484608 || Val Loss : 4.101165294647217\n",
      "Epoch : 808 || Train Loss : 0.015317666344344616 || Val Loss : 4.0641770362854\n",
      "Epoch : 809 || Train Loss : 0.021061090752482414 || Val Loss : 4.123616695404053\n",
      "Epoch : 810 || Train Loss : 0.02030188776552677 || Val Loss : 4.0619797706604\n",
      "Epoch : 811 || Train Loss : 0.01750301383435726 || Val Loss : 4.128963947296143\n",
      "Epoch : 812 || Train Loss : 0.018915480002760887 || Val Loss : 4.061967849731445\n",
      "Epoch : 813 || Train Loss : 0.018773812800645828 || Val Loss : 4.100070953369141\n",
      "Epoch : 814 || Train Loss : 0.0161301176995039 || Val Loss : 4.074158668518066\n",
      "Epoch : 815 || Train Loss : 0.017177414149045944 || Val Loss : 4.09885311126709\n",
      "Epoch : 816 || Train Loss : 0.014033577404916286 || Val Loss : 4.088969707489014\n",
      "Epoch : 817 || Train Loss : 0.014977877028286457 || Val Loss : 4.0788679122924805\n",
      "Epoch : 818 || Train Loss : 0.014049566350877285 || Val Loss : 4.071965217590332\n",
      "Epoch : 819 || Train Loss : 0.014735214412212372 || Val Loss : 4.063408851623535\n",
      "Epoch : 820 || Train Loss : 0.013975284993648529 || Val Loss : 4.108265399932861\n",
      "Epoch : 821 || Train Loss : 0.020414387807250023 || Val Loss : 4.066290855407715\n",
      "Epoch : 822 || Train Loss : 0.014611909165978432 || Val Loss : 4.067071914672852\n",
      "Epoch : 823 || Train Loss : 0.013645810075104237 || Val Loss : 4.049633979797363\n",
      "Epoch : 824 || Train Loss : 0.014822720550000668 || Val Loss : 4.053581714630127\n",
      "Epoch : 825 || Train Loss : 0.016033342108130455 || Val Loss : 4.106980323791504\n",
      "Epoch : 826 || Train Loss : 0.01815200038254261 || Val Loss : 4.072908401489258\n",
      "Epoch : 827 || Train Loss : 0.01492893137037754 || Val Loss : 4.072141647338867\n",
      "Epoch : 828 || Train Loss : 0.015188068151473999 || Val Loss : 4.029199123382568\n",
      "Epoch : 829 || Train Loss : 0.01708167977631092 || Val Loss : 4.066205978393555\n",
      "Epoch : 830 || Train Loss : 0.016582507640123367 || Val Loss : 4.009520053863525\n",
      "Epoch : 831 || Train Loss : 0.022025613114237785 || Val Loss : 4.042540550231934\n",
      "Epoch : 832 || Train Loss : 0.01540034543722868 || Val Loss : 4.034738063812256\n",
      "Epoch : 833 || Train Loss : 0.014170481823384762 || Val Loss : 4.043142318725586\n",
      "Epoch : 834 || Train Loss : 0.014075224287807941 || Val Loss : 4.017793655395508\n",
      "Epoch : 835 || Train Loss : 0.016239790245890617 || Val Loss : 4.016777992248535\n",
      "Epoch : 836 || Train Loss : 0.01471775770187378 || Val Loss : 4.003959655761719\n",
      "Epoch : 837 || Train Loss : 0.022342687472701073 || Val Loss : 4.082439422607422\n",
      "Epoch : 838 || Train Loss : 0.026204852387309074 || Val Loss : 4.032435417175293\n",
      "Epoch : 839 || Train Loss : 0.016321269795298576 || Val Loss : 4.029088497161865\n",
      "Epoch : 840 || Train Loss : 0.013631804846227169 || Val Loss : 4.018887519836426\n",
      "Epoch : 841 || Train Loss : 0.01655779778957367 || Val Loss : 3.988165855407715\n",
      "Epoch : 842 || Train Loss : 0.019372599199414253 || Val Loss : 3.999032735824585\n",
      "Epoch : 843 || Train Loss : 0.014991501346230507 || Val Loss : 4.028671741485596\n",
      "Epoch : 844 || Train Loss : 0.01436665654182434 || Val Loss : 4.00721549987793\n",
      "Epoch : 845 || Train Loss : 0.015193498693406582 || Val Loss : 4.015045166015625\n",
      "Epoch : 846 || Train Loss : 0.012534061446785927 || Val Loss : 4.004213333129883\n",
      "Epoch : 847 || Train Loss : 0.014504238031804562 || Val Loss : 3.9842369556427\n",
      "Epoch : 848 || Train Loss : 0.018564455211162567 || Val Loss : 4.0117011070251465\n",
      "Epoch : 849 || Train Loss : 0.013905840925872326 || Val Loss : 3.986036777496338\n",
      "Epoch : 850 || Train Loss : 0.0165349580347538 || Val Loss : 4.001149654388428\n",
      "Epoch : 851 || Train Loss : 0.015015973709523678 || Val Loss : 3.9986965656280518\n",
      "Epoch : 852 || Train Loss : 0.013925080187618732 || Val Loss : 4.014965534210205\n",
      "Epoch : 853 || Train Loss : 0.015346153639256954 || Val Loss : 4.060669898986816\n",
      "Epoch : 854 || Train Loss : 0.02358236163854599 || Val Loss : 3.981708526611328\n",
      "Epoch : 855 || Train Loss : 0.015714650973677635 || Val Loss : 4.031374931335449\n",
      "Epoch : 856 || Train Loss : 0.017976747825741768 || Val Loss : 3.9726462364196777\n",
      "Epoch : 857 || Train Loss : 0.015687840059399605 || Val Loss : 4.008791446685791\n",
      "Epoch : 858 || Train Loss : 0.013732947409152985 || Val Loss : 3.9986064434051514\n",
      "Epoch : 859 || Train Loss : 0.01571318879723549 || Val Loss : 3.952691078186035\n",
      "Epoch : 860 || Train Loss : 0.02102057822048664 || Val Loss : 4.026031970977783\n",
      "Epoch : 861 || Train Loss : 0.017689768224954605 || Val Loss : 4.082748889923096\n",
      "Epoch : 862 || Train Loss : 0.021885493770241737 || Val Loss : 3.997344970703125\n",
      "Epoch : 863 || Train Loss : 0.015151101164519787 || Val Loss : 3.9807422161102295\n",
      "Epoch : 864 || Train Loss : 0.01751166768372059 || Val Loss : 4.002523422241211\n",
      "Epoch : 865 || Train Loss : 0.016332635655999184 || Val Loss : 3.9942383766174316\n",
      "Epoch : 866 || Train Loss : 0.012569839134812355 || Val Loss : 3.9935662746429443\n",
      "Epoch : 867 || Train Loss : 0.01427577342838049 || Val Loss : 3.951260566711426\n",
      "Epoch : 868 || Train Loss : 0.02174144797027111 || Val Loss : 4.0503458976745605\n",
      "Epoch : 869 || Train Loss : 0.020372258499264717 || Val Loss : 3.9740452766418457\n",
      "Epoch : 870 || Train Loss : 0.01777549460530281 || Val Loss : 4.011902332305908\n",
      "Epoch : 871 || Train Loss : 0.0158731397241354 || Val Loss : 3.961381196975708\n",
      "Epoch : 872 || Train Loss : 0.014707575552165508 || Val Loss : 3.9756698608398438\n",
      "Epoch : 873 || Train Loss : 0.015033978037536144 || Val Loss : 3.990549087524414\n",
      "Epoch : 874 || Train Loss : 0.01418154127895832 || Val Loss : 3.9667303562164307\n",
      "Epoch : 875 || Train Loss : 0.014004917815327644 || Val Loss : 3.9776525497436523\n",
      "Epoch : 876 || Train Loss : 0.016766730695962906 || Val Loss : 3.929464340209961\n",
      "Epoch : 877 || Train Loss : 0.025194261223077774 || Val Loss : 3.997361421585083\n",
      "Epoch : 878 || Train Loss : 0.014598013833165169 || Val Loss : 3.9706528186798096\n",
      "Epoch : 879 || Train Loss : 0.014468616805970669 || Val Loss : 4.019996166229248\n",
      "Epoch : 880 || Train Loss : 0.018509892746806145 || Val Loss : 3.971506118774414\n",
      "Epoch : 881 || Train Loss : 0.015293535776436329 || Val Loss : 3.9921610355377197\n",
      "Epoch : 882 || Train Loss : 0.016519686207175255 || Val Loss : 3.9497315883636475\n",
      "Epoch : 883 || Train Loss : 0.015519283711910248 || Val Loss : 3.9921395778656006\n",
      "Epoch : 884 || Train Loss : 0.01979941502213478 || Val Loss : 3.949000835418701\n",
      "Epoch : 885 || Train Loss : 0.013254018500447273 || Val Loss : 3.955332040786743\n",
      "Epoch : 886 || Train Loss : 0.013788938522338867 || Val Loss : 3.988187551498413\n",
      "Epoch : 887 || Train Loss : 0.014533497393131256 || Val Loss : 3.9511172771453857\n",
      "Epoch : 888 || Train Loss : 0.017992040142416954 || Val Loss : 3.989595413208008\n",
      "Epoch : 889 || Train Loss : 0.01592875085771084 || Val Loss : 3.962658405303955\n",
      "Epoch : 890 || Train Loss : 0.015241587534546852 || Val Loss : 3.951421022415161\n",
      "Epoch : 891 || Train Loss : 0.013778457418084145 || Val Loss : 3.952871799468994\n",
      "Epoch : 892 || Train Loss : 0.014307538978755474 || Val Loss : 3.9673140048980713\n",
      "Epoch : 893 || Train Loss : 0.014961409382522106 || Val Loss : 3.932705879211426\n",
      "Epoch : 894 || Train Loss : 0.015498662367463112 || Val Loss : 3.9472169876098633\n",
      "Epoch : 895 || Train Loss : 0.014341133646667004 || Val Loss : 3.9847421646118164\n",
      "Epoch : 896 || Train Loss : 0.01932736113667488 || Val Loss : 3.9365251064300537\n",
      "Epoch : 897 || Train Loss : 0.015312829986214638 || Val Loss : 3.944693088531494\n",
      "Epoch : 898 || Train Loss : 0.01571410708129406 || Val Loss : 3.8892178535461426\n",
      "Epoch : 899 || Train Loss : 0.02311486005783081 || Val Loss : 3.9528961181640625\n",
      "Epoch : 900 || Train Loss : 0.020300334319472313 || Val Loss : 3.8896477222442627\n",
      "Epoch : 901 || Train Loss : 0.01895594410598278 || Val Loss : 3.9446640014648438\n",
      "Epoch : 902 || Train Loss : 0.014325529336929321 || Val Loss : 3.965386152267456\n",
      "Epoch : 903 || Train Loss : 0.016625745221972466 || Val Loss : 3.8997642993927\n",
      "Epoch : 904 || Train Loss : 0.01842097006738186 || Val Loss : 3.933757781982422\n",
      "Epoch : 905 || Train Loss : 0.013742429204285145 || Val Loss : 3.90437650680542\n",
      "Epoch : 906 || Train Loss : 0.016489597037434578 || Val Loss : 3.9635939598083496\n",
      "Epoch : 907 || Train Loss : 0.020895352587103844 || Val Loss : 3.8944129943847656\n",
      "Epoch : 908 || Train Loss : 0.018358711153268814 || Val Loss : 3.9220364093780518\n",
      "Epoch : 909 || Train Loss : 0.016675421968102455 || Val Loss : 3.8780360221862793\n",
      "Epoch : 910 || Train Loss : 0.017133284360170364 || Val Loss : 3.9137680530548096\n",
      "Epoch : 911 || Train Loss : 0.012782110832631588 || Val Loss : 3.9116265773773193\n",
      "Epoch : 912 || Train Loss : 0.013517587445676327 || Val Loss : 3.9211156368255615\n",
      "Epoch : 913 || Train Loss : 0.0144161656498909 || Val Loss : 3.908245086669922\n",
      "Epoch : 914 || Train Loss : 0.012102747336030006 || Val Loss : 3.8927533626556396\n",
      "Epoch : 915 || Train Loss : 0.01437296997755766 || Val Loss : 3.9275896549224854\n",
      "Epoch : 916 || Train Loss : 0.015900731086730957 || Val Loss : 3.929198741912842\n",
      "Epoch : 917 || Train Loss : 0.01532052457332611 || Val Loss : 3.9156887531280518\n",
      "Epoch : 918 || Train Loss : 0.015750577673316002 || Val Loss : 3.9448390007019043\n",
      "Epoch : 919 || Train Loss : 0.025663131847977638 || Val Loss : 3.8924121856689453\n",
      "Epoch : 920 || Train Loss : 0.015246662311255932 || Val Loss : 3.920555591583252\n",
      "Epoch : 921 || Train Loss : 0.013846742920577526 || Val Loss : 3.8880226612091064\n",
      "Epoch : 922 || Train Loss : 0.01570773497223854 || Val Loss : 3.9092438220977783\n",
      "Epoch : 923 || Train Loss : 0.015188452787697315 || Val Loss : 3.9567668437957764\n",
      "Epoch : 924 || Train Loss : 0.018026456236839294 || Val Loss : 3.892305850982666\n",
      "Epoch : 925 || Train Loss : 0.01572003774344921 || Val Loss : 3.9297749996185303\n",
      "Epoch : 926 || Train Loss : 0.01682819053530693 || Val Loss : 3.876136064529419\n",
      "Epoch : 927 || Train Loss : 0.018291516229510307 || Val Loss : 3.9370665550231934\n",
      "Epoch : 928 || Train Loss : 0.01761925034224987 || Val Loss : 3.8952436447143555\n",
      "Epoch : 929 || Train Loss : 0.013030524365603924 || Val Loss : 3.9105231761932373\n",
      "Epoch : 930 || Train Loss : 0.01440417766571045 || Val Loss : 3.871509313583374\n",
      "Epoch : 931 || Train Loss : 0.015111954882740974 || Val Loss : 3.902385950088501\n",
      "Epoch : 932 || Train Loss : 0.01693033054471016 || Val Loss : 3.865795135498047\n",
      "Epoch : 933 || Train Loss : 0.018248045817017555 || Val Loss : 3.9093382358551025\n",
      "Epoch : 934 || Train Loss : 0.013876164332032204 || Val Loss : 3.8996286392211914\n",
      "Epoch : 935 || Train Loss : 0.014170818030834198 || Val Loss : 3.874476909637451\n",
      "Epoch : 936 || Train Loss : 0.01649021916091442 || Val Loss : 3.917999744415283\n",
      "Epoch : 937 || Train Loss : 0.017516696825623512 || Val Loss : 3.858586311340332\n",
      "Epoch : 938 || Train Loss : 0.015982864424586296 || Val Loss : 3.8933064937591553\n",
      "Epoch : 939 || Train Loss : 0.013736993074417114 || Val Loss : 3.877338409423828\n",
      "Epoch : 940 || Train Loss : 0.013891427777707577 || Val Loss : 3.8708248138427734\n",
      "Epoch : 941 || Train Loss : 0.013230639509856701 || Val Loss : 3.867506265640259\n",
      "Epoch : 942 || Train Loss : 0.014945769682526588 || Val Loss : 3.8912105560302734\n",
      "Epoch : 943 || Train Loss : 0.013332716189324856 || Val Loss : 3.858912229537964\n",
      "Epoch : 944 || Train Loss : 0.015050756745040417 || Val Loss : 3.881239891052246\n",
      "Epoch : 945 || Train Loss : 0.014830045402050018 || Val Loss : 3.863046407699585\n",
      "Epoch : 946 || Train Loss : 0.014011633582413197 || Val Loss : 3.8586747646331787\n",
      "Epoch : 947 || Train Loss : 0.015109560452401638 || Val Loss : 3.8406126499176025\n",
      "Epoch : 948 || Train Loss : 0.015174168162047863 || Val Loss : 3.891465187072754\n",
      "Epoch : 949 || Train Loss : 0.015408105216920376 || Val Loss : 3.844193696975708\n",
      "Epoch : 950 || Train Loss : 0.014983653090894222 || Val Loss : 3.8721323013305664\n",
      "Epoch : 951 || Train Loss : 0.014736421406269073 || Val Loss : 3.845911979675293\n",
      "Epoch : 952 || Train Loss : 0.01567627303302288 || Val Loss : 3.8437414169311523\n",
      "Epoch : 953 || Train Loss : 0.013608606532216072 || Val Loss : 3.862398624420166\n",
      "Epoch : 954 || Train Loss : 0.012964839115738869 || Val Loss : 3.8460395336151123\n",
      "Epoch : 955 || Train Loss : 0.01303807832300663 || Val Loss : 3.834798812866211\n",
      "Epoch : 956 || Train Loss : 0.016322076320648193 || Val Loss : 3.8442790508270264\n",
      "Epoch : 957 || Train Loss : 0.012997927144169807 || Val Loss : 3.823590040206909\n",
      "Epoch : 958 || Train Loss : 0.016169944778084755 || Val Loss : 3.8604190349578857\n",
      "Epoch : 959 || Train Loss : 0.013169663026928902 || Val Loss : 3.830219268798828\n",
      "Epoch : 960 || Train Loss : 0.01482305396348238 || Val Loss : 3.8455545902252197\n",
      "Epoch : 961 || Train Loss : 0.014168075285851955 || Val Loss : 3.8637137413024902\n",
      "Epoch : 962 || Train Loss : 0.01501536276191473 || Val Loss : 3.8214914798736572\n",
      "Epoch : 963 || Train Loss : 0.01747438684105873 || Val Loss : 3.868417501449585\n",
      "Epoch : 964 || Train Loss : 0.014460349455475807 || Val Loss : 3.8381950855255127\n",
      "Epoch : 965 || Train Loss : 0.012413281947374344 || Val Loss : 3.8404762744903564\n",
      "Epoch : 966 || Train Loss : 0.013154217973351479 || Val Loss : 3.839738607406616\n",
      "Epoch : 967 || Train Loss : 0.013678607530891895 || Val Loss : 3.8425488471984863\n",
      "Epoch : 968 || Train Loss : 0.012229804880917072 || Val Loss : 3.8523073196411133\n",
      "Epoch : 969 || Train Loss : 0.01536059845238924 || Val Loss : 3.818256378173828\n",
      "Epoch : 970 || Train Loss : 0.013961290009319782 || Val Loss : 3.8108737468719482\n",
      "Epoch : 971 || Train Loss : 0.01571856625378132 || Val Loss : 3.8272933959960938\n",
      "Epoch : 972 || Train Loss : 0.014187008142471313 || Val Loss : 3.846137523651123\n",
      "Epoch : 973 || Train Loss : 0.0133981229737401 || Val Loss : 3.836334705352783\n",
      "Epoch : 974 || Train Loss : 0.015019348822534084 || Val Loss : 3.8257510662078857\n",
      "Epoch : 975 || Train Loss : 0.01433503907173872 || Val Loss : 3.853485107421875\n",
      "Epoch : 976 || Train Loss : 0.0140224015340209 || Val Loss : 3.8413925170898438\n",
      "Epoch : 977 || Train Loss : 0.013568082824349403 || Val Loss : 3.8230886459350586\n",
      "Epoch : 978 || Train Loss : 0.014193162322044373 || Val Loss : 3.836859703063965\n",
      "Epoch : 979 || Train Loss : 0.015879981219768524 || Val Loss : 3.796579599380493\n",
      "Epoch : 980 || Train Loss : 0.015744512900710106 || Val Loss : 3.8226215839385986\n",
      "Epoch : 981 || Train Loss : 0.014059612527489662 || Val Loss : 3.789713144302368\n",
      "Epoch : 982 || Train Loss : 0.013140114024281502 || Val Loss : 3.8102409839630127\n",
      "Epoch : 983 || Train Loss : 0.012614858336746693 || Val Loss : 3.8041512966156006\n",
      "Epoch : 984 || Train Loss : 0.01481231302022934 || Val Loss : 3.8164920806884766\n",
      "Epoch : 985 || Train Loss : 0.014073614962399006 || Val Loss : 3.8357996940612793\n",
      "Epoch : 986 || Train Loss : 0.016745347529649734 || Val Loss : 3.7811849117279053\n",
      "Epoch : 987 || Train Loss : 0.01600189320743084 || Val Loss : 3.7949540615081787\n",
      "Epoch : 988 || Train Loss : 0.012785646133124828 || Val Loss : 3.7952933311462402\n",
      "Epoch : 989 || Train Loss : 0.015104456804692745 || Val Loss : 3.844838857650757\n",
      "Epoch : 990 || Train Loss : 0.021743884310126305 || Val Loss : 3.790506362915039\n",
      "Epoch : 991 || Train Loss : 0.013110809028148651 || Val Loss : 3.803224802017212\n",
      "Epoch : 992 || Train Loss : 0.013104140758514404 || Val Loss : 3.819261074066162\n",
      "Epoch : 993 || Train Loss : 0.013428556732833385 || Val Loss : 3.800055503845215\n",
      "Epoch : 994 || Train Loss : 0.014714712277054787 || Val Loss : 3.7605974674224854\n",
      "Epoch : 995 || Train Loss : 0.02351801097393036 || Val Loss : 3.857956886291504\n",
      "Epoch : 996 || Train Loss : 0.018601572141051292 || Val Loss : 3.794867992401123\n",
      "Epoch : 997 || Train Loss : 0.01505811233073473 || Val Loss : 3.8014252185821533\n",
      "Epoch : 998 || Train Loss : 0.01357843168079853 || Val Loss : 3.8056273460388184\n",
      "Epoch : 999 || Train Loss : 0.013470577076077461 || Val Loss : 3.774836301803589\n",
      "Epoch : 1000 || Train Loss : 0.020185701549053192 || Val Loss : 3.842329263687134\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    curr_tr_loss = 0\n",
    "    curr_val_loss = 0\n",
    "    for X,y in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        X = X[:,:,None]\n",
    "        \n",
    "        output = model(X)\n",
    "        #print(output.size(), y.size())\n",
    "        loss = loss_function(output.view(-1), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        curr_tr_loss += loss.div(train_batch_size)\n",
    "    train_losses.append(curr_tr_loss.div(len(train_dataloader)).item())\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #validation:\n",
    "    for X,y in val_dataloader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        X = X[:,:,None]\n",
    "        output = model(X)\n",
    "        loss = loss_function(output.view(-1), y)\n",
    "\n",
    "        curr_val_loss += loss.div(val_batch_size)\n",
    "    val_losses.append(curr_val_loss.div(len(val_dataloader)).item())\n",
    "    \n",
    "    print(f'Epoch : {e} || Train Loss : {curr_tr_loss.div(len(train_dataloader)).item()} || Val Loss : {curr_val_loss.div(len(val_dataloader)).item()}')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dcb77ca-73b7-4d39-9836-c6f751fffdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2)=plt.subplots(1,2)\n",
    "ax1.plot(train_losses)\n",
    "ax2.plot(val_losses)\n",
    "ax1.set_title(\"Train Loss\")\n",
    "ax2.set_title(\"Val Loss\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.tight_layout()\n",
    "fig.savefig('DLSLab1.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
